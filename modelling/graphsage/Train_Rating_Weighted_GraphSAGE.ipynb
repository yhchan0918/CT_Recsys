{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baaf5704",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-24 2022-10-23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/yhchan/Downloads/FYP/CT_Recsys/modelling/graphsage/wandb/run-20230506_171131-lgv75oy2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yhchan0918/Experimenting_GraphSAGE/runs/lgv75oy2' target=\"_blank\">valiant-breeze-39</a></strong> to <a href='https://wandb.ai/yhchan0918/Experimenting_GraphSAGE' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yhchan0918/Experimenting_GraphSAGE' target=\"_blank\">https://wandb.ai/yhchan0918/Experimenting_GraphSAGE</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yhchan0918/Experimenting_GraphSAGE/runs/lgv75oy2' target=\"_blank\">https://wandb.ai/yhchan0918/Experimenting_GraphSAGE/runs/lgv75oy2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 17:11:41.075 | INFO     | process_data:main_train_test:140 - Split df into train and test portion\n",
      "/Users/yhchan/Downloads/FYP/CT_Recsys/modelling/graphsage/process_data.py:172: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1670525682339/work/torch/csrc/utils/tensor_numpy.cpp:205.)\n",
      "  temp = torch.from_numpy(val).view(-1, 1).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole Graph HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={ x=[18523, 158] },\n",
      "  \u001b[1muser\u001b[0m={ x=[394551, 384] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 408596],\n",
      "    edge_label=[408596],\n",
      "    edge_label_index=[2, 408596]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 408596] }\n",
      ")\n",
      "Training Heterogenous Graph HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={ x=[17229, 158] },\n",
      "  \u001b[1muser\u001b[0m={ x=[324135, 384] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 334678],\n",
      "    edge_label=[334678],\n",
      "    edge_label_index=[2, 334678]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 334678] }\n",
      ")\n",
      "Test Heterogenous Graph HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={ x=[14380, 158] },\n",
      "  \u001b[1muser\u001b[0m={ x=[72447, 384] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 73918],\n",
      "    edge_label=[73918],\n",
      "    edge_label_index=[2, 73918]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 73918] }\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./train)... Done. 15.7s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./test)... Done. 3.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.wandb_artifacts.Artifact at 0x2d7c6dd00>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#main_train.py\n",
    "import wandb\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "from dateutil.relativedelta import relativedelta  # type: ignore\n",
    "import functools\n",
    "\n",
    "from process_data import *\n",
    "from evaluate import *\n",
    "from constants import *\n",
    "from model import *\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "start_date = dt.strptime(\"2021-10-24\", \"%Y-%m-%d\").date()\n",
    "end_date, nxt_start_date = split_date_by_period_months(start_date, TOTAL_MONTHS_PER_ITERATION)\n",
    "print(start_date, end_date)\n",
    "directory = \"/Users/yhchan/Downloads/FYP/data/processed\"\n",
    "# reviews = pd.read_parquet(f\"{directory}/reviews_with_interactions.parquet\")\n",
    "reviews = pd.read_parquet(f\"eval_result/i.parquet\")\n",
    "listings = pd.read_parquet(f\"{directory}/listings_with_interactions.parquet\")\n",
    "\n",
    "config = {\n",
    "        \"architecture\": \"Rating-Weighted GraphSAGE\",\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"hidden_channels\": 64,\n",
    "        \"train_batch_size\": 128,\n",
    "        \"test_batch_size\": 128,\n",
    "        \"epochs\": 300,\n",
    "        \"train_num_neighbours\": [10, 10],\n",
    "        \"test_num_neighbours\": [-1],\n",
    "        \"train_split_period_months\": 10,\n",
    "        \"total_months_of_data\": TOTAL_MONTHS_PER_ITERATION,\n",
    "    }\n",
    "\n",
    "wandb.init(\n",
    "    project=PROJECT_NAME,\n",
    "    config=config,\n",
    ")\n",
    "wandb.define_metric(\"train_loss\", step_metric=\"epoch\", summary=\"min\")\n",
    "wandb.define_metric(\"test_loss\", step_metric=\"epoch\", summary=\"min\")\n",
    "\n",
    "(\n",
    "    train_reviews,\n",
    "    train_listings,\n",
    "    train_reviewers,\n",
    "    test_reviews,\n",
    "    test_listings,\n",
    "    test_reviewers,\n",
    ") = main_train_test(\n",
    "    reviews,\n",
    "    listings,\n",
    "    start_date,\n",
    "    end_date,\n",
    "    config[\"train_split_period_months\"],\n",
    ")\n",
    "\n",
    "# Build Graph\n",
    "involved_reviews = pd.concat([train_reviews, test_reviews])\n",
    "involved_listings, involved_reviewers = build_partitioned_data(involved_reviews, listings)\n",
    "involved_data = build_heterograph(involved_reviews, involved_listings, involved_reviewers, True)\n",
    "train_data = build_heterograph(train_reviews, train_listings, train_reviewers, True)\n",
    "test_data = build_heterograph(test_reviews, test_listings, test_reviewers, True)\n",
    "\n",
    "print(\"Whole Graph\", involved_data)\n",
    "print(\"Training Heterogenous Graph\", train_data)\n",
    "print(\"Test Heterogenous Graph\", test_data)\n",
    "\n",
    "involved_listings2dict = get_entity2dict(involved_listings, \"listing_id\")\n",
    "reverse_involved_listings2dict = {k: v for v, k in involved_listings2dict.items()}\n",
    "\n",
    "metadata_dict = {\n",
    "    \"num_reviews\": len(involved_reviews),\n",
    "    \"num_train_reviews\": len(train_reviews),\n",
    "    \"num_test_reviews\": len(test_reviews),\n",
    "    \n",
    "    \"num_unique_listings\": len(involved_listings),\n",
    "    \"num_unique_train_listings\": len(train_listings),\n",
    "    \"num_unique_test_listings\": len(test_listings),\n",
    "    \n",
    "    \"num_unique_reviewers\": len(involved_reviewers),\n",
    "    \"num_unique_train_reviewers\": len(train_reviewers),\n",
    "    \"num_unique_test_reviewers\": len(test_reviewers),\n",
    "\n",
    "}\n",
    "\n",
    "wandb.log(metadata_dict)\n",
    "train_reviews.to_parquet(\"train/train_reviews.parquet\", index=False)\n",
    "train_listings.to_parquet(\"train/train_listings.parquet\", index=False)\n",
    "train_reviewers.to_parquet(\"train/train_reviewers.parquet\", index=False)\n",
    "test_reviews.to_parquet(\"test/test_reviews.parquet\", index=False)\n",
    "test_listings.to_parquet(\"test/test_listings.parquet\", index=False)\n",
    "test_reviewers.to_parquet(\"test/test_reviewers.parquet\", index=False)\n",
    "\n",
    "dataset_art = wandb.Artifact(f\"{start_date}_{end_date}_data\", type=\"dataset\")\n",
    "for dir in [\"train\", \"test\"]:\n",
    "    dataset_art.add_dir(dir)\n",
    "wandb.log_artifact(dataset_art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "799f3eee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>rating</th>\n",
       "      <th>comments</th>\n",
       "      <th>localized_comments</th>\n",
       "      <th>response</th>\n",
       "      <th>localized_response</th>\n",
       "      <th>language</th>\n",
       "      <th>created_at</th>\n",
       "      <th>localized_date</th>\n",
       "      <th>...</th>\n",
       "      <th>comment_embedding_374</th>\n",
       "      <th>comment_embedding_375</th>\n",
       "      <th>comment_embedding_376</th>\n",
       "      <th>comment_embedding_377</th>\n",
       "      <th>comment_embedding_378</th>\n",
       "      <th>comment_embedding_379</th>\n",
       "      <th>comment_embedding_380</th>\n",
       "      <th>comment_embedding_381</th>\n",
       "      <th>comment_embedding_382</th>\n",
       "      <th>comment_embedding_383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>327020</th>\n",
       "      <td>565363545634411496</td>\n",
       "      <td>700148910573345619</td>\n",
       "      <td>5</td>\n",
       "      <td>Cute interior and it’s clear they are working ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-08-24 00:30:54+00:00</td>\n",
       "      <td>August 2022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038409</td>\n",
       "      <td>-0.066551</td>\n",
       "      <td>-0.014902</td>\n",
       "      <td>0.010823</td>\n",
       "      <td>0.041533</td>\n",
       "      <td>0.011691</td>\n",
       "      <td>-0.009620</td>\n",
       "      <td>0.029076</td>\n",
       "      <td>-0.088270</td>\n",
       "      <td>0.102734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79084</th>\n",
       "      <td>1160513</td>\n",
       "      <td>700174478220621084</td>\n",
       "      <td>5</td>\n",
       "      <td>We had a wonderful four nights at the stables....</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-08-24 01:21:42+00:00</td>\n",
       "      <td>August 2022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032808</td>\n",
       "      <td>0.037328</td>\n",
       "      <td>-0.007237</td>\n",
       "      <td>0.013807</td>\n",
       "      <td>0.049898</td>\n",
       "      <td>-0.020697</td>\n",
       "      <td>-0.041794</td>\n",
       "      <td>0.070709</td>\n",
       "      <td>-0.065858</td>\n",
       "      <td>-0.021460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113978</th>\n",
       "      <td>18257779</td>\n",
       "      <td>700197391577040975</td>\n",
       "      <td>5</td>\n",
       "      <td>A beautiful  spot that's very well appointed a...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-08-24 02:07:13+00:00</td>\n",
       "      <td>August 2022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094430</td>\n",
       "      <td>-0.070190</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.010329</td>\n",
       "      <td>0.025568</td>\n",
       "      <td>0.069839</td>\n",
       "      <td>-0.032196</td>\n",
       "      <td>0.121626</td>\n",
       "      <td>-0.076257</td>\n",
       "      <td>0.003784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169334</th>\n",
       "      <td>53943018</td>\n",
       "      <td>700212335835357732</td>\n",
       "      <td>5</td>\n",
       "      <td>We could not have been more pleased with our h...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-08-24 02:36:55+00:00</td>\n",
       "      <td>August 2022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032651</td>\n",
       "      <td>0.074519</td>\n",
       "      <td>-0.092788</td>\n",
       "      <td>-0.018733</td>\n",
       "      <td>0.008588</td>\n",
       "      <td>0.100716</td>\n",
       "      <td>-0.013107</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>-0.086565</td>\n",
       "      <td>0.011032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168345</th>\n",
       "      <td>45354179</td>\n",
       "      <td>700214006782856333</td>\n",
       "      <td>5</td>\n",
       "      <td>This place is incredible! Beautiful location a...</td>\n",
       "      <td>None</td>\n",
       "      <td>We’re glad you had a great stay! We look forwa...</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-08-24 02:40:14+00:00</td>\n",
       "      <td>August 2022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044387</td>\n",
       "      <td>0.031949</td>\n",
       "      <td>-0.034708</td>\n",
       "      <td>-0.060949</td>\n",
       "      <td>0.036342</td>\n",
       "      <td>0.062206</td>\n",
       "      <td>-0.082926</td>\n",
       "      <td>-0.028832</td>\n",
       "      <td>-0.103534</td>\n",
       "      <td>0.014343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384193</th>\n",
       "      <td>14064796</td>\n",
       "      <td>743754797882360083</td>\n",
       "      <td>5</td>\n",
       "      <td>房子很乾淨，空間也很舒服，準備的東西也很齊全，唯一美中不足的是，離地鐵站有一段距離，需要走1...</td>\n",
       "      <td>The house is very clean, the space is also ver...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>zh-TW</td>\n",
       "      <td>2022-10-23 04:28:01+00:00</td>\n",
       "      <td>October 2022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063871</td>\n",
       "      <td>-0.013477</td>\n",
       "      <td>-0.029722</td>\n",
       "      <td>0.015655</td>\n",
       "      <td>0.053216</td>\n",
       "      <td>-0.017010</td>\n",
       "      <td>-0.039557</td>\n",
       "      <td>0.056494</td>\n",
       "      <td>-0.085848</td>\n",
       "      <td>-0.010447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294531</th>\n",
       "      <td>46286939</td>\n",
       "      <td>743757361545674933</td>\n",
       "      <td>5</td>\n",
       "      <td>The pictures don’t do this place justice. Perf...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-10-23 04:33:06+00:00</td>\n",
       "      <td>October 2022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019919</td>\n",
       "      <td>-0.059019</td>\n",
       "      <td>0.029331</td>\n",
       "      <td>0.022194</td>\n",
       "      <td>0.075792</td>\n",
       "      <td>0.094105</td>\n",
       "      <td>-0.005719</td>\n",
       "      <td>-0.037350</td>\n",
       "      <td>-0.136996</td>\n",
       "      <td>0.003359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52977</th>\n",
       "      <td>51197659</td>\n",
       "      <td>743805310969690631</td>\n",
       "      <td>5</td>\n",
       "      <td>1) 프라이빗하고 귀여운 숙소 찾는다면 필수&lt;br/&gt;2) 한적한 산 향을 코 끝까지...</td>\n",
       "      <td>1) If you are looking for a private and cute p...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ko</td>\n",
       "      <td>2022-10-23 06:08:22+00:00</td>\n",
       "      <td>October 2022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076334</td>\n",
       "      <td>0.019734</td>\n",
       "      <td>-0.027781</td>\n",
       "      <td>-0.032406</td>\n",
       "      <td>0.052717</td>\n",
       "      <td>0.057844</td>\n",
       "      <td>0.030669</td>\n",
       "      <td>0.063396</td>\n",
       "      <td>-0.058295</td>\n",
       "      <td>-0.025689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294815</th>\n",
       "      <td>13660583</td>\n",
       "      <td>743878492821039786</td>\n",
       "      <td>5</td>\n",
       "      <td>Lovely and quiet place away from the main stri...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-10-23 08:33:46+00:00</td>\n",
       "      <td>October 2022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033631</td>\n",
       "      <td>0.029964</td>\n",
       "      <td>-0.045013</td>\n",
       "      <td>0.038327</td>\n",
       "      <td>0.025526</td>\n",
       "      <td>0.100794</td>\n",
       "      <td>0.028082</td>\n",
       "      <td>0.017888</td>\n",
       "      <td>-0.078899</td>\n",
       "      <td>0.041347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396371</th>\n",
       "      <td>50458828</td>\n",
       "      <td>744013061565099656</td>\n",
       "      <td>2</td>\n",
       "      <td>el edificio es muy antiguo.&lt;br/&gt;la ducha esta ...</td>\n",
       "      <td>the building is very old.&lt;br/&gt;the shower is br...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>es</td>\n",
       "      <td>2022-10-23 13:01:08+00:00</td>\n",
       "      <td>October 2022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027117</td>\n",
       "      <td>-0.037116</td>\n",
       "      <td>0.018932</td>\n",
       "      <td>-0.043876</td>\n",
       "      <td>0.033317</td>\n",
       "      <td>-0.031043</td>\n",
       "      <td>0.066531</td>\n",
       "      <td>-0.037273</td>\n",
       "      <td>-0.032762</td>\n",
       "      <td>0.098167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72447 rows × 405 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                listing_id                  id  rating  \\\n",
       "327020  565363545634411496  700148910573345619       5   \n",
       "79084              1160513  700174478220621084       5   \n",
       "113978            18257779  700197391577040975       5   \n",
       "169334            53943018  700212335835357732       5   \n",
       "168345            45354179  700214006782856333       5   \n",
       "...                    ...                 ...     ...   \n",
       "384193            14064796  743754797882360083       5   \n",
       "294531            46286939  743757361545674933       5   \n",
       "52977             51197659  743805310969690631       5   \n",
       "294815            13660583  743878492821039786       5   \n",
       "396371            50458828  744013061565099656       2   \n",
       "\n",
       "                                                 comments  \\\n",
       "327020  Cute interior and it’s clear they are working ...   \n",
       "79084   We had a wonderful four nights at the stables....   \n",
       "113978  A beautiful  spot that's very well appointed a...   \n",
       "169334  We could not have been more pleased with our h...   \n",
       "168345  This place is incredible! Beautiful location a...   \n",
       "...                                                   ...   \n",
       "384193  房子很乾淨，空間也很舒服，準備的東西也很齊全，唯一美中不足的是，離地鐵站有一段距離，需要走1...   \n",
       "294531  The pictures don’t do this place justice. Perf...   \n",
       "52977   1) 프라이빗하고 귀여운 숙소 찾는다면 필수<br/>2) 한적한 산 향을 코 끝까지...   \n",
       "294815  Lovely and quiet place away from the main stri...   \n",
       "396371  el edificio es muy antiguo.<br/>la ducha esta ...   \n",
       "\n",
       "                                       localized_comments  \\\n",
       "327020                                               None   \n",
       "79084                                                None   \n",
       "113978                                               None   \n",
       "169334                                               None   \n",
       "168345                                               None   \n",
       "...                                                   ...   \n",
       "384193  The house is very clean, the space is also ver...   \n",
       "294531                                               None   \n",
       "52977   1) If you are looking for a private and cute p...   \n",
       "294815                                               None   \n",
       "396371  the building is very old.<br/>the shower is br...   \n",
       "\n",
       "                                                 response localized_response  \\\n",
       "327020                                               None               None   \n",
       "79084                                                None               None   \n",
       "113978                                               None               None   \n",
       "169334                                               None               None   \n",
       "168345  We’re glad you had a great stay! We look forwa...               None   \n",
       "...                                                   ...                ...   \n",
       "384193                                               None               None   \n",
       "294531                                               None               None   \n",
       "52977                                                None               None   \n",
       "294815                                               None               None   \n",
       "396371                                               None               None   \n",
       "\n",
       "       language                created_at localized_date  ...  \\\n",
       "327020       en 2022-08-24 00:30:54+00:00    August 2022  ...   \n",
       "79084        en 2022-08-24 01:21:42+00:00    August 2022  ...   \n",
       "113978       en 2022-08-24 02:07:13+00:00    August 2022  ...   \n",
       "169334       en 2022-08-24 02:36:55+00:00    August 2022  ...   \n",
       "168345       en 2022-08-24 02:40:14+00:00    August 2022  ...   \n",
       "...         ...                       ...            ...  ...   \n",
       "384193    zh-TW 2022-10-23 04:28:01+00:00   October 2022  ...   \n",
       "294531       en 2022-10-23 04:33:06+00:00   October 2022  ...   \n",
       "52977        ko 2022-10-23 06:08:22+00:00   October 2022  ...   \n",
       "294815       en 2022-10-23 08:33:46+00:00   October 2022  ...   \n",
       "396371       es 2022-10-23 13:01:08+00:00   October 2022  ...   \n",
       "\n",
       "       comment_embedding_374 comment_embedding_375 comment_embedding_376  \\\n",
       "327020              0.038409             -0.066551             -0.014902   \n",
       "79084               0.032808              0.037328             -0.007237   \n",
       "113978              0.094430             -0.070190             -0.000054   \n",
       "169334              0.032651              0.074519             -0.092788   \n",
       "168345              0.044387              0.031949             -0.034708   \n",
       "...                      ...                   ...                   ...   \n",
       "384193              0.063871             -0.013477             -0.029722   \n",
       "294531              0.019919             -0.059019              0.029331   \n",
       "52977               0.076334              0.019734             -0.027781   \n",
       "294815              0.033631              0.029964             -0.045013   \n",
       "396371              0.027117             -0.037116              0.018932   \n",
       "\n",
       "        comment_embedding_377 comment_embedding_378 comment_embedding_379  \\\n",
       "327020               0.010823              0.041533              0.011691   \n",
       "79084                0.013807              0.049898             -0.020697   \n",
       "113978              -0.010329              0.025568              0.069839   \n",
       "169334              -0.018733              0.008588              0.100716   \n",
       "168345              -0.060949              0.036342              0.062206   \n",
       "...                       ...                   ...                   ...   \n",
       "384193               0.015655              0.053216             -0.017010   \n",
       "294531               0.022194              0.075792              0.094105   \n",
       "52977               -0.032406              0.052717              0.057844   \n",
       "294815               0.038327              0.025526              0.100794   \n",
       "396371              -0.043876              0.033317             -0.031043   \n",
       "\n",
       "       comment_embedding_380 comment_embedding_381  comment_embedding_382  \\\n",
       "327020             -0.009620              0.029076              -0.088270   \n",
       "79084              -0.041794              0.070709              -0.065858   \n",
       "113978             -0.032196              0.121626              -0.076257   \n",
       "169334             -0.013107              0.004675              -0.086565   \n",
       "168345             -0.082926             -0.028832              -0.103534   \n",
       "...                      ...                   ...                    ...   \n",
       "384193             -0.039557              0.056494              -0.085848   \n",
       "294531             -0.005719             -0.037350              -0.136996   \n",
       "52977               0.030669              0.063396              -0.058295   \n",
       "294815              0.028082              0.017888              -0.078899   \n",
       "396371              0.066531             -0.037273              -0.032762   \n",
       "\n",
       "       comment_embedding_383  \n",
       "327020              0.102734  \n",
       "79084              -0.021460  \n",
       "113978              0.003784  \n",
       "169334              0.011032  \n",
       "168345              0.014343  \n",
       "...                      ...  \n",
       "384193             -0.010447  \n",
       "294531              0.003359  \n",
       "52977              -0.025689  \n",
       "294815              0.041347  \n",
       "396371              0.098167  \n",
       "\n",
       "[72447 rows x 405 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7af4a17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Modelling\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_data = train_data.to(device)\n",
    "train_loader = prepare_data_loader(\n",
    "    data=train_data,\n",
    "    batch_size=config[\"train_batch_size\"],\n",
    "    num_neighbours=config[\"train_num_neighbours\"],\n",
    ")\n",
    "test_loader = prepare_data_loader(\n",
    "    data=test_data,\n",
    "    batch_size=config[\"test_batch_size\"],\n",
    "    num_neighbours=config[\"test_num_neighbours\"],\n",
    ")\n",
    "model = Model(hidden_channels=config[\"hidden_channels\"], data=involved_data).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "\n",
    "# Train and Evaluate Loss\n",
    "best_train_loss = float(\"inf\")\n",
    "best_test_loss = float(\"inf\")\n",
    "model_prefix = \"./rating_weighted_models\"\n",
    "for epoch in range(1, config[\"epochs\"] + 1):\n",
    "    model_is_best = False\n",
    "    train_loss = train(model, optimizer, train_loader, device)\n",
    "    test_loss = test(test_loader, device, model)\n",
    "\n",
    "    if train_loss < best_train_loss:\n",
    "        best_train_loss = train_loss\n",
    "\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        model_is_best = True\n",
    "        \n",
    "    metrics_dict = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"test_loss\": test_loss,\n",
    "        \"epoch\": epoch,\n",
    "    }\n",
    "    wandb.log(metrics_dict)\n",
    "    logger.info(\n",
    "        f\"Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f} \"\n",
    "    )\n",
    "    \n",
    "    model_path = f\"{model_prefix}/{epoch}_model_state_dict.pt\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    model_art = wandb.Artifact(f\"{MODEL_NAME}_epoch_epoch\", type=\"model\")\n",
    "    model_art.add_file(model_path)\n",
    "    wandb.log_artifact(\n",
    "        model_art,\n",
    "        aliases=[\n",
    "            \"BEST\",\n",
    "        ]\n",
    "        if model_is_best\n",
    "        else None,\n",
    "    )\n",
    "        \n",
    "logger.info(\"End of Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f481d7b5",
   "metadata": {},
   "source": [
    "## Check ground truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7925981f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    72447.000000\n",
       "mean         1.020304\n",
       "std          0.154582\n",
       "min          1.000000\n",
       "25%          1.000000\n",
       "50%          1.000000\n",
       "75%          1.000000\n",
       "max          6.000000\n",
       "Name: reviewer_id, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_reviews['reviewer_id'].value_counts().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecc7b2e",
   "metadata": {},
   "source": [
    "## Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d6e41bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Any, List, Optional, Union\n",
    "\n",
    "import torch\n",
    "from torch.jit import ScriptModule\n",
    "from torch.nn import Module\n",
    "\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.typing import SparseTensor\n",
    "\n",
    "\n",
    "def summary(\n",
    "    model: torch.nn.Module,\n",
    "    *args,\n",
    "    max_depth: int = 3,\n",
    "    leaf_module: Optional[Union[Module, List[Module]]] = 'MessagePassing',\n",
    "    **kwargs,\n",
    ") -> str:\n",
    "    r\"\"\"Summarizes a given :class:`torch.nn.Module`.\n",
    "    The summarized information includes (1) layer names, (2) input and output\n",
    "    shapes, and (3) the number of parameters.\n",
    "\n",
    "    .. code-block:: python\n",
    "\n",
    "        import torch\n",
    "        from torch_geometric.nn import GCN, summary\n",
    "\n",
    "        model = GCN(128, 64, num_layers=2, out_channels=32)\n",
    "        x = torch.randn(100, 128)\n",
    "        edge_index = torch.randint(100, size=(2, 20))\n",
    "\n",
    "        print(summary(model, x, edge_index))\n",
    "\n",
    "    .. code-block::\n",
    "\n",
    "        +---------------------+---------------------+--------------+--------+\n",
    "        | Layer               | Input Shape         | Output Shape | #Param |\n",
    "        |---------------------+---------------------+--------------+--------|\n",
    "        | GCN                 | [100, 128], [2, 20] | [100, 32]    | 10,336 |\n",
    "        | ├─(act)ReLU         | [100, 64]           | [100, 64]    | --     |\n",
    "        | ├─(convs)ModuleList | --                  | --           | 10,336 |\n",
    "        | │    └─(0)GCNConv   | [100, 128], [2, 20] | [100, 64]    | 8,256  |\n",
    "        | │    └─(1)GCNConv   | [100, 64], [2, 20]  | [100, 32]    | 2,080  |\n",
    "        +---------------------+---------------------+--------------+--------+\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to summarize.\n",
    "        *args: The arguments of the :obj:`model`.\n",
    "        max_depth (int, optional): The depth of nested layers to display.\n",
    "            Any layers deeper than this depth will not be displayed in the\n",
    "            summary. (default: :obj:`3`)\n",
    "        leaf_module (torch.nn.Module or [torch.nn.Module], optional): The\n",
    "            modules to be treated as leaf modules, whose submodules are\n",
    "            excluded from the summary.\n",
    "            (default: :class:`~torch_geometric.nn.conv.MessagePassing`)\n",
    "        **kwargs: Additional arguments of the :obj:`model`.\n",
    "    \"\"\"\n",
    "    # NOTE This is just for the doc-string to render nicely:\n",
    "    if leaf_module == 'MessagePassing':\n",
    "        leaf_module = MessagePassing\n",
    "\n",
    "    def register_hook(info):\n",
    "        def hook(module, inputs, output):\n",
    "            info['input_shape'].append(get_shape(inputs))\n",
    "            info['output_shape'].append(get_shape(output))\n",
    "\n",
    "        return hook\n",
    "\n",
    "    hooks = {}\n",
    "    depth = 0\n",
    "    stack = [(model.__class__.__name__, model, depth)]\n",
    "\n",
    "    info_list = []\n",
    "    input_shape = defaultdict(list)\n",
    "    output_shape = defaultdict(list)\n",
    "    while stack:\n",
    "        name, module, depth = stack.pop()\n",
    "        module_id = id(module)\n",
    "\n",
    "        if name.startswith('(_'):  # Do not summarize private modules.\n",
    "            continue\n",
    "\n",
    "        if module_id in hooks:  # Avoid duplicated hooks.\n",
    "            hooks[module_id].remove()\n",
    "\n",
    "        info = {}\n",
    "        info['name'] = name\n",
    "        info['input_shape'] = input_shape[module_id]\n",
    "        info['output_shape'] = output_shape[module_id]\n",
    "        info['depth'] = depth\n",
    "        num_params = sum(p.numel() for p in module.parameters())\n",
    "        info['#param'] = f'{num_params:,}' if num_params > 0 else '--'\n",
    "        info_list.append(info)\n",
    "\n",
    "        if not isinstance(module, ScriptModule):\n",
    "            hooks[module_id] = module.register_forward_hook(\n",
    "                register_hook(info))\n",
    "\n",
    "        if depth >= max_depth:\n",
    "            continue\n",
    "\n",
    "        if (leaf_module is not None and isinstance(module, leaf_module)):\n",
    "            continue\n",
    "\n",
    "        module_items = reversed(module._modules.items())\n",
    "        stack += [(f\"({name}){mod.__class__.__name__}\", mod, depth + 1)\n",
    "                  for name, mod in module_items if mod is not None]\n",
    "\n",
    "    training = model.training\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model(*args, **kwargs)\n",
    "\n",
    "    model.train(training)\n",
    "\n",
    "    for h in hooks.values():  # Remove hooks.\n",
    "        h.remove()\n",
    "\n",
    "    info_list = postprocess(info_list)\n",
    "    return make_table(info_list, max_depth=max_depth)\n",
    "\n",
    "\n",
    "def get_shape(inputs: Any) -> str:\n",
    "    if not isinstance(inputs, (tuple, list)):\n",
    "        inputs = (inputs, )\n",
    "\n",
    "    out = []\n",
    "    for x in inputs:\n",
    "        if isinstance(x, SparseTensor):\n",
    "            out.append(str(list(x.sizes())))\n",
    "        elif hasattr(x, 'size'):\n",
    "            out.append(str(list(x.size())))\n",
    "    return ', '.join(out)\n",
    "\n",
    "\n",
    "def postprocess(info_list: List[dict]) -> List[dict]:\n",
    "    for idx, info in enumerate(info_list):\n",
    "        depth = info['depth']\n",
    "        if idx > 0:  # root module (0) is exclued\n",
    "            if depth == 1:\n",
    "                prefix = '├─'\n",
    "            else:\n",
    "                prefix = f\"{'│    '*(depth-1)}└─\"\n",
    "            info['name'] = prefix + info['name']\n",
    "\n",
    "        if info['input_shape']:\n",
    "            info['input_shape'] = info['input_shape'].pop(0)\n",
    "            info['output_shape'] = info['output_shape'].pop(0)\n",
    "        else:\n",
    "            info['input_shape'] = '--'\n",
    "            info['output_shape'] = '--'\n",
    "    return info_list\n",
    "\n",
    "\n",
    "def make_table(info_list: List[dict], max_depth: int) -> str:\n",
    "    from tabulate import tabulate\n",
    "    content = [['Layer', 'Input Shape', 'Output Shape', '#Param']]\n",
    "    for info in info_list:\n",
    "        content.append([\n",
    "            info['name'],\n",
    "            info['input_shape'],\n",
    "            info['output_shape'],\n",
    "            info['#param'],\n",
    "        ])\n",
    "    return tabulate(content, headers='firstrow', tablefmt='psql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "463b8ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e01492e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mlisting\u001b[0m={ x=[17229, 158] },\n",
       "  \u001b[1muser\u001b[0m={ x=[324135, 384] },\n",
       "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
       "    edge_index=[2, 334678],\n",
       "    edge_label=[334678],\n",
       "    edge_label_index=[2, 334678]\n",
       "  },\n",
       "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 334678] }\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b2dbe8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (encoder): GraphModule(\n",
      "    (conv1): ModuleDict(\n",
      "      (user__rates__listing): SAGEConv((-1, -1), 64, aggr=mean)\n",
      "      (listing__rev_rates__user): SAGEConv((-1, -1), 64, aggr=mean)\n",
      "    )\n",
      "    (conv2): ModuleDict(\n",
      "      (user__rates__listing): SAGEConv((-1, -1), 64, aggr=mean)\n",
      "      (listing__rev_rates__user): SAGEConv((-1, -1), 64, aggr=mean)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "+------------------------------------------------+---------------+----------------+----------+\n",
      "| Layer                                          | Input Shape   | Output Shape   | #Param   |\n",
      "|------------------------------------------------+---------------+----------------+----------|\n",
      "| Model                                          |               |                | 86,016   |\n",
      "| ├─(encoder)GraphModule                         |               |                | 86,016   |\n",
      "| │    └─(conv1)ModuleDict                       | --            | --             | 69,504   |\n",
      "| │    │    └─(user__rates__listing)SAGEConv     | [2, 919]      | [180, 64]      | 34,752   |\n",
      "| │    │    └─(listing__rev_rates__user)SAGEConv | [2, 983]      | [917, 64]      | 34,752   |\n",
      "| │    └─(conv2)ModuleDict                       | --            | --             | 16,512   |\n",
      "| │    │    └─(user__rates__listing)SAGEConv     | [2, 919]      | [180, 64]      | 8,256    |\n",
      "| │    │    └─(listing__rev_rates__user)SAGEConv | [2, 983]      | [917, 64]      | 8,256    |\n",
      "+------------------------------------------------+---------------+----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "with torch.no_grad():  # Initialize lazy modules.\n",
    "    out = model(batch.x_dict, batch.edge_index_dict)\n",
    "print(model)\n",
    "\n",
    "print(summary(model, batch.x_dict, batch.edge_index_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tt] *",
   "language": "python",
   "name": "conda-env-tt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
