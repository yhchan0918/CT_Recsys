{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d0aebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baaf5704",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 16:30:16.338 | INFO     | __main__:<module>:115 - Start of Retraining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2021-10-24 2022-10-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 16:30:20.589 | INFO     | train_test_split:main_train_val_test:133 - Split df into train and test portion\n",
      "/Users/yhchan/Downloads/FYP/CT_of_recommendation_system/modelling/graphsage/train_test_split.py:168: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1670525682339/work/torch/csrc/utils/tensor_numpy.cpp:205.)\n",
      "  temp = torch.from_numpy(val).view(-1, 1).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 5, 4,  ..., 5, 4, 5])\n",
      "tensor([5, 4, 5,  ..., 5, 5, 4])\n",
      "tensor([5, 5, 5,  ..., 5, 5, 5])\n",
      "tensor([5, 5, 5,  ..., 5, 5, 5])\n",
      "Training Heterogenous Graph HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={ x=[17229, 159] },\n",
      "  \u001b[1muser\u001b[0m={ x=[324135, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 334678],\n",
      "    edge_label=[334678],\n",
      "    edge_label_index=[2, 334678]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 334678] }\n",
      ")\n",
      "Test Heterogenous Graph HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={ x=[14380, 159] },\n",
      "  \u001b[1muser\u001b[0m={ x=[72447, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 73918],\n",
      "    edge_label=[73918],\n",
      "    edge_label_index=[2, 73918]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 73918] }\n",
      ")\n",
      "Test Heterogenous Graph (Cold Start Scenerio) HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={ x=[14254, 159] },\n",
      "  \u001b[1muser\u001b[0m={ x=[70416, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 71775],\n",
      "    edge_label=[71775],\n",
      "    edge_label_index=[2, 71775]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 71775] }\n",
      ")\n",
      "{'num_reviews': 408596, 'num_train_reviews': 334678, 'num_test_reviews': 73918, 'num_cold_start_test_reviews': 71775, 'num_unique_cold_start_test_listings': 14254, 'num_unique_cold_start_test_reviewers': 70416, 'num_unique_train_listings': 17229, 'num_unique_test_listings': 14380, 'num_unique_train_reviewers': 324135, 'num_unique_test_reviewers': 72447}\n"
     ]
    }
   ],
   "source": [
    "#model.py\n",
    "import torch\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "\n",
    "\n",
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        # Mean pooling, by default\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, data):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
    "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr=\"sum\")\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        # Node embedding here\n",
    "        return self.encoder(x_dict, edge_index_dict)\n",
    "\n",
    "    def inference(self, x_dict, edge_index_dict):\n",
    "        return self.encoder(x_dict, edge_index_dict)\n",
    "\n",
    "\n",
    "def prepare_data_loader(\n",
    "    data,\n",
    "    batch_size,\n",
    "    num_neighbours,\n",
    "):\n",
    "    neighbourhood_sampling_loader = NeighborLoader(\n",
    "        data,\n",
    "        batch_size=batch_size,\n",
    "        num_neighbors=num_neighbours,\n",
    "        shuffle=True,\n",
    "        input_nodes=('listing', None)\n",
    "    )\n",
    "    return neighbourhood_sampling_loader\n",
    "\n",
    "\n",
    "def load_model(path, hidden_channels, data):\n",
    "    model = Model(hidden_channels=hidden_channels, data=data).to(\"cpu\")\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    return model\n",
    "\n",
    "#main_train.py\n",
    "import wandb\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "from dateutil.relativedelta import relativedelta  # type: ignore\n",
    "import functools\n",
    "\n",
    "from train_test_split import *\n",
    "from evaluate import *\n",
    "from constants import *\n",
    "\n",
    "\n",
    "def initialize_run():\n",
    "    try:\n",
    "        api = wandb.Api()\n",
    "        runs = api.runs(f\"{ENTITY_NAME}/{PROJECT_NAME}\")\n",
    "        if len(runs) == 0:\n",
    "            raise Exception(\"No runs\")\n",
    "        last_iteration = float(\"-inf\")\n",
    "        end_date_of_last_iteration = None\n",
    "\n",
    "        for run in runs:\n",
    "            config = {k: v for k, v in run.config.items() if not k.startswith(\"_\")}\n",
    "            run_name = run.name\n",
    "            iteration_no = int(run_name.split(\"_\")[1])\n",
    "            if iteration_no > last_iteration:\n",
    "                last_iteration = iteration_no\n",
    "                end_date_of_last_iteration = config[\"end_date\"]\n",
    "\n",
    "        current_iteration = last_iteration + 1\n",
    "        current_start_date = dt.strptime(\n",
    "            end_date_of_last_iteration, \"%Y-%m-%d\"\n",
    "        ).date() + relativedelta(days=1)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        current_iteration = 0\n",
    "        current_start_date = dt.strptime(SIMULATION_START_DATE, \"%Y-%m-%d\").date()\n",
    "\n",
    "    return current_iteration, current_start_date\n",
    "\n",
    "\n",
    "def filter_test_data_by_scenario(train_reviews, test_reviews, user_col, scenario_type):\n",
    "    if scenario_type == \"cold_start_new_user\":\n",
    "        train_reviewers = list(train_reviews[user_col].unique())\n",
    "        return test_reviews[~test_reviews[user_col].isin(train_reviewers)]\n",
    "\n",
    "\n",
    "def get_nunique(df, col):\n",
    "    return df[col].nunique()\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "start_date = dt.strptime(\"2021-10-24\", \"%Y-%m-%d\").date()\n",
    "if start_date == dt.strptime(MAX_START_DATE, \"%Y-%m-%d\").date():\n",
    "    raise Exception(\"Stop Simulation\")\n",
    "end_date, nxt_start_date = split_date_by_period_months(start_date, TOTAL_MONTHS_PER_ITERATION)\n",
    "\n",
    "logger.info(\"Start of Retraining\")\n",
    "print(iteration)\n",
    "print(start_date, end_date)\n",
    "directory = \"/Users/yhchan/Downloads/FYP/data/processed\"\n",
    "reviews = pd.read_parquet(f\"{directory}/reviews_with_interactions.parquet\")\n",
    "listings = pd.read_parquet(f\"{directory}/listings_with_interactions.parquet\")\n",
    "reviewers = pd.read_parquet(f\"{directory}/reviewers_with_interactions.parquet\")\n",
    "\n",
    "\n",
    "config={\n",
    "    \"architecture\": \"Unsupervised GraphSAGE\",\n",
    "    \"iteration\": iteration,\n",
    "    \"start_date\": start_date,\n",
    "    \"end_date\": end_date,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"hidden_channels\": 64,\n",
    "    \"train_batch_size\": 128,\n",
    "    \"test_batch_size\": 128,\n",
    "    \"epochs\": 100,\n",
    "    \"train_num_neighbours\": [10, 10],\n",
    "    \"test_num_neighbours\": [-1],  # So no sampling happens\n",
    "    \"train_split_period_months\": TRAIN_SPLIT_PERIOD_MONTHS,\n",
    "    \"total_months_of_data\": TOTAL_MONTHS_PER_ITERATION,\n",
    "}\n",
    "\n",
    "\n",
    "# Split into train, test and test for cold start scenario\n",
    "(\n",
    "    train_reviews,\n",
    "    train_listings,\n",
    "    train_reviewers,\n",
    "    test_reviews,\n",
    "    test_listings,\n",
    "    test_reviewers,\n",
    ") = main_train_val_test(\n",
    "    reviews,\n",
    "    listings,\n",
    "    reviewers,\n",
    "    start_date,\n",
    "    end_date,\n",
    "    config[\"train_split_period_months\"],\n",
    ")\n",
    "cold_start_test_reviews = filter_test_data_by_scenario(\n",
    "    train_reviews, test_reviews, \"reviewer_id\", \"cold_start_new_user\"\n",
    ")\n",
    "cold_start_test_listings, cold_start_test_reviewers = build_partitioned_data(\n",
    "    cold_start_test_reviews, listings, reviewers\n",
    ")\n",
    "\n",
    "def build_heterograph(reviews, listings, include_rating_as_edge_label=False):\n",
    "\n",
    "    listing_features_cols = FEATURE_COLS[\"features_cols\"]\n",
    "\n",
    "    # Convert data type\n",
    "    for col in listings[listing_features_cols].select_dtypes(include=[\"bool\"]):\n",
    "        listings[col] = listings[col].astype(\"category\")\n",
    "\n",
    "    user_x, user_mapping = load_node_from_df(reviews, index_col=\"reviewer_id\")\n",
    "    listing_x, listing_mapping = load_node_from_df(\n",
    "        listings, index_col=\"listing_id\", features_cols=listing_features_cols\n",
    "    )\n",
    "    edge_index, edge_label = load_edge_from_df(\n",
    "        reviews,\n",
    "        src_index_col=\"reviewer_id\",\n",
    "        src_mapping=user_mapping,\n",
    "        dst_index_col=\"listing_id\",\n",
    "        dst_mapping=listing_mapping,\n",
    "        encoders={\"rating\": IdentityEncoder(dtype=torch.long)},\n",
    "    )\n",
    "\n",
    "    data = HeteroData()\n",
    "    num_user_nodes = len(user_mapping)\n",
    "    print(edge_label)\n",
    "    data[\"listing\"].x = listing_x\n",
    "    data[\"user\"].x = torch.arange(num_user_nodes).view(num_user_nodes, 1).to(torch.float32)\n",
    "    data[\"user\", \"rates\", \"listing\"].edge_index = edge_index\n",
    "    if include_rating_as_edge_label:\n",
    "        data[\"user\", \"rates\", \"listing\"].edge_label = edge_label\n",
    "        data[\"user\", \"rates\", \"listing\"].edge_label_index = edge_index\n",
    "    # We can now convert `data` into an appropriate format for training a\n",
    "    # graph-based machine learning model:\n",
    "\n",
    "    # 1. Add a reverse ('listing', 'rev_rates', 'user') relation for message passing.\n",
    "    data = ToUndirected()(data)\n",
    "    del data[\"listing\", \"rev_rates\", \"user\"].edge_label  # Remove \"reverse\" label.\n",
    "    return data\n",
    "\n",
    "# Build idx to id dict and reverse version of it\n",
    "test_listings2dict = get_entity2dict(test_listings, \"listing_id\")\n",
    "reverse_test_listings2dict = {k: v for v, k in test_listings2dict.items()}\n",
    "test_reviewers2dict = get_entity2dict(test_reviewers, \"reviewer_id\")\n",
    "reverse_test_reviewers2dict = {k: v for v, k in test_reviewers2dict.items()}\n",
    "cold_start_test_listings2dict = get_entity2dict(cold_start_test_listings, \"listing_id\")\n",
    "reverse_cold_start_test_listings2dict = {k: v for v, k in cold_start_test_listings2dict.items()}\n",
    "cold_start_test_reviewers2dict = get_entity2dict(cold_start_test_reviewers, \"reviewer_id\")\n",
    "reverse_cold_start_test_reviewers2dict = {\n",
    "    k: v for v, k in cold_start_test_reviewers2dict.items()\n",
    "}\n",
    "\n",
    "# Build Graph\n",
    "data = build_heterograph(reviews, listings, True)\n",
    "train_data = build_heterograph(train_reviews, train_listings, True)\n",
    "test_data = build_heterograph(test_reviews, test_listings, True)\n",
    "cold_start_test_data = build_heterograph(cold_start_test_reviews, cold_start_test_listings, True)\n",
    "print(\"Training Heterogenous Graph\", train_data)\n",
    "print(\"Test Heterogenous Graph\", test_data)\n",
    "print(\"Test Heterogenous Graph (Cold Start Scenerio)\", cold_start_test_data)\n",
    "\n",
    "train_loader = prepare_data_loader(\n",
    "    data=train_data,\n",
    "    batch_size=config[\"train_batch_size\"],\n",
    "    num_neighbours=config[\"train_num_neighbours\"],\n",
    ")\n",
    "test_loader = prepare_data_loader(\n",
    "    data=test_data,\n",
    "    batch_size=config[\"test_batch_size\"],\n",
    "    num_neighbours=config[\"test_num_neighbours\"],\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_data = train_data.to(device)\n",
    "\n",
    "train_test_data_dict = {\n",
    "    \"num_reviews\": len(train_reviews) + len(test_reviews),\n",
    "    \"num_train_reviews\": len(train_reviews),\n",
    "    \"num_test_reviews\": len(test_reviews),\n",
    "    \"num_cold_start_test_reviews\": len(cold_start_test_reviews),\n",
    "    \"num_unique_cold_start_test_listings\": get_nunique(cold_start_test_reviews, \"listing_id\"),\n",
    "    \"num_unique_cold_start_test_reviewers\": get_nunique(cold_start_test_reviews, \"reviewer_id\"),\n",
    "    \"num_unique_train_listings\": get_nunique(train_listings, \"listing_id\"),\n",
    "    \"num_unique_test_listings\": get_nunique(test_listings, \"listing_id\"),\n",
    "    \"num_unique_train_reviewers\": get_nunique(train_reviewers, \"reviewer_id\"),\n",
    "    \"num_unique_test_reviewers\": get_nunique(test_reviewers, \"reviewer_id\"),\n",
    "}\n",
    "train_reviews.to_parquet(\"train/train_reviews.parquet\", index=False)\n",
    "train_listings.to_parquet(\"train/train_listings.parquet\", index=False)\n",
    "train_reviewers.to_parquet(\"train/train_reviewers.parquet\", index=False)\n",
    "test_reviews.to_parquet(\"test/test_reviews.parquet\", index=False)\n",
    "test_listings.to_parquet(\"test/test_listings.parquet\", index=False)\n",
    "test_reviewers.to_parquet(\"test/test_reviewers.parquet\", index=False)\n",
    "cold_start_test_reviews.to_parquet(\"test/cold_start_test_reviews.parquet\", index=False)\n",
    "cold_start_test_listings.to_parquet(\"test/cold_start_test_listings.parquet\", index=False)\n",
    "cold_start_test_reviewers.to_parquet(\"test/cold_start_test_reviewers.parquet\", index=False)\n",
    "\n",
    "print(train_test_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f55522b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b\n",
       "0  2  1\n",
       "1  2  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "a = [{\"a\":2 ,\"b\":1},{\"a\":2 ,\"b\":1}]\n",
    "pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "e7af4a17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 19:58:43.795 | INFO     | __main__:<module>:133 - Epoch: 001, Train Loss: 0.6289, Test Loss: 0.6297 \n",
      "2023-04-01 19:59:03.103 | INFO     | __main__:<module>:133 - Epoch: 002, Train Loss: 0.6299, Test Loss: 0.6305 \n",
      "2023-04-01 19:59:22.439 | INFO     | __main__:<module>:133 - Epoch: 003, Train Loss: 0.6286, Test Loss: 0.6297 \n",
      "2023-04-01 19:59:41.468 | INFO     | __main__:<module>:133 - Epoch: 004, Train Loss: 0.6283, Test Loss: 0.6294 \n",
      "2023-04-01 20:00:00.604 | INFO     | __main__:<module>:133 - Epoch: 005, Train Loss: 0.6284, Test Loss: 0.6298 \n",
      "2023-04-01 20:00:19.838 | INFO     | __main__:<module>:133 - Epoch: 006, Train Loss: 0.6279, Test Loss: 0.6309 \n",
      "2023-04-01 20:00:38.884 | INFO     | __main__:<module>:133 - Epoch: 007, Train Loss: 0.6276, Test Loss: 0.6369 \n",
      "2023-04-01 20:00:57.997 | INFO     | __main__:<module>:133 - Epoch: 008, Train Loss: 0.6271, Test Loss: 0.6475 \n",
      "2023-04-01 20:01:17.191 | INFO     | __main__:<module>:133 - Epoch: 009, Train Loss: 0.6277, Test Loss: 0.6361 \n",
      "2023-04-01 20:01:36.497 | INFO     | __main__:<module>:133 - Epoch: 010, Train Loss: 0.6277, Test Loss: 0.6406 \n",
      "2023-04-01 20:01:55.500 | INFO     | __main__:<module>:133 - Epoch: 011, Train Loss: 0.6269, Test Loss: 0.6564 \n",
      "2023-04-01 20:02:14.535 | INFO     | __main__:<module>:133 - Epoch: 012, Train Loss: 0.6269, Test Loss: 0.6404 \n",
      "2023-04-01 20:02:33.743 | INFO     | __main__:<module>:133 - Epoch: 013, Train Loss: 0.6272, Test Loss: 0.6486 \n",
      "2023-04-01 20:02:52.785 | INFO     | __main__:<module>:133 - Epoch: 014, Train Loss: 0.6262, Test Loss: 0.7099 \n",
      "2023-04-01 20:03:11.812 | INFO     | __main__:<module>:133 - Epoch: 015, Train Loss: 0.6264, Test Loss: 0.6723 \n",
      "2023-04-01 20:03:32.835 | INFO     | __main__:<module>:133 - Epoch: 016, Train Loss: 0.6258, Test Loss: 0.6841 \n",
      "2023-04-01 20:03:54.962 | INFO     | __main__:<module>:133 - Epoch: 017, Train Loss: 0.6259, Test Loss: 0.6844 \n",
      "2023-04-01 20:04:17.478 | INFO     | __main__:<module>:133 - Epoch: 018, Train Loss: 0.6253, Test Loss: 0.6606 \n",
      "2023-04-01 20:04:37.277 | INFO     | __main__:<module>:133 - Epoch: 019, Train Loss: 0.6262, Test Loss: 0.6663 \n",
      "2023-04-01 20:04:57.477 | INFO     | __main__:<module>:133 - Epoch: 020, Train Loss: 0.6256, Test Loss: 0.6759 \n",
      "2023-04-01 20:05:18.489 | INFO     | __main__:<module>:133 - Epoch: 021, Train Loss: 0.6248, Test Loss: 0.7150 \n",
      "2023-04-01 20:05:40.714 | INFO     | __main__:<module>:133 - Epoch: 022, Train Loss: 0.6257, Test Loss: 0.6922 \n",
      "2023-04-01 20:05:59.881 | INFO     | __main__:<module>:133 - Epoch: 023, Train Loss: 0.6244, Test Loss: 0.6830 \n",
      "2023-04-01 20:06:21.843 | INFO     | __main__:<module>:133 - Epoch: 024, Train Loss: 0.6247, Test Loss: 0.6882 \n",
      "2023-04-01 20:06:45.028 | INFO     | __main__:<module>:133 - Epoch: 025, Train Loss: 0.6243, Test Loss: 0.6715 \n",
      "2023-04-01 20:07:06.650 | INFO     | __main__:<module>:133 - Epoch: 026, Train Loss: 0.6222, Test Loss: 0.6910 \n",
      "2023-04-01 20:07:29.235 | INFO     | __main__:<module>:133 - Epoch: 027, Train Loss: 0.6225, Test Loss: 0.6923 \n",
      "2023-04-01 20:07:48.607 | INFO     | __main__:<module>:133 - Epoch: 028, Train Loss: 0.6221, Test Loss: 0.7498 \n",
      "2023-04-01 20:08:07.658 | INFO     | __main__:<module>:133 - Epoch: 029, Train Loss: 0.6209, Test Loss: 0.7854 \n",
      "2023-04-01 20:08:26.751 | INFO     | __main__:<module>:133 - Epoch: 030, Train Loss: 0.6195, Test Loss: 0.7681 \n",
      "2023-04-01 20:08:45.751 | INFO     | __main__:<module>:133 - Epoch: 031, Train Loss: 0.6201, Test Loss: 1.0056 \n",
      "2023-04-01 20:09:04.805 | INFO     | __main__:<module>:133 - Epoch: 032, Train Loss: 0.6178, Test Loss: 1.0553 \n",
      "2023-04-01 20:09:23.929 | INFO     | __main__:<module>:133 - Epoch: 033, Train Loss: 0.6147, Test Loss: 1.3194 \n",
      "2023-04-01 20:09:43.012 | INFO     | __main__:<module>:133 - Epoch: 034, Train Loss: 0.6127, Test Loss: 1.1401 \n",
      "2023-04-01 20:10:02.139 | INFO     | __main__:<module>:133 - Epoch: 035, Train Loss: 0.6139, Test Loss: 1.0954 \n",
      "2023-04-01 20:10:21.313 | INFO     | __main__:<module>:133 - Epoch: 036, Train Loss: 0.6107, Test Loss: 1.3141 \n",
      "2023-04-01 20:10:40.342 | INFO     | __main__:<module>:133 - Epoch: 037, Train Loss: 0.6128, Test Loss: 1.5246 \n",
      "2023-04-01 20:10:59.415 | INFO     | __main__:<module>:133 - Epoch: 038, Train Loss: 0.6093, Test Loss: 1.6574 \n",
      "2023-04-01 20:11:18.519 | INFO     | __main__:<module>:133 - Epoch: 039, Train Loss: 0.6074, Test Loss: 1.5136 \n",
      "2023-04-01 20:11:37.519 | INFO     | __main__:<module>:133 - Epoch: 040, Train Loss: 0.6040, Test Loss: 1.1458 \n",
      "2023-04-01 20:11:56.566 | INFO     | __main__:<module>:133 - Epoch: 041, Train Loss: 0.6050, Test Loss: 1.2886 \n",
      "2023-04-01 20:12:15.613 | INFO     | __main__:<module>:133 - Epoch: 042, Train Loss: 0.6046, Test Loss: 1.8962 \n",
      "2023-04-01 20:12:34.669 | INFO     | __main__:<module>:133 - Epoch: 043, Train Loss: 0.6047, Test Loss: 1.7329 \n",
      "2023-04-01 20:12:53.730 | INFO     | __main__:<module>:133 - Epoch: 044, Train Loss: 0.6112, Test Loss: 1.5914 \n",
      "2023-04-01 20:13:12.734 | INFO     | __main__:<module>:133 - Epoch: 045, Train Loss: 0.6139, Test Loss: 1.0277 \n",
      "2023-04-01 20:13:31.882 | INFO     | __main__:<module>:133 - Epoch: 046, Train Loss: 0.6081, Test Loss: 1.5856 \n",
      "2023-04-01 20:13:50.958 | INFO     | __main__:<module>:133 - Epoch: 047, Train Loss: 0.6192, Test Loss: 1.4238 \n",
      "2023-04-01 20:14:10.118 | INFO     | __main__:<module>:133 - Epoch: 048, Train Loss: 0.6039, Test Loss: 1.3275 \n",
      "2023-04-01 20:14:29.378 | INFO     | __main__:<module>:133 - Epoch: 049, Train Loss: 0.6077, Test Loss: 0.8421 \n",
      "2023-04-01 20:14:48.258 | INFO     | __main__:<module>:133 - Epoch: 050, Train Loss: 0.6136, Test Loss: 1.8162 \n",
      "2023-04-01 20:15:07.266 | INFO     | __main__:<module>:133 - Epoch: 051, Train Loss: 0.6035, Test Loss: 1.3969 \n",
      "2023-04-01 20:15:26.464 | INFO     | __main__:<module>:133 - Epoch: 052, Train Loss: 0.6017, Test Loss: 1.4506 \n",
      "2023-04-01 20:15:45.479 | INFO     | __main__:<module>:133 - Epoch: 053, Train Loss: 0.5958, Test Loss: 1.1300 \n",
      "2023-04-01 20:16:04.506 | INFO     | __main__:<module>:133 - Epoch: 054, Train Loss: 0.5894, Test Loss: 1.3803 \n",
      "2023-04-01 20:16:23.537 | INFO     | __main__:<module>:133 - Epoch: 055, Train Loss: 0.5868, Test Loss: 1.1810 \n",
      "2023-04-01 20:16:42.353 | INFO     | __main__:<module>:133 - Epoch: 056, Train Loss: 0.5847, Test Loss: 1.3008 \n",
      "2023-04-01 20:17:01.578 | INFO     | __main__:<module>:133 - Epoch: 057, Train Loss: 0.5830, Test Loss: 1.0168 \n",
      "2023-04-01 20:17:20.638 | INFO     | __main__:<module>:133 - Epoch: 058, Train Loss: 0.5811, Test Loss: 1.2291 \n",
      "2023-04-01 20:17:39.799 | INFO     | __main__:<module>:133 - Epoch: 059, Train Loss: 0.5780, Test Loss: 1.0420 \n",
      "2023-04-01 20:17:58.857 | INFO     | __main__:<module>:133 - Epoch: 060, Train Loss: 0.5758, Test Loss: 1.2017 \n",
      "2023-04-01 20:18:17.962 | INFO     | __main__:<module>:133 - Epoch: 061, Train Loss: 0.5759, Test Loss: 1.2420 \n",
      "2023-04-01 20:18:37.046 | INFO     | __main__:<module>:133 - Epoch: 062, Train Loss: 0.5712, Test Loss: 1.0658 \n",
      "2023-04-01 20:18:56.051 | INFO     | __main__:<module>:133 - Epoch: 063, Train Loss: 0.5707, Test Loss: 1.1549 \n",
      "2023-04-01 20:19:15.176 | INFO     | __main__:<module>:133 - Epoch: 064, Train Loss: 0.6136, Test Loss: 1.1522 \n",
      "2023-04-01 20:19:34.211 | INFO     | __main__:<module>:133 - Epoch: 065, Train Loss: 0.6022, Test Loss: 1.3206 \n",
      "2023-04-01 20:19:53.225 | INFO     | __main__:<module>:133 - Epoch: 066, Train Loss: 0.5870, Test Loss: 1.0334 \n",
      "2023-04-01 20:20:12.326 | INFO     | __main__:<module>:133 - Epoch: 067, Train Loss: 0.5796, Test Loss: 1.0397 \n",
      "2023-04-01 20:20:31.341 | INFO     | __main__:<module>:133 - Epoch: 068, Train Loss: 0.5775, Test Loss: 1.0665 \n",
      "2023-04-01 20:20:50.394 | INFO     | __main__:<module>:133 - Epoch: 069, Train Loss: 0.5706, Test Loss: 1.0360 \n",
      "2023-04-01 20:21:09.430 | INFO     | __main__:<module>:133 - Epoch: 070, Train Loss: 0.5646, Test Loss: 1.0751 \n",
      "2023-04-01 20:21:28.598 | INFO     | __main__:<module>:133 - Epoch: 071, Train Loss: 0.5572, Test Loss: 1.0746 \n",
      "2023-04-01 20:21:47.616 | INFO     | __main__:<module>:133 - Epoch: 072, Train Loss: 0.5518, Test Loss: 1.0429 \n",
      "2023-04-01 20:22:06.612 | INFO     | __main__:<module>:133 - Epoch: 073, Train Loss: 0.5495, Test Loss: 1.1015 \n",
      "2023-04-01 20:22:25.663 | INFO     | __main__:<module>:133 - Epoch: 074, Train Loss: 0.5480, Test Loss: 1.0908 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 20:22:44.691 | INFO     | __main__:<module>:133 - Epoch: 075, Train Loss: 0.5445, Test Loss: 1.0079 \n",
      "2023-04-01 20:23:03.712 | INFO     | __main__:<module>:133 - Epoch: 076, Train Loss: 0.5410, Test Loss: 1.0608 \n",
      "2023-04-01 20:23:22.762 | INFO     | __main__:<module>:133 - Epoch: 077, Train Loss: 0.5389, Test Loss: 1.1014 \n",
      "2023-04-01 20:23:41.784 | INFO     | __main__:<module>:133 - Epoch: 078, Train Loss: 0.5383, Test Loss: 1.0186 \n",
      "2023-04-01 20:24:00.766 | INFO     | __main__:<module>:133 - Epoch: 079, Train Loss: 0.5350, Test Loss: 1.0230 \n",
      "2023-04-01 20:24:19.824 | INFO     | __main__:<module>:133 - Epoch: 080, Train Loss: 0.5304, Test Loss: 0.9342 \n",
      "2023-04-01 20:24:38.856 | INFO     | __main__:<module>:133 - Epoch: 081, Train Loss: 0.5337, Test Loss: 0.9360 \n",
      "2023-04-01 20:24:57.869 | INFO     | __main__:<module>:133 - Epoch: 082, Train Loss: 0.5308, Test Loss: 0.9052 \n",
      "2023-04-01 20:25:16.925 | INFO     | __main__:<module>:133 - Epoch: 083, Train Loss: 0.5318, Test Loss: 0.9365 \n",
      "2023-04-01 20:25:36.183 | INFO     | __main__:<module>:133 - Epoch: 084, Train Loss: 0.5254, Test Loss: 1.1010 \n",
      "2023-04-01 20:25:55.605 | INFO     | __main__:<module>:133 - Epoch: 085, Train Loss: 0.5235, Test Loss: 1.0855 \n",
      "2023-04-01 20:26:15.093 | INFO     | __main__:<module>:133 - Epoch: 086, Train Loss: 0.5256, Test Loss: 1.0386 \n",
      "2023-04-01 20:26:34.409 | INFO     | __main__:<module>:133 - Epoch: 087, Train Loss: 0.5199, Test Loss: 0.8964 \n",
      "2023-04-01 20:26:53.969 | INFO     | __main__:<module>:133 - Epoch: 088, Train Loss: 0.5177, Test Loss: 1.0145 \n",
      "2023-04-01 20:27:12.983 | INFO     | __main__:<module>:133 - Epoch: 089, Train Loss: 0.5161, Test Loss: 0.9141 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[402], line 118\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    117\u001b[0m     model_is_best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     test_loss \u001b[38;5;241m=\u001b[39m test_wrapper(model)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m train_loss \u001b[38;5;241m<\u001b[39m best_train_loss:\n",
      "Cell \u001b[0;32mIn[402], line 81\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m rating \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisting\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39medge_label\n\u001b[1;32m     80\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisting\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39medge_index\n\u001b[0;32m---> 81\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtriplet_ranking_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrating\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Compute the loss and its gradients\u001b[39;00m\n\u001b[1;32m     83\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[402], line 23\u001b[0m, in \u001b[0;36mtriplet_ranking_loss\u001b[0;34m(emb, rating, edge_index, batch_size, margin_constant)\u001b[0m\n\u001b[1;32m     21\u001b[0m edge_label_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_nodes):\n\u001b[0;32m---> 23\u001b[0m     adj_dict[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(dst_tensor[\u001b[43msrc_tensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m]\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     24\u001b[0m     edge_label_dict[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(rating[src_tensor \u001b[38;5;241m==\u001b[39m i]\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexclude_elem\u001b[39m(a, b):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torchmetrics.functional import pairwise_cosine_similarity\n",
    "\n",
    "\n",
    "# Modelling\n",
    "model = Model(hidden_channels=config[\"hidden_channels\"], data=data).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "\n",
    "def triplet_ranking_loss(emb, rating, edge_index, batch_size, margin_constant=0.1):\n",
    "    # Compute pairwise cosine similarity between user embedding and listing embedding\n",
    "    cosine_similarity_matrix = pairwise_cosine_similarity(emb[\"user\"], emb[\"listing\"][:batch_size])\n",
    "    # Sample adjacency matrix (binary) represented by two tensors\n",
    "    src_tensor = edge_index[0]\n",
    "    dst_tensor = edge_index[1]\n",
    "    max_listing_idx = dst_tensor.max()\n",
    "    # Number of nodes\n",
    "    n_nodes = max(src_tensor.max(), max_listing_idx) + 1\n",
    "\n",
    "    # Convert adjacency matrix to dictionary\n",
    "    adj_dict = {}\n",
    "    edge_label_dict = {}\n",
    "    for i in range(n_nodes):\n",
    "        adj_dict[i] = list(dst_tensor[src_tensor == i].numpy())\n",
    "        edge_label_dict[i] = list(rating[src_tensor == i].numpy())\n",
    "\n",
    "    def exclude_elem(a, b):\n",
    "        mask = torch.ones_like(b, dtype=torch.bool)\n",
    "        mask[a] = 0\n",
    "        return torch.masked_select(b, mask)\n",
    "\n",
    "    listing_indices = torch.arange(max_listing_idx + 1)\n",
    "    hardest_pos_sims = []\n",
    "    hardest_neg_sims = []\n",
    "    ratings = []\n",
    "    for i in adj_dict:\n",
    "        pos_idx = torch.tensor(adj_dict[i])\n",
    "        neg_idx = exclude_elem(pos_idx, listing_indices)\n",
    "        # If there are no negative examples, skip this user\n",
    "        if len(neg_idx) == 0:\n",
    "            continue\n",
    "\n",
    "        # Retrieve distance between the positive and negative examples\n",
    "        pos_sim = cosine_similarity_matrix[i, pos_idx]\n",
    "        neg_sim = cosine_similarity_matrix[i, neg_idx]\n",
    "        # Select the hardest negative example and hardest postive example\n",
    "        hardest_pos_idx = torch.argmin(pos_sim)\n",
    "        hardest_pos_sim = pos_sim[hardest_pos_idx]\n",
    "        pos_rating = torch.tensor(edge_label_dict[i])[hardest_pos_idx]\n",
    "        hardest_neg_idx = torch.argmax(neg_sim)\n",
    "        hardest_neg_sim = neg_sim[hardest_neg_idx]\n",
    "        hardest_pos_sims.append(hardest_pos_sim)\n",
    "        hardest_neg_sims.append(hardest_neg_sim)\n",
    "        ratings.append(pos_rating)\n",
    "\n",
    "    hardest_pos_sims = torch.stack(hardest_pos_sims, dim=0)\n",
    "    hardest_neg_sims = torch.stack(hardest_neg_sims, dim=0)    \n",
    "    ratings = torch.stack(ratings, dim=0)\n",
    "    m = ratings * margin_constant\n",
    "\n",
    "    # Combine most disimilar s(a, p) and most similar s(a, n) into final triplet loss\n",
    "    triplet_loss = torch.maximum(torch.zeros(m.size()), - hardest_pos_sims + hardest_neg_sims + m)\n",
    "    return triplet_loss.mean()\n",
    "\n",
    "def train():\n",
    "    model.train(True)\n",
    "    total_examples = total_loss = 0\n",
    "    # Why using mini-batch gradient descent\n",
    "    # Update NN multiple times every epoch, Make more precise update to the parameters by calculating the average loss in each step\n",
    "    # Reduce overall training time and num of required epochs for reaching convergence, computational efficiency\n",
    "    i = 0\n",
    "    n_samples = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        # Zero gradients for every batch\n",
    "        optimizer.zero_grad()\n",
    "        # Make predictions for this batch\n",
    "        emb = model(batch.x_dict, batch.edge_index_dict)\n",
    "        batch_size = batch['listing'].batch_size\n",
    "        rating = batch[\"user\", \"listing\"].edge_label\n",
    "        edge_index = batch[\"user\", \"listing\"].edge_index\n",
    "        loss = triplet_ranking_loss(emb, rating, edge_index, batch_size)\n",
    "        # Compute the loss and its gradients\n",
    "        loss.backward()\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * batch_size\n",
    "        total_examples += batch_size\n",
    "\n",
    "    train_loss = total_loss / total_examples\n",
    "    return train_loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(test_data_loader, test_data, model):\n",
    "    model.eval()\n",
    "    total_examples = total_loss = 0\n",
    "    for batch in test_data_loader:\n",
    "        batch = batch.to(device)\n",
    "        # Make predictions for this batch\n",
    "        emb = model(batch.x_dict, batch.edge_index_dict)\n",
    "        batch_size = batch['listing'].batch_size\n",
    "        rating = batch[\"user\", \"listing\"].edge_label\n",
    "        edge_index = batch[\"user\", \"listing\"].edge_index\n",
    "        loss = triplet_ranking_loss(emb, rating, edge_index, batch_size)\n",
    "        total_loss += float(loss) * batch_size\n",
    "        total_examples += batch_size\n",
    "        \n",
    "    test_loss = total_loss / total_examples\n",
    "    return test_loss\n",
    "\n",
    "best_train_loss = float(\"inf\")\n",
    "best_test_loss = float(\"inf\")\n",
    "best_model_path = None\n",
    "# Train and Evaluate Loss\n",
    "test_wrapper = functools.partial(test, test_loader, test_data)\n",
    "\n",
    "for epoch in range(1, config[\"epochs\"] + 1):\n",
    "    model_is_best = False\n",
    "    train_loss = train()\n",
    "    test_loss = test_wrapper(model)\n",
    "\n",
    "    if train_loss < best_train_loss:\n",
    "        best_train_loss = train_loss\n",
    "\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        model_is_best = True\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"test_loss\": test_loss,\n",
    "        \"epoch\": epoch,\n",
    "    }\n",
    "    logger.info(\n",
    "        f\"Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f} \"\n",
    "    )\n",
    "\n",
    "logger.info(\"End of Retraining\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "66e3f1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334678"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "92da5b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[164, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[940, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 945],\n",
      "    edge_label=[945],\n",
      "    edge_label_index=[2, 945]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 987] }\n",
      ")\n",
      "tensor([[  0,   1,   2,  ..., 937, 938, 939],\n",
      "        [  0,   0,   0,  ..., 127, 127, 127]])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "edge_index = batch[\"user\", \"listing\"].edge_index\n",
    "print(batch)\n",
    "print((edge_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "2c69670a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   2,  ..., 937, 938, 939],\n",
       "        [  0,   0,   0,  ..., 127, 127, 127]])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "bf45b47d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "cda69fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6335, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "930d5351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "940"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "25f33599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [5],\n",
       " 1: [5],\n",
       " 2: [5],\n",
       " 3: [5],\n",
       " 4: [5],\n",
       " 5: [5],\n",
       " 6: [5],\n",
       " 7: [5],\n",
       " 8: [5],\n",
       " 9: [5],\n",
       " 10: [5],\n",
       " 11: [5],\n",
       " 12: [5],\n",
       " 13: [5],\n",
       " 14: [5],\n",
       " 15: [5],\n",
       " 16: [5],\n",
       " 17: [5],\n",
       " 18: [5],\n",
       " 19: [5],\n",
       " 20: [5],\n",
       " 21: [5],\n",
       " 22: [4],\n",
       " 23: [5],\n",
       " 24: [5],\n",
       " 25: [5],\n",
       " 26: [5],\n",
       " 27: [5],\n",
       " 28: [5],\n",
       " 29: [5],\n",
       " 30: [5],\n",
       " 31: [5],\n",
       " 32: [5],\n",
       " 33: [4],\n",
       " 34: [4],\n",
       " 35: [5],\n",
       " 36: [5],\n",
       " 37: [5],\n",
       " 38: [5],\n",
       " 39: [5],\n",
       " 40: [5],\n",
       " 41: [5],\n",
       " 42: [4],\n",
       " 43: [5],\n",
       " 44: [5],\n",
       " 45: [5],\n",
       " 46: [5],\n",
       " 47: [5],\n",
       " 48: [5],\n",
       " 49: [5],\n",
       " 50: [4],\n",
       " 51: [5],\n",
       " 52: [5],\n",
       " 53: [5],\n",
       " 54: [5],\n",
       " 55: [5, 5],\n",
       " 56: [5],\n",
       " 57: [5],\n",
       " 58: [5],\n",
       " 59: [5],\n",
       " 60: [5],\n",
       " 61: [5],\n",
       " 62: [5],\n",
       " 63: [5],\n",
       " 64: [5],\n",
       " 65: [5],\n",
       " 66: [5],\n",
       " 67: [5],\n",
       " 68: [5],\n",
       " 69: [5],\n",
       " 70: [3],\n",
       " 71: [5],\n",
       " 72: [5],\n",
       " 73: [5],\n",
       " 74: [5],\n",
       " 75: [4],\n",
       " 76: [5],\n",
       " 77: [5],\n",
       " 78: [4],\n",
       " 79: [4],\n",
       " 80: [5],\n",
       " 81: [5],\n",
       " 82: [5],\n",
       " 83: [5],\n",
       " 84: [5],\n",
       " 85: [5],\n",
       " 86: [5],\n",
       " 87: [4],\n",
       " 88: [5],\n",
       " 89: [5],\n",
       " 90: [5],\n",
       " 91: [5],\n",
       " 92: [5],\n",
       " 93: [5],\n",
       " 94: [5],\n",
       " 95: [5],\n",
       " 96: [5],\n",
       " 97: [5],\n",
       " 98: [5],\n",
       " 99: [5],\n",
       " 100: [5],\n",
       " 101: [5],\n",
       " 102: [5],\n",
       " 103: [5],\n",
       " 104: [5],\n",
       " 105: [5],\n",
       " 106: [5],\n",
       " 107: [5],\n",
       " 108: [5],\n",
       " 109: [5],\n",
       " 110: [5],\n",
       " 111: [5],\n",
       " 112: [5],\n",
       " 113: [5],\n",
       " 114: [5],\n",
       " 115: [5],\n",
       " 116: [5],\n",
       " 117: [5],\n",
       " 118: [5],\n",
       " 119: [5],\n",
       " 120: [5],\n",
       " 121: [5],\n",
       " 122: [5],\n",
       " 123: [5],\n",
       " 124: [5],\n",
       " 125: [5],\n",
       " 126: [4],\n",
       " 127: [5],\n",
       " 128: [5],\n",
       " 129: [4],\n",
       " 130: [5],\n",
       " 131: [5],\n",
       " 132: [4],\n",
       " 133: [5],\n",
       " 134: [5],\n",
       " 135: [5],\n",
       " 136: [4],\n",
       " 137: [5],\n",
       " 138: [4],\n",
       " 139: [5],\n",
       " 140: [5],\n",
       " 141: [5],\n",
       " 142: [5],\n",
       " 143: [5],\n",
       " 144: [5],\n",
       " 145: [5],\n",
       " 146: [5],\n",
       " 147: [5],\n",
       " 148: [5],\n",
       " 149: [5],\n",
       " 150: [4],\n",
       " 151: [5],\n",
       " 152: [5],\n",
       " 153: [5],\n",
       " 154: [5],\n",
       " 155: [5],\n",
       " 156: [5],\n",
       " 157: [5],\n",
       " 158: [5],\n",
       " 159: [5],\n",
       " 160: [5],\n",
       " 161: [5],\n",
       " 162: [4],\n",
       " 163: [5],\n",
       " 164: [5],\n",
       " 165: [5],\n",
       " 166: [3],\n",
       " 167: [4],\n",
       " 168: [3],\n",
       " 169: [5],\n",
       " 170: [5],\n",
       " 171: [5],\n",
       " 172: [5],\n",
       " 173: [4],\n",
       " 174: [5],\n",
       " 175: [5],\n",
       " 176: [5],\n",
       " 177: [5],\n",
       " 178: [5],\n",
       " 179: [5],\n",
       " 180: [5],\n",
       " 181: [5],\n",
       " 182: [4],\n",
       " 183: [5],\n",
       " 184: [5],\n",
       " 185: [5],\n",
       " 186: [5],\n",
       " 187: [5],\n",
       " 188: [5],\n",
       " 189: [5],\n",
       " 190: [3],\n",
       " 191: [5],\n",
       " 192: [5],\n",
       " 193: [5],\n",
       " 194: [5],\n",
       " 195: [4],\n",
       " 196: [5],\n",
       " 197: [4],\n",
       " 198: [4],\n",
       " 199: [4],\n",
       " 200: [5],\n",
       " 201: [5],\n",
       " 202: [4],\n",
       " 203: [5],\n",
       " 204: [5],\n",
       " 205: [5],\n",
       " 206: [5],\n",
       " 207: [5],\n",
       " 208: [5],\n",
       " 209: [5],\n",
       " 210: [5],\n",
       " 211: [5],\n",
       " 212: [5],\n",
       " 213: [5],\n",
       " 214: [5],\n",
       " 215: [5],\n",
       " 216: [5],\n",
       " 217: [5],\n",
       " 218: [5],\n",
       " 219: [2],\n",
       " 220: [5],\n",
       " 221: [5],\n",
       " 222: [5],\n",
       " 223: [5],\n",
       " 224: [5],\n",
       " 225: [5],\n",
       " 226: [5],\n",
       " 227: [5],\n",
       " 228: [5],\n",
       " 229: [5],\n",
       " 230: [5],\n",
       " 231: [5],\n",
       " 232: [5],\n",
       " 233: [5],\n",
       " 234: [5],\n",
       " 235: [5],\n",
       " 236: [5],\n",
       " 237: [4],\n",
       " 238: [5],\n",
       " 239: [5],\n",
       " 240: [5],\n",
       " 241: [5],\n",
       " 242: [4],\n",
       " 243: [5],\n",
       " 244: [5],\n",
       " 245: [5],\n",
       " 246: [5],\n",
       " 247: [5],\n",
       " 248: [5],\n",
       " 249: [5],\n",
       " 250: [5],\n",
       " 251: [5],\n",
       " 252: [4],\n",
       " 253: [5],\n",
       " 254: [5],\n",
       " 255: [5],\n",
       " 256: [5],\n",
       " 257: [5],\n",
       " 258: [5],\n",
       " 259: [5],\n",
       " 260: [4],\n",
       " 261: [5],\n",
       " 262: [3],\n",
       " 263: [5],\n",
       " 264: [5],\n",
       " 265: [5],\n",
       " 266: [5],\n",
       " 267: [5],\n",
       " 268: [5],\n",
       " 269: [5],\n",
       " 270: [5],\n",
       " 271: [5],\n",
       " 272: [5],\n",
       " 273: [5],\n",
       " 274: [5],\n",
       " 275: [5],\n",
       " 276: [5],\n",
       " 277: [5],\n",
       " 278: [5],\n",
       " 279: [5],\n",
       " 280: [5],\n",
       " 281: [5],\n",
       " 282: [5],\n",
       " 283: [5],\n",
       " 284: [5],\n",
       " 285: [5],\n",
       " 286: [5],\n",
       " 287: [5],\n",
       " 288: [5],\n",
       " 289: [5],\n",
       " 290: [5],\n",
       " 291: [5],\n",
       " 292: [5],\n",
       " 293: [5],\n",
       " 294: [5],\n",
       " 295: [5],\n",
       " 296: [5],\n",
       " 297: [5],\n",
       " 298: [5],\n",
       " 299: [5],\n",
       " 300: [5],\n",
       " 301: [5],\n",
       " 302: [5],\n",
       " 303: [5],\n",
       " 304: [5],\n",
       " 305: [5],\n",
       " 306: [4],\n",
       " 307: [4],\n",
       " 308: [5],\n",
       " 309: [5],\n",
       " 310: [5],\n",
       " 311: [4],\n",
       " 312: [4],\n",
       " 313: [5],\n",
       " 314: [5],\n",
       " 315: [5],\n",
       " 316: [5],\n",
       " 317: [5],\n",
       " 318: [4],\n",
       " 319: [5],\n",
       " 320: [5],\n",
       " 321: [5],\n",
       " 322: [5],\n",
       " 323: [5],\n",
       " 324: [5],\n",
       " 325: [5],\n",
       " 326: [5],\n",
       " 327: [5],\n",
       " 328: [5],\n",
       " 329: [5],\n",
       " 330: [5],\n",
       " 331: [5],\n",
       " 332: [4],\n",
       " 333: [5],\n",
       " 334: [5],\n",
       " 335: [5],\n",
       " 336: [5],\n",
       " 337: [5],\n",
       " 338: [5],\n",
       " 339: [5],\n",
       " 340: [5],\n",
       " 341: [5],\n",
       " 342: [5],\n",
       " 343: [5],\n",
       " 344: [5],\n",
       " 345: [5],\n",
       " 346: [4],\n",
       " 347: [5],\n",
       " 348: [5],\n",
       " 349: [5],\n",
       " 350: [5],\n",
       " 351: [5],\n",
       " 352: [5],\n",
       " 353: [5],\n",
       " 354: [3],\n",
       " 355: [5],\n",
       " 356: [5],\n",
       " 357: [5],\n",
       " 358: [5],\n",
       " 359: [5],\n",
       " 360: [4],\n",
       " 361: [5],\n",
       " 362: [5],\n",
       " 363: [5],\n",
       " 364: [5],\n",
       " 365: [5],\n",
       " 366: [5],\n",
       " 367: [5],\n",
       " 368: [5],\n",
       " 369: [5],\n",
       " 370: [5],\n",
       " 371: [5],\n",
       " 372: [5],\n",
       " 373: [5],\n",
       " 374: [4],\n",
       " 375: [5],\n",
       " 376: [5],\n",
       " 377: [5],\n",
       " 378: [5],\n",
       " 379: [5],\n",
       " 380: [5],\n",
       " 381: [5],\n",
       " 382: [5],\n",
       " 383: [5],\n",
       " 384: [5],\n",
       " 385: [4],\n",
       " 386: [5],\n",
       " 387: [5],\n",
       " 388: [5],\n",
       " 389: [5, 5],\n",
       " 390: [5],\n",
       " 391: [5],\n",
       " 392: [5],\n",
       " 393: [5],\n",
       " 394: [5],\n",
       " 395: [5],\n",
       " 396: [4],\n",
       " 397: [4],\n",
       " 398: [5],\n",
       " 399: [3],\n",
       " 400: [4],\n",
       " 401: [5],\n",
       " 402: [3],\n",
       " 403: [5],\n",
       " 404: [5],\n",
       " 405: [5],\n",
       " 406: [5],\n",
       " 407: [5],\n",
       " 408: [5],\n",
       " 409: [5],\n",
       " 410: [5],\n",
       " 411: [5],\n",
       " 412: [5],\n",
       " 413: [5],\n",
       " 414: [5],\n",
       " 415: [5],\n",
       " 416: [5],\n",
       " 417: [5],\n",
       " 418: [5],\n",
       " 419: [5],\n",
       " 420: [5],\n",
       " 421: [5],\n",
       " 422: [5],\n",
       " 423: [5],\n",
       " 424: [5],\n",
       " 425: [5],\n",
       " 426: [5],\n",
       " 427: [5],\n",
       " 428: [5],\n",
       " 429: [5],\n",
       " 430: [5],\n",
       " 431: [5],\n",
       " 432: [5],\n",
       " 433: [5],\n",
       " 434: [5],\n",
       " 435: [5],\n",
       " 436: [5],\n",
       " 437: [5],\n",
       " 438: [5],\n",
       " 439: [5],\n",
       " 440: [5],\n",
       " 441: [5],\n",
       " 442: [5],\n",
       " 443: [5],\n",
       " 444: [5],\n",
       " 445: [5],\n",
       " 446: [5],\n",
       " 447: [5],\n",
       " 448: [5],\n",
       " 449: [5],\n",
       " 450: [5],\n",
       " 451: [5],\n",
       " 452: [4],\n",
       " 453: [5],\n",
       " 454: [5],\n",
       " 455: [5],\n",
       " 456: [5],\n",
       " 457: [5],\n",
       " 458: [5],\n",
       " 459: [5],\n",
       " 460: [5],\n",
       " 461: [5],\n",
       " 462: [5],\n",
       " 463: [5],\n",
       " 464: [4],\n",
       " 465: [5],\n",
       " 466: [5],\n",
       " 467: [4],\n",
       " 468: [5],\n",
       " 469: [5],\n",
       " 470: [5],\n",
       " 471: [4],\n",
       " 472: [5],\n",
       " 473: [5],\n",
       " 474: [5],\n",
       " 475: [5],\n",
       " 476: [4],\n",
       " 477: [5],\n",
       " 478: [5],\n",
       " 479: [5],\n",
       " 480: [5],\n",
       " 481: [5],\n",
       " 482: [5],\n",
       " 483: [5],\n",
       " 484: [5],\n",
       " 485: [5],\n",
       " 486: [5],\n",
       " 487: [5],\n",
       " 488: [5],\n",
       " 489: [5],\n",
       " 490: [5],\n",
       " 491: [5],\n",
       " 492: [3],\n",
       " 493: [1],\n",
       " 494: [5],\n",
       " 495: [5],\n",
       " 496: [3],\n",
       " 497: [4],\n",
       " 498: [5],\n",
       " 499: [5],\n",
       " 500: [5],\n",
       " 501: [5],\n",
       " 502: [5],\n",
       " 503: [4],\n",
       " 504: [5],\n",
       " 505: [3],\n",
       " 506: [5],\n",
       " 507: [5],\n",
       " 508: [5],\n",
       " 509: [5],\n",
       " 510: [5],\n",
       " 511: [3],\n",
       " 512: [5],\n",
       " 513: [4],\n",
       " 514: [5],\n",
       " 515: [5],\n",
       " 516: [5],\n",
       " 517: [5],\n",
       " 518: [5],\n",
       " 519: [4],\n",
       " 520: [5],\n",
       " 521: [5],\n",
       " 522: [5],\n",
       " 523: [5],\n",
       " 524: [5],\n",
       " 525: [5],\n",
       " 526: [5],\n",
       " 527: [5],\n",
       " 528: [5],\n",
       " 529: [5],\n",
       " 530: [5],\n",
       " 531: [5],\n",
       " 532: [5],\n",
       " 533: [5],\n",
       " 534: [4],\n",
       " 535: [5],\n",
       " 536: [5],\n",
       " 537: [5],\n",
       " 538: [4],\n",
       " 539: [5],\n",
       " 540: [5],\n",
       " 541: [5],\n",
       " 542: [5],\n",
       " 543: [5],\n",
       " 544: [5],\n",
       " 545: [2],\n",
       " 546: [5],\n",
       " 547: [5],\n",
       " 548: [5],\n",
       " 549: [5],\n",
       " 550: [5],\n",
       " 551: [5],\n",
       " 552: [5],\n",
       " 553: [5],\n",
       " 554: [5],\n",
       " 555: [3],\n",
       " 556: [5],\n",
       " 557: [5],\n",
       " 558: [5],\n",
       " 559: [4],\n",
       " 560: [5],\n",
       " 561: [5],\n",
       " 562: [5],\n",
       " 563: [5],\n",
       " 564: [5],\n",
       " 565: [5],\n",
       " 566: [4],\n",
       " 567: [5],\n",
       " 568: [5],\n",
       " 569: [5],\n",
       " 570: [5],\n",
       " 571: [5],\n",
       " 572: [5],\n",
       " 573: [5],\n",
       " 574: [5],\n",
       " 575: [5],\n",
       " 576: [3],\n",
       " 577: [5],\n",
       " 578: [5],\n",
       " 579: [3],\n",
       " 580: [5],\n",
       " 581: [5],\n",
       " 582: [4],\n",
       " 583: [5],\n",
       " 584: [5],\n",
       " 585: [5],\n",
       " 586: [5],\n",
       " 587: [5],\n",
       " 588: [4],\n",
       " 589: [5],\n",
       " 590: [5],\n",
       " 591: [5],\n",
       " 592: [5],\n",
       " 593: [5],\n",
       " 594: [4],\n",
       " 595: [5],\n",
       " 596: [5],\n",
       " 597: [5],\n",
       " 598: [5],\n",
       " 599: [5],\n",
       " 600: [5],\n",
       " 601: [4],\n",
       " 602: [5],\n",
       " 603: [5],\n",
       " 604: [4],\n",
       " 605: [5],\n",
       " 606: [5],\n",
       " 607: [3],\n",
       " 608: [5],\n",
       " 609: [5],\n",
       " 610: [5],\n",
       " 611: [5],\n",
       " 612: [5],\n",
       " 613: [4],\n",
       " 614: [5],\n",
       " 615: [4],\n",
       " 616: [5],\n",
       " 617: [5],\n",
       " 618: [5],\n",
       " 619: [5],\n",
       " 620: [5],\n",
       " 621: [5],\n",
       " 622: [5],\n",
       " 623: [5],\n",
       " 624: [5],\n",
       " 625: [5],\n",
       " 626: [5],\n",
       " 627: [5],\n",
       " 628: [5],\n",
       " 629: [5],\n",
       " 630: [5],\n",
       " 631: [5],\n",
       " 632: [5],\n",
       " 633: [5],\n",
       " 634: [5],\n",
       " 635: [5],\n",
       " 636: [5],\n",
       " 637: [5],\n",
       " 638: [5],\n",
       " 639: [5],\n",
       " 640: [5],\n",
       " 641: [4],\n",
       " 642: [3],\n",
       " 643: [4],\n",
       " 644: [5],\n",
       " 645: [5],\n",
       " 646: [5],\n",
       " 647: [5],\n",
       " 648: [5],\n",
       " 649: [5],\n",
       " 650: [5, 4],\n",
       " 651: [5],\n",
       " 652: [4],\n",
       " 653: [5],\n",
       " 654: [5],\n",
       " 655: [5],\n",
       " 656: [5],\n",
       " 657: [5],\n",
       " 658: [5],\n",
       " 659: [5],\n",
       " 660: [5],\n",
       " 661: [5],\n",
       " 662: [5],\n",
       " 663: [5],\n",
       " 664: [5],\n",
       " 665: [4],\n",
       " 666: [5],\n",
       " 667: [5],\n",
       " 668: [5],\n",
       " 669: [5],\n",
       " 670: [5],\n",
       " 671: [5],\n",
       " 672: [5],\n",
       " 673: [5],\n",
       " 674: [3],\n",
       " 675: [5],\n",
       " 676: [5],\n",
       " 677: [5],\n",
       " 678: [5],\n",
       " 679: [5],\n",
       " 680: [5],\n",
       " 681: [5],\n",
       " 682: [5],\n",
       " 683: [5],\n",
       " 684: [5],\n",
       " 685: [5],\n",
       " 686: [5],\n",
       " 687: [5],\n",
       " 688: [5],\n",
       " 689: [5],\n",
       " 690: [5],\n",
       " 691: [5],\n",
       " 692: [5],\n",
       " 693: [5],\n",
       " 694: [5],\n",
       " 695: [5],\n",
       " 696: [5],\n",
       " 697: [5],\n",
       " 698: [5],\n",
       " 699: [5],\n",
       " 700: [5],\n",
       " 701: [5],\n",
       " 702: [5],\n",
       " 703: [5],\n",
       " 704: [5],\n",
       " 705: [2],\n",
       " 706: [5],\n",
       " 707: [5],\n",
       " 708: [5],\n",
       " 709: [5],\n",
       " 710: [5],\n",
       " 711: [5],\n",
       " 712: [5],\n",
       " 713: [5],\n",
       " 714: [4],\n",
       " 715: [5],\n",
       " 716: [5],\n",
       " 717: [5],\n",
       " 718: [5],\n",
       " 719: [5],\n",
       " 720: [5],\n",
       " 721: [5],\n",
       " 722: [5],\n",
       " 723: [4],\n",
       " 724: [5],\n",
       " 725: [5],\n",
       " 726: [5],\n",
       " 727: [5],\n",
       " 728: [5],\n",
       " 729: [5],\n",
       " 730: [5],\n",
       " 731: [5],\n",
       " 732: [5],\n",
       " 733: [5],\n",
       " 734: [5],\n",
       " 735: [5],\n",
       " 736: [5],\n",
       " 737: [5],\n",
       " 738: [5],\n",
       " 739: [5],\n",
       " 740: [5],\n",
       " 741: [5],\n",
       " 742: [5],\n",
       " 743: [5],\n",
       " 744: [5],\n",
       " 745: [5],\n",
       " 746: [5],\n",
       " 747: [5],\n",
       " 748: [5, 5],\n",
       " 749: [5],\n",
       " 750: [5],\n",
       " 751: [5],\n",
       " 752: [4],\n",
       " 753: [3],\n",
       " 754: [4],\n",
       " 755: [5],\n",
       " 756: [5],\n",
       " 757: [5],\n",
       " 758: [5],\n",
       " 759: [5],\n",
       " 760: [5],\n",
       " 761: [5],\n",
       " 762: [5],\n",
       " 763: [5],\n",
       " 764: [5],\n",
       " 765: [5],\n",
       " 766: [5],\n",
       " 767: [5],\n",
       " 768: [5],\n",
       " 769: [5],\n",
       " 770: [5],\n",
       " 771: [5],\n",
       " 772: [5],\n",
       " 773: [5],\n",
       " 774: [4],\n",
       " 775: [5],\n",
       " 776: [5],\n",
       " 777: [4],\n",
       " 778: [5, 5],\n",
       " 779: [5],\n",
       " 780: [5],\n",
       " 781: [5],\n",
       " 782: [5],\n",
       " 783: [5],\n",
       " 784: [5],\n",
       " 785: [5],\n",
       " 786: [4],\n",
       " 787: [5],\n",
       " 788: [5],\n",
       " 789: [4],\n",
       " 790: [5],\n",
       " 791: [4],\n",
       " 792: [5],\n",
       " 793: [5],\n",
       " 794: [5],\n",
       " 795: [5],\n",
       " 796: [4],\n",
       " 797: [5],\n",
       " 798: [4],\n",
       " 799: [5],\n",
       " 800: [5],\n",
       " 801: [4],\n",
       " 802: [5],\n",
       " 803: [4],\n",
       " 804: [5],\n",
       " 805: [5],\n",
       " 806: [5],\n",
       " 807: [5],\n",
       " 808: [5],\n",
       " 809: [5],\n",
       " 810: [5],\n",
       " 811: [5],\n",
       " 812: [5],\n",
       " 813: [5],\n",
       " 814: [4],\n",
       " 815: [5],\n",
       " 816: [5],\n",
       " 817: [5],\n",
       " 818: [5],\n",
       " 819: [5],\n",
       " 820: [5],\n",
       " 821: [5],\n",
       " 822: [5],\n",
       " 823: [5],\n",
       " 824: [5],\n",
       " 825: [5],\n",
       " 826: [5],\n",
       " 827: [5],\n",
       " 828: [5],\n",
       " 829: [5],\n",
       " 830: [5],\n",
       " 831: [5],\n",
       " 832: [5],\n",
       " 833: [5],\n",
       " 834: [5],\n",
       " 835: [3],\n",
       " 836: [3],\n",
       " 837: [4],\n",
       " 838: [5],\n",
       " 839: [5],\n",
       " 840: [4],\n",
       " 841: [4],\n",
       " 842: [4],\n",
       " 843: [4],\n",
       " 844: [5],\n",
       " 845: [5],\n",
       " 846: [5],\n",
       " 847: [5],\n",
       " 848: [4],\n",
       " 849: [4],\n",
       " 850: [4],\n",
       " 851: [5],\n",
       " 852: [5],\n",
       " 853: [5],\n",
       " 854: [5],\n",
       " 855: [4],\n",
       " 856: [5],\n",
       " 857: [5],\n",
       " 858: [5],\n",
       " 859: [5],\n",
       " 860: [5],\n",
       " 861: [5],\n",
       " 862: [5],\n",
       " 863: [5],\n",
       " 864: [5],\n",
       " 865: [5],\n",
       " 866: [5],\n",
       " 867: [5],\n",
       " 868: [5],\n",
       " 869: [5],\n",
       " 870: [5],\n",
       " 871: [5],\n",
       " 872: [5],\n",
       " 873: [5],\n",
       " 874: [5],\n",
       " 875: [5],\n",
       " 876: [5],\n",
       " 877: [5],\n",
       " 878: [5],\n",
       " 879: [5],\n",
       " 880: [5],\n",
       " 881: [5],\n",
       " 882: [5],\n",
       " 883: [5],\n",
       " 884: [4],\n",
       " 885: [5],\n",
       " 886: [4],\n",
       " 887: [4],\n",
       " 888: [4],\n",
       " 889: [5],\n",
       " 890: [5],\n",
       " 891: [5],\n",
       " 892: [5],\n",
       " 893: [5],\n",
       " 894: [5],\n",
       " 895: [5],\n",
       " 896: [5],\n",
       " 897: [4],\n",
       " 898: [4],\n",
       " 899: [5],\n",
       " 900: [5],\n",
       " 901: [5],\n",
       " 902: [5],\n",
       " 903: [5],\n",
       " 904: [5],\n",
       " 905: [2],\n",
       " 906: [5],\n",
       " 907: [4],\n",
       " 908: [5],\n",
       " 909: [5],\n",
       " 910: [5],\n",
       " 911: [5],\n",
       " 912: [5],\n",
       " 913: [5],\n",
       " 914: [5],\n",
       " 915: [5],\n",
       " 916: [5],\n",
       " 917: [5],\n",
       " 918: [5],\n",
       " 919: [5],\n",
       " 920: [5],\n",
       " 921: [5],\n",
       " 922: [5],\n",
       " 923: [5],\n",
       " 924: [5],\n",
       " 925: [3],\n",
       " 926: [5],\n",
       " 927: [5],\n",
       " 928: [5],\n",
       " 929: [5],\n",
       " 930: [5],\n",
       " 931: [5],\n",
       " 932: [5],\n",
       " 933: [5],\n",
       " 934: [4],\n",
       " 935: [5],\n",
       " 936: [5],\n",
       " 937: [5],\n",
       " 938: [5],\n",
       " 939: [5]}"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "51798612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.stack(pos_pairs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "0b58cce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "389\n",
      "650\n",
      "748\n",
      "778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 1,\n",
       "         1: 1,\n",
       "         2: 1,\n",
       "         3: 1,\n",
       "         4: 1,\n",
       "         5: 1,\n",
       "         6: 1,\n",
       "         7: 1,\n",
       "         8: 1,\n",
       "         9: 1,\n",
       "         10: 1,\n",
       "         11: 1,\n",
       "         12: 1,\n",
       "         13: 1,\n",
       "         14: 1,\n",
       "         15: 1,\n",
       "         16: 1,\n",
       "         17: 1,\n",
       "         18: 1,\n",
       "         19: 1,\n",
       "         20: 1,\n",
       "         21: 1,\n",
       "         22: 1,\n",
       "         23: 1,\n",
       "         24: 1,\n",
       "         25: 1,\n",
       "         26: 1,\n",
       "         27: 1,\n",
       "         28: 1,\n",
       "         29: 1,\n",
       "         30: 1,\n",
       "         31: 1,\n",
       "         32: 1,\n",
       "         33: 1,\n",
       "         34: 1,\n",
       "         35: 1,\n",
       "         36: 1,\n",
       "         37: 1,\n",
       "         38: 1,\n",
       "         39: 1,\n",
       "         40: 1,\n",
       "         41: 1,\n",
       "         42: 1,\n",
       "         43: 1,\n",
       "         44: 1,\n",
       "         45: 1,\n",
       "         46: 1,\n",
       "         47: 1,\n",
       "         48: 1,\n",
       "         49: 1,\n",
       "         50: 1,\n",
       "         51: 1,\n",
       "         52: 1,\n",
       "         53: 1,\n",
       "         54: 1,\n",
       "         55: 2,\n",
       "         56: 1,\n",
       "         57: 1,\n",
       "         58: 1,\n",
       "         59: 1,\n",
       "         60: 1,\n",
       "         61: 1,\n",
       "         62: 1,\n",
       "         63: 1,\n",
       "         64: 1,\n",
       "         65: 1,\n",
       "         66: 1,\n",
       "         67: 1,\n",
       "         68: 1,\n",
       "         69: 1,\n",
       "         70: 1,\n",
       "         71: 1,\n",
       "         72: 1,\n",
       "         73: 1,\n",
       "         74: 1,\n",
       "         75: 1,\n",
       "         76: 1,\n",
       "         77: 1,\n",
       "         78: 1,\n",
       "         79: 1,\n",
       "         80: 1,\n",
       "         81: 1,\n",
       "         82: 1,\n",
       "         83: 1,\n",
       "         84: 1,\n",
       "         85: 1,\n",
       "         86: 1,\n",
       "         87: 1,\n",
       "         88: 1,\n",
       "         89: 1,\n",
       "         90: 1,\n",
       "         91: 1,\n",
       "         92: 1,\n",
       "         93: 1,\n",
       "         94: 1,\n",
       "         95: 1,\n",
       "         96: 1,\n",
       "         97: 1,\n",
       "         98: 1,\n",
       "         99: 1,\n",
       "         100: 1,\n",
       "         101: 1,\n",
       "         102: 1,\n",
       "         103: 1,\n",
       "         104: 1,\n",
       "         105: 1,\n",
       "         106: 1,\n",
       "         107: 1,\n",
       "         108: 1,\n",
       "         109: 1,\n",
       "         110: 1,\n",
       "         111: 1,\n",
       "         112: 1,\n",
       "         113: 1,\n",
       "         114: 1,\n",
       "         115: 1,\n",
       "         116: 1,\n",
       "         117: 1,\n",
       "         118: 1,\n",
       "         119: 1,\n",
       "         120: 1,\n",
       "         121: 1,\n",
       "         122: 1,\n",
       "         123: 1,\n",
       "         124: 1,\n",
       "         125: 1,\n",
       "         126: 1,\n",
       "         127: 1,\n",
       "         128: 1,\n",
       "         129: 1,\n",
       "         130: 1,\n",
       "         131: 1,\n",
       "         132: 1,\n",
       "         133: 1,\n",
       "         134: 1,\n",
       "         135: 1,\n",
       "         136: 1,\n",
       "         137: 1,\n",
       "         138: 1,\n",
       "         139: 1,\n",
       "         140: 1,\n",
       "         141: 1,\n",
       "         142: 1,\n",
       "         143: 1,\n",
       "         144: 1,\n",
       "         145: 1,\n",
       "         146: 1,\n",
       "         147: 1,\n",
       "         148: 1,\n",
       "         149: 1,\n",
       "         150: 1,\n",
       "         151: 1,\n",
       "         152: 1,\n",
       "         153: 1,\n",
       "         154: 1,\n",
       "         155: 1,\n",
       "         156: 1,\n",
       "         157: 1,\n",
       "         158: 1,\n",
       "         159: 1,\n",
       "         160: 1,\n",
       "         161: 1,\n",
       "         162: 1,\n",
       "         163: 1,\n",
       "         164: 1,\n",
       "         165: 1,\n",
       "         166: 1,\n",
       "         167: 1,\n",
       "         168: 1,\n",
       "         169: 1,\n",
       "         170: 1,\n",
       "         171: 1,\n",
       "         172: 1,\n",
       "         173: 1,\n",
       "         174: 1,\n",
       "         175: 1,\n",
       "         176: 1,\n",
       "         177: 1,\n",
       "         178: 1,\n",
       "         179: 1,\n",
       "         180: 1,\n",
       "         181: 1,\n",
       "         182: 1,\n",
       "         183: 1,\n",
       "         184: 1,\n",
       "         185: 1,\n",
       "         186: 1,\n",
       "         187: 1,\n",
       "         188: 1,\n",
       "         189: 1,\n",
       "         190: 1,\n",
       "         191: 1,\n",
       "         192: 1,\n",
       "         193: 1,\n",
       "         194: 1,\n",
       "         195: 1,\n",
       "         196: 1,\n",
       "         197: 1,\n",
       "         198: 1,\n",
       "         199: 1,\n",
       "         200: 1,\n",
       "         201: 1,\n",
       "         202: 1,\n",
       "         203: 1,\n",
       "         204: 1,\n",
       "         205: 1,\n",
       "         206: 1,\n",
       "         207: 1,\n",
       "         208: 1,\n",
       "         209: 1,\n",
       "         210: 1,\n",
       "         211: 1,\n",
       "         212: 1,\n",
       "         213: 1,\n",
       "         214: 1,\n",
       "         215: 1,\n",
       "         216: 1,\n",
       "         217: 1,\n",
       "         218: 1,\n",
       "         219: 1,\n",
       "         220: 1,\n",
       "         221: 1,\n",
       "         222: 1,\n",
       "         223: 1,\n",
       "         224: 1,\n",
       "         225: 1,\n",
       "         226: 1,\n",
       "         227: 1,\n",
       "         228: 1,\n",
       "         229: 1,\n",
       "         230: 1,\n",
       "         231: 1,\n",
       "         232: 1,\n",
       "         233: 1,\n",
       "         234: 1,\n",
       "         235: 1,\n",
       "         236: 1,\n",
       "         237: 1,\n",
       "         238: 1,\n",
       "         239: 1,\n",
       "         240: 1,\n",
       "         241: 1,\n",
       "         242: 1,\n",
       "         243: 1,\n",
       "         244: 1,\n",
       "         245: 1,\n",
       "         246: 1,\n",
       "         247: 1,\n",
       "         248: 1,\n",
       "         249: 1,\n",
       "         250: 1,\n",
       "         251: 1,\n",
       "         252: 1,\n",
       "         253: 1,\n",
       "         254: 1,\n",
       "         255: 1,\n",
       "         256: 1,\n",
       "         257: 1,\n",
       "         258: 1,\n",
       "         259: 1,\n",
       "         260: 1,\n",
       "         261: 1,\n",
       "         262: 1,\n",
       "         263: 1,\n",
       "         264: 1,\n",
       "         265: 1,\n",
       "         266: 1,\n",
       "         267: 1,\n",
       "         268: 1,\n",
       "         269: 1,\n",
       "         270: 1,\n",
       "         271: 1,\n",
       "         272: 1,\n",
       "         273: 1,\n",
       "         274: 1,\n",
       "         275: 1,\n",
       "         276: 1,\n",
       "         277: 1,\n",
       "         278: 1,\n",
       "         279: 1,\n",
       "         280: 1,\n",
       "         281: 1,\n",
       "         282: 1,\n",
       "         283: 1,\n",
       "         284: 1,\n",
       "         285: 1,\n",
       "         286: 1,\n",
       "         287: 1,\n",
       "         288: 1,\n",
       "         289: 1,\n",
       "         290: 1,\n",
       "         291: 1,\n",
       "         292: 1,\n",
       "         293: 1,\n",
       "         294: 1,\n",
       "         295: 1,\n",
       "         296: 1,\n",
       "         297: 1,\n",
       "         298: 1,\n",
       "         299: 1,\n",
       "         300: 1,\n",
       "         301: 1,\n",
       "         302: 1,\n",
       "         303: 1,\n",
       "         304: 1,\n",
       "         305: 1,\n",
       "         306: 1,\n",
       "         307: 1,\n",
       "         308: 1,\n",
       "         309: 1,\n",
       "         310: 1,\n",
       "         311: 1,\n",
       "         312: 1,\n",
       "         313: 1,\n",
       "         314: 1,\n",
       "         315: 1,\n",
       "         316: 1,\n",
       "         317: 1,\n",
       "         318: 1,\n",
       "         319: 1,\n",
       "         320: 1,\n",
       "         321: 1,\n",
       "         322: 1,\n",
       "         323: 1,\n",
       "         324: 1,\n",
       "         325: 1,\n",
       "         326: 1,\n",
       "         327: 1,\n",
       "         328: 1,\n",
       "         329: 1,\n",
       "         330: 1,\n",
       "         331: 1,\n",
       "         332: 1,\n",
       "         333: 1,\n",
       "         334: 1,\n",
       "         335: 1,\n",
       "         336: 1,\n",
       "         337: 1,\n",
       "         338: 1,\n",
       "         339: 1,\n",
       "         340: 1,\n",
       "         341: 1,\n",
       "         342: 1,\n",
       "         343: 1,\n",
       "         344: 1,\n",
       "         345: 1,\n",
       "         346: 1,\n",
       "         347: 1,\n",
       "         348: 1,\n",
       "         349: 1,\n",
       "         350: 1,\n",
       "         351: 1,\n",
       "         352: 1,\n",
       "         353: 1,\n",
       "         354: 1,\n",
       "         355: 1,\n",
       "         356: 1,\n",
       "         357: 1,\n",
       "         358: 1,\n",
       "         359: 1,\n",
       "         360: 1,\n",
       "         361: 1,\n",
       "         362: 1,\n",
       "         363: 1,\n",
       "         364: 1,\n",
       "         365: 1,\n",
       "         366: 1,\n",
       "         367: 1,\n",
       "         368: 1,\n",
       "         369: 1,\n",
       "         370: 1,\n",
       "         371: 1,\n",
       "         372: 1,\n",
       "         373: 1,\n",
       "         374: 1,\n",
       "         375: 1,\n",
       "         376: 1,\n",
       "         377: 1,\n",
       "         378: 1,\n",
       "         379: 1,\n",
       "         380: 1,\n",
       "         381: 1,\n",
       "         382: 1,\n",
       "         383: 1,\n",
       "         384: 1,\n",
       "         385: 1,\n",
       "         386: 1,\n",
       "         387: 1,\n",
       "         388: 1,\n",
       "         389: 2,\n",
       "         390: 1,\n",
       "         391: 1,\n",
       "         392: 1,\n",
       "         393: 1,\n",
       "         394: 1,\n",
       "         395: 1,\n",
       "         396: 1,\n",
       "         397: 1,\n",
       "         398: 1,\n",
       "         399: 1,\n",
       "         400: 1,\n",
       "         401: 1,\n",
       "         402: 1,\n",
       "         403: 1,\n",
       "         404: 1,\n",
       "         405: 1,\n",
       "         406: 1,\n",
       "         407: 1,\n",
       "         408: 1,\n",
       "         409: 1,\n",
       "         410: 1,\n",
       "         411: 1,\n",
       "         412: 1,\n",
       "         413: 1,\n",
       "         414: 1,\n",
       "         415: 1,\n",
       "         416: 1,\n",
       "         417: 1,\n",
       "         418: 1,\n",
       "         419: 1,\n",
       "         420: 1,\n",
       "         421: 1,\n",
       "         422: 1,\n",
       "         423: 1,\n",
       "         424: 1,\n",
       "         425: 1,\n",
       "         426: 1,\n",
       "         427: 1,\n",
       "         428: 1,\n",
       "         429: 1,\n",
       "         430: 1,\n",
       "         431: 1,\n",
       "         432: 1,\n",
       "         433: 1,\n",
       "         434: 1,\n",
       "         435: 1,\n",
       "         436: 1,\n",
       "         437: 1,\n",
       "         438: 1,\n",
       "         439: 1,\n",
       "         440: 1,\n",
       "         441: 1,\n",
       "         442: 1,\n",
       "         443: 1,\n",
       "         444: 1,\n",
       "         445: 1,\n",
       "         446: 1,\n",
       "         447: 1,\n",
       "         448: 1,\n",
       "         449: 1,\n",
       "         450: 1,\n",
       "         451: 1,\n",
       "         452: 1,\n",
       "         453: 1,\n",
       "         454: 1,\n",
       "         455: 1,\n",
       "         456: 1,\n",
       "         457: 1,\n",
       "         458: 1,\n",
       "         459: 1,\n",
       "         460: 1,\n",
       "         461: 1,\n",
       "         462: 1,\n",
       "         463: 1,\n",
       "         464: 1,\n",
       "         465: 1,\n",
       "         466: 1,\n",
       "         467: 1,\n",
       "         468: 1,\n",
       "         469: 1,\n",
       "         470: 1,\n",
       "         471: 1,\n",
       "         472: 1,\n",
       "         473: 1,\n",
       "         474: 1,\n",
       "         475: 1,\n",
       "         476: 1,\n",
       "         477: 1,\n",
       "         478: 1,\n",
       "         479: 1,\n",
       "         480: 1,\n",
       "         481: 1,\n",
       "         482: 1,\n",
       "         483: 1,\n",
       "         484: 1,\n",
       "         485: 1,\n",
       "         486: 1,\n",
       "         487: 1,\n",
       "         488: 1,\n",
       "         489: 1,\n",
       "         490: 1,\n",
       "         491: 1,\n",
       "         492: 1,\n",
       "         493: 1,\n",
       "         494: 1,\n",
       "         495: 1,\n",
       "         496: 1,\n",
       "         497: 1,\n",
       "         498: 1,\n",
       "         499: 1,\n",
       "         500: 1,\n",
       "         501: 1,\n",
       "         502: 1,\n",
       "         503: 1,\n",
       "         504: 1,\n",
       "         505: 1,\n",
       "         506: 1,\n",
       "         507: 1,\n",
       "         508: 1,\n",
       "         509: 1,\n",
       "         510: 1,\n",
       "         511: 1,\n",
       "         512: 1,\n",
       "         513: 1,\n",
       "         514: 1,\n",
       "         515: 1,\n",
       "         516: 1,\n",
       "         517: 1,\n",
       "         518: 1,\n",
       "         519: 1,\n",
       "         520: 1,\n",
       "         521: 1,\n",
       "         522: 1,\n",
       "         523: 1,\n",
       "         524: 1,\n",
       "         525: 1,\n",
       "         526: 1,\n",
       "         527: 1,\n",
       "         528: 1,\n",
       "         529: 1,\n",
       "         530: 1,\n",
       "         531: 1,\n",
       "         532: 1,\n",
       "         533: 1,\n",
       "         534: 1,\n",
       "         535: 1,\n",
       "         536: 1,\n",
       "         537: 1,\n",
       "         538: 1,\n",
       "         539: 1,\n",
       "         540: 1,\n",
       "         541: 1,\n",
       "         542: 1,\n",
       "         543: 1,\n",
       "         544: 1,\n",
       "         545: 1,\n",
       "         546: 1,\n",
       "         547: 1,\n",
       "         548: 1,\n",
       "         549: 1,\n",
       "         550: 1,\n",
       "         551: 1,\n",
       "         552: 1,\n",
       "         553: 1,\n",
       "         554: 1,\n",
       "         555: 1,\n",
       "         556: 1,\n",
       "         557: 1,\n",
       "         558: 1,\n",
       "         559: 1,\n",
       "         560: 1,\n",
       "         561: 1,\n",
       "         562: 1,\n",
       "         563: 1,\n",
       "         564: 1,\n",
       "         565: 1,\n",
       "         566: 1,\n",
       "         567: 1,\n",
       "         568: 1,\n",
       "         569: 1,\n",
       "         570: 1,\n",
       "         571: 1,\n",
       "         572: 1,\n",
       "         573: 1,\n",
       "         574: 1,\n",
       "         575: 1,\n",
       "         576: 1,\n",
       "         577: 1,\n",
       "         578: 1,\n",
       "         579: 1,\n",
       "         580: 1,\n",
       "         581: 1,\n",
       "         582: 1,\n",
       "         583: 1,\n",
       "         584: 1,\n",
       "         585: 1,\n",
       "         586: 1,\n",
       "         587: 1,\n",
       "         588: 1,\n",
       "         589: 1,\n",
       "         590: 1,\n",
       "         591: 1,\n",
       "         592: 1,\n",
       "         593: 1,\n",
       "         594: 1,\n",
       "         595: 1,\n",
       "         596: 1,\n",
       "         597: 1,\n",
       "         598: 1,\n",
       "         599: 1,\n",
       "         600: 1,\n",
       "         601: 1,\n",
       "         602: 1,\n",
       "         603: 1,\n",
       "         604: 1,\n",
       "         605: 1,\n",
       "         606: 1,\n",
       "         607: 1,\n",
       "         608: 1,\n",
       "         609: 1,\n",
       "         610: 1,\n",
       "         611: 1,\n",
       "         612: 1,\n",
       "         613: 1,\n",
       "         614: 1,\n",
       "         615: 1,\n",
       "         616: 1,\n",
       "         617: 1,\n",
       "         618: 1,\n",
       "         619: 1,\n",
       "         620: 1,\n",
       "         621: 1,\n",
       "         622: 1,\n",
       "         623: 1,\n",
       "         624: 1,\n",
       "         625: 1,\n",
       "         626: 1,\n",
       "         627: 1,\n",
       "         628: 1,\n",
       "         629: 1,\n",
       "         630: 1,\n",
       "         631: 1,\n",
       "         632: 1,\n",
       "         633: 1,\n",
       "         634: 1,\n",
       "         635: 1,\n",
       "         636: 1,\n",
       "         637: 1,\n",
       "         638: 1,\n",
       "         639: 1,\n",
       "         640: 1,\n",
       "         641: 1,\n",
       "         642: 1,\n",
       "         643: 1,\n",
       "         644: 1,\n",
       "         645: 1,\n",
       "         646: 1,\n",
       "         647: 1,\n",
       "         648: 1,\n",
       "         649: 1,\n",
       "         650: 2,\n",
       "         651: 1,\n",
       "         652: 1,\n",
       "         653: 1,\n",
       "         654: 1,\n",
       "         655: 1,\n",
       "         656: 1,\n",
       "         657: 1,\n",
       "         658: 1,\n",
       "         659: 1,\n",
       "         660: 1,\n",
       "         661: 1,\n",
       "         662: 1,\n",
       "         663: 1,\n",
       "         664: 1,\n",
       "         665: 1,\n",
       "         666: 1,\n",
       "         667: 1,\n",
       "         668: 1,\n",
       "         669: 1,\n",
       "         670: 1,\n",
       "         671: 1,\n",
       "         672: 1,\n",
       "         673: 1,\n",
       "         674: 1,\n",
       "         675: 1,\n",
       "         676: 1,\n",
       "         677: 1,\n",
       "         678: 1,\n",
       "         679: 1,\n",
       "         680: 1,\n",
       "         681: 1,\n",
       "         682: 1,\n",
       "         683: 1,\n",
       "         684: 1,\n",
       "         685: 1,\n",
       "         686: 1,\n",
       "         687: 1,\n",
       "         688: 1,\n",
       "         689: 1,\n",
       "         690: 1,\n",
       "         691: 1,\n",
       "         692: 1,\n",
       "         693: 1,\n",
       "         694: 1,\n",
       "         695: 1,\n",
       "         696: 1,\n",
       "         697: 1,\n",
       "         698: 1,\n",
       "         699: 1,\n",
       "         700: 1,\n",
       "         701: 1,\n",
       "         702: 1,\n",
       "         703: 1,\n",
       "         704: 1,\n",
       "         705: 1,\n",
       "         706: 1,\n",
       "         707: 1,\n",
       "         708: 1,\n",
       "         709: 1,\n",
       "         710: 1,\n",
       "         711: 1,\n",
       "         712: 1,\n",
       "         713: 1,\n",
       "         714: 1,\n",
       "         715: 1,\n",
       "         716: 1,\n",
       "         717: 1,\n",
       "         718: 1,\n",
       "         719: 1,\n",
       "         720: 1,\n",
       "         721: 1,\n",
       "         722: 1,\n",
       "         723: 1,\n",
       "         724: 1,\n",
       "         725: 1,\n",
       "         726: 1,\n",
       "         727: 1,\n",
       "         728: 1,\n",
       "         729: 1,\n",
       "         730: 1,\n",
       "         731: 1,\n",
       "         732: 1,\n",
       "         733: 1,\n",
       "         734: 1,\n",
       "         735: 1,\n",
       "         736: 1,\n",
       "         737: 1,\n",
       "         738: 1,\n",
       "         739: 1,\n",
       "         740: 1,\n",
       "         741: 1,\n",
       "         742: 1,\n",
       "         743: 1,\n",
       "         744: 1,\n",
       "         745: 1,\n",
       "         746: 1,\n",
       "         747: 1,\n",
       "         748: 2,\n",
       "         749: 1,\n",
       "         750: 1,\n",
       "         751: 1,\n",
       "         752: 1,\n",
       "         753: 1,\n",
       "         754: 1,\n",
       "         755: 1,\n",
       "         756: 1,\n",
       "         757: 1,\n",
       "         758: 1,\n",
       "         759: 1,\n",
       "         760: 1,\n",
       "         761: 1,\n",
       "         762: 1,\n",
       "         763: 1,\n",
       "         764: 1,\n",
       "         765: 1,\n",
       "         766: 1,\n",
       "         767: 1,\n",
       "         768: 1,\n",
       "         769: 1,\n",
       "         770: 1,\n",
       "         771: 1,\n",
       "         772: 1,\n",
       "         773: 1,\n",
       "         774: 1,\n",
       "         775: 1,\n",
       "         776: 1,\n",
       "         777: 1,\n",
       "         778: 2,\n",
       "         779: 1,\n",
       "         780: 1,\n",
       "         781: 1,\n",
       "         782: 1,\n",
       "         783: 1,\n",
       "         784: 1,\n",
       "         785: 1,\n",
       "         786: 1,\n",
       "         787: 1,\n",
       "         788: 1,\n",
       "         789: 1,\n",
       "         790: 1,\n",
       "         791: 1,\n",
       "         792: 1,\n",
       "         793: 1,\n",
       "         794: 1,\n",
       "         795: 1,\n",
       "         796: 1,\n",
       "         797: 1,\n",
       "         798: 1,\n",
       "         799: 1,\n",
       "         800: 1,\n",
       "         801: 1,\n",
       "         802: 1,\n",
       "         803: 1,\n",
       "         804: 1,\n",
       "         805: 1,\n",
       "         806: 1,\n",
       "         807: 1,\n",
       "         808: 1,\n",
       "         809: 1,\n",
       "         810: 1,\n",
       "         811: 1,\n",
       "         812: 1,\n",
       "         813: 1,\n",
       "         814: 1,\n",
       "         815: 1,\n",
       "         816: 1,\n",
       "         817: 1,\n",
       "         818: 1,\n",
       "         819: 1,\n",
       "         820: 1,\n",
       "         821: 1,\n",
       "         822: 1,\n",
       "         823: 1,\n",
       "         824: 1,\n",
       "         825: 1,\n",
       "         826: 1,\n",
       "         827: 1,\n",
       "         828: 1,\n",
       "         829: 1,\n",
       "         830: 1,\n",
       "         831: 1,\n",
       "         832: 1,\n",
       "         833: 1,\n",
       "         834: 1,\n",
       "         835: 1,\n",
       "         836: 1,\n",
       "         837: 1,\n",
       "         838: 1,\n",
       "         839: 1,\n",
       "         840: 1,\n",
       "         841: 1,\n",
       "         842: 1,\n",
       "         843: 1,\n",
       "         844: 1,\n",
       "         845: 1,\n",
       "         846: 1,\n",
       "         847: 1,\n",
       "         848: 1,\n",
       "         849: 1,\n",
       "         850: 1,\n",
       "         851: 1,\n",
       "         852: 1,\n",
       "         853: 1,\n",
       "         854: 1,\n",
       "         855: 1,\n",
       "         856: 1,\n",
       "         857: 1,\n",
       "         858: 1,\n",
       "         859: 1,\n",
       "         860: 1,\n",
       "         861: 1,\n",
       "         862: 1,\n",
       "         863: 1,\n",
       "         864: 1,\n",
       "         865: 1,\n",
       "         866: 1,\n",
       "         867: 1,\n",
       "         868: 1,\n",
       "         869: 1,\n",
       "         870: 1,\n",
       "         871: 1,\n",
       "         872: 1,\n",
       "         873: 1,\n",
       "         874: 1,\n",
       "         875: 1,\n",
       "         876: 1,\n",
       "         877: 1,\n",
       "         878: 1,\n",
       "         879: 1,\n",
       "         880: 1,\n",
       "         881: 1,\n",
       "         882: 1,\n",
       "         883: 1,\n",
       "         884: 1,\n",
       "         885: 1,\n",
       "         886: 1,\n",
       "         887: 1,\n",
       "         888: 1,\n",
       "         889: 1,\n",
       "         890: 1,\n",
       "         891: 1,\n",
       "         892: 1,\n",
       "         893: 1,\n",
       "         894: 1,\n",
       "         895: 1,\n",
       "         896: 1,\n",
       "         897: 1,\n",
       "         898: 1,\n",
       "         899: 1,\n",
       "         900: 1,\n",
       "         901: 1,\n",
       "         902: 1,\n",
       "         903: 1,\n",
       "         904: 1,\n",
       "         905: 1,\n",
       "         906: 1,\n",
       "         907: 1,\n",
       "         908: 1,\n",
       "         909: 1,\n",
       "         910: 1,\n",
       "         911: 1,\n",
       "         912: 1,\n",
       "         913: 1,\n",
       "         914: 1,\n",
       "         915: 1,\n",
       "         916: 1,\n",
       "         917: 1,\n",
       "         918: 1,\n",
       "         919: 1,\n",
       "         920: 1,\n",
       "         921: 1,\n",
       "         922: 1,\n",
       "         923: 1,\n",
       "         924: 1,\n",
       "         925: 1,\n",
       "         926: 1,\n",
       "         927: 1,\n",
       "         928: 1,\n",
       "         929: 1,\n",
       "         930: 1,\n",
       "         931: 1,\n",
       "         932: 1,\n",
       "         933: 1,\n",
       "         934: 1,\n",
       "         935: 1,\n",
       "         936: 1,\n",
       "         937: 1,\n",
       "         938: 1,\n",
       "         939: 1})"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter(edge_index[0].tolist())\n",
    "\n",
    "for key in c:\n",
    "    if c[key] > 1:\n",
    "        print(key)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "2d283eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.clone(edge_index[0])\n",
    "edge_index[0] = edge_index[1]\n",
    "edge_index[1] = temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "aaaacebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,  ..., 127, 127, 127],\n",
       "        [  0,   1,   2,  ..., 944, 945, 946]])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6bf07a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   2,   3,   3,   3,   3,   3,   3,   3,\n",
       "          3,   3,   3,   4,   4,   4,   4,   5,   6,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   8,   9,   9,   9,   9,   9,   9,   9,   9,   9,\n",
       "          9,  10,  10,  10,  10,  10,  10,  10,  10,  11,  11,  12,  12,  13,\n",
       "         13,  13,  13,  13,  13,  13,  13,  13,  13,  14,  14,  14,  14,  14,\n",
       "         14,  14,  14,  14,  14,  15,  15,  15,  16,  16,  16,  16,  16,  16,\n",
       "         16,  16,  16,  16,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
       "         18,  18,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  20,  20,\n",
       "         21,  21,  21,  21,  21,  21,  21,  21,  21,  22,  22,  22,  22,  22,\n",
       "         22,  22,  22,  22,  22,  23,  24,  24,  24,  25,  25,  25,  25,  25,\n",
       "         25,  25,  26,  27,  27,  27,  27,  28,  29,  29,  29,  29,  29,  29,\n",
       "         29,  29,  29,  29,  30,  30,  30,  30,  31,  31,  31,  31,  31,  31,\n",
       "         31,  31,  31,  31,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,\n",
       "         33,  33,  34,  34,  34,  34,  34,  34,  34,  34,  34,  34,  35,  35,\n",
       "         35,  35,  35,  35,  35,  35,  35,  35,  36,  36,  36,  36,  36,  36,\n",
       "         36,  36,  36,  36,  37,  37,  37,  37,  37,  37,  38,  38,  38,  38,\n",
       "         38,  38,  38,  38,  38,  38,  39,  40,  40,  40,  41,  41,  41,  41,\n",
       "         42,  42,  42,  42,  42,  42,  42,  42,  42,  42,  43,  43,  43,  43,\n",
       "         43,  43,  43,  43,  43,  43,  44,  44,  44,  44,  44,  44,  44,  44,\n",
       "         44,  44,  45,  46,  47,  47,  47,  47,  47,  47,  47,  47,  47,  47,\n",
       "         48,  49,  49,  49,  49,  49,  49,  49,  49,  49,  49,  50,  50,  50,\n",
       "         50,  50,  50,  50,  50,  50,  50,  51,  51,  51,  51,  51,  51,  51,\n",
       "         51,  51,  51,  52,  52,  52,  52,  53,  53,  53,  54,  54,  54,  54,\n",
       "         54,  54,  54,  54,  54,  54,  55,  55,  55,  55,  55,  55,  55,  55,\n",
       "         55,  55,  56,  56,  56,  56,  56,  56,  56,  56,  56,  56,  57,  57,\n",
       "         58,  58,  58,  58,  58,  58,  58,  58,  58,  58,  59,  60,  60,  60,\n",
       "         60,  60,  60,  60,  60,  60,  60,  61,  61,  61,  61,  61,  61,  61,\n",
       "         61,  61,  61,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  63,\n",
       "         63,  63,  63,  63,  63,  63,  63,  63,  63,  64,  64,  64,  64,  64,\n",
       "         64,  65,  65,  65,  65,  65,  65,  65,  66,  66,  66,  66,  66,  66,\n",
       "         66,  66,  66,  66,  67,  67,  67,  67,  67,  67,  67,  67,  68,  68,\n",
       "         68,  68,  68,  68,  68,  68,  68,  68,  69,  69,  69,  69,  69,  69,\n",
       "         69,  69,  69,  69,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,\n",
       "         71,  72,  72,  72,  72,  72,  72,  72,  73,  74,  75,  76,  76,  76,\n",
       "         76,  76,  76,  76,  76,  76,  76,  77,  78,  78,  78,  78,  78,  78,\n",
       "         78,  78,  78,  78,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,\n",
       "         80,  80,  80,  80,  80,  80,  80,  80,  80,  80,  81,  81,  81,  81,\n",
       "         81,  81,  81,  81,  81,  81,  82,  82,  82,  82,  82,  82,  82,  82,\n",
       "         82,  82,  83,  83,  83,  83,  83,  83,  83,  83,  83,  83,  84,  84,\n",
       "         84,  84,  84,  84,  84,  85,  85,  85,  86,  87,  87,  87,  87,  87,\n",
       "         87,  87,  87,  87,  87,  88,  88,  88,  88,  88,  88,  88,  88,  88,\n",
       "         88,  89,  89,  89,  89,  89,  89,  89,  89,  89,  89,  90,  90,  90,\n",
       "         90,  90,  90,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  92,\n",
       "         92,  92,  92,  92,  92,  92,  92,  92,  92,  93,  93,  93,  93,  93,\n",
       "         93,  93,  93,  93,  93,  94,  94,  94,  94,  94,  94,  94,  94,  94,\n",
       "         94,  95,  95,  95,  95,  96,  96,  96,  96,  96,  96,  96,  96,  96,\n",
       "         96,  97,  97,  97,  97,  97,  97,  97,  97,  97,  97,  98,  98,  98,\n",
       "         98,  98,  98,  98,  98,  98,  98,  99,  99,  99,  99, 100, 100, 100,\n",
       "        100, 100, 100, 100, 100, 100, 100, 101, 101, 101, 101, 101, 101, 101,\n",
       "        101, 101, 101, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 103,\n",
       "        103, 103, 103, 103, 103, 103, 103, 103, 103, 104, 104, 104, 104, 104,\n",
       "        104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 105, 105, 105, 105,\n",
       "        106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 107, 107, 107, 107,\n",
       "        107, 107, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 109, 109,\n",
       "        109, 109, 109, 109, 109, 109, 109, 109, 110, 110, 110, 110, 110, 110,\n",
       "        110, 110, 110, 110, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111,\n",
       "        112, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 114, 114, 114,\n",
       "        114, 114, 114, 114, 114, 114, 114, 115, 115, 116, 116, 116, 116, 116,\n",
       "        116, 116, 116, 116, 116, 117, 117, 117, 117, 117, 117, 117, 117, 117,\n",
       "        117, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 119, 119, 119,\n",
       "        119, 119, 119, 119, 119, 119, 119, 120, 120, 120, 120, 120, 120, 120,\n",
       "        120, 120, 120, 121, 121, 121, 122, 122, 122, 122, 122, 122, 122, 122,\n",
       "        122, 122, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 124, 124,\n",
       "        124, 124, 124, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 126,\n",
       "        126, 126, 126, 126, 126, 126, 126, 126, 126, 127])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = etedge_index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "61eed423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 1, 2]), tensor([0, 1, 2, 3]), tensor([2, 3, 3, 1]))"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ei = torch.as_tensor([[0, 0, 1, 2],\n",
    "                              [0, 1, 2, 3]])\n",
    "structured_negative_sampling(ei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6c2b1d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1,\n",
       "         1: 1,\n",
       "         2: 1,\n",
       "         3: 1,\n",
       "         4: 1,\n",
       "         5: 1,\n",
       "         6: 1,\n",
       "         7: 1,\n",
       "         8: 1,\n",
       "         9: 1,\n",
       "         10: 1,\n",
       "         11: 1,\n",
       "         12: 1,\n",
       "         13: 1,\n",
       "         14: 1,\n",
       "         15: 1,\n",
       "         16: 1,\n",
       "         17: 1,\n",
       "         18: 1,\n",
       "         19: 1,\n",
       "         20: 1,\n",
       "         21: 1,\n",
       "         22: 1,\n",
       "         23: 1,\n",
       "         24: 1,\n",
       "         25: 1,\n",
       "         26: 1,\n",
       "         27: 1,\n",
       "         28: 1,\n",
       "         29: 1,\n",
       "         30: 1,\n",
       "         31: 1,\n",
       "         32: 1,\n",
       "         33: 1,\n",
       "         34: 1,\n",
       "         35: 1,\n",
       "         36: 1,\n",
       "         37: 1,\n",
       "         38: 1,\n",
       "         39: 1,\n",
       "         40: 1,\n",
       "         41: 1,\n",
       "         42: 1,\n",
       "         43: 1,\n",
       "         44: 1,\n",
       "         45: 1,\n",
       "         46: 1,\n",
       "         47: 1,\n",
       "         48: 1,\n",
       "         49: 1,\n",
       "         50: 1,\n",
       "         51: 1,\n",
       "         52: 1,\n",
       "         53: 1,\n",
       "         54: 1,\n",
       "         55: 1,\n",
       "         56: 1,\n",
       "         57: 1,\n",
       "         58: 1,\n",
       "         59: 1,\n",
       "         60: 1,\n",
       "         61: 1,\n",
       "         62: 1,\n",
       "         63: 1,\n",
       "         64: 1,\n",
       "         65: 1,\n",
       "         66: 1,\n",
       "         67: 1,\n",
       "         68: 1,\n",
       "         69: 1,\n",
       "         70: 1,\n",
       "         71: 1,\n",
       "         72: 1,\n",
       "         73: 1,\n",
       "         74: 1,\n",
       "         75: 1,\n",
       "         76: 1,\n",
       "         77: 1,\n",
       "         78: 1,\n",
       "         79: 1,\n",
       "         80: 1,\n",
       "         81: 1,\n",
       "         82: 1,\n",
       "         83: 1,\n",
       "         84: 1,\n",
       "         85: 1,\n",
       "         86: 1,\n",
       "         87: 1,\n",
       "         88: 1,\n",
       "         89: 1,\n",
       "         90: 1,\n",
       "         91: 1,\n",
       "         92: 1,\n",
       "         93: 1,\n",
       "         94: 1,\n",
       "         95: 1,\n",
       "         96: 1,\n",
       "         97: 1,\n",
       "         98: 1,\n",
       "         99: 1,\n",
       "         100: 1,\n",
       "         101: 1,\n",
       "         102: 1,\n",
       "         103: 1,\n",
       "         104: 1,\n",
       "         105: 1,\n",
       "         106: 1,\n",
       "         107: 1,\n",
       "         108: 1,\n",
       "         109: 1,\n",
       "         110: 1,\n",
       "         111: 1,\n",
       "         112: 1,\n",
       "         113: 1,\n",
       "         114: 1,\n",
       "         115: 1,\n",
       "         116: 1,\n",
       "         117: 1,\n",
       "         118: 1,\n",
       "         119: 1,\n",
       "         120: 1,\n",
       "         121: 1,\n",
       "         122: 1,\n",
       "         123: 1,\n",
       "         124: 1,\n",
       "         125: 1,\n",
       "         126: 1,\n",
       "         127: 1,\n",
       "         128: 1,\n",
       "         129: 1,\n",
       "         130: 1,\n",
       "         131: 1,\n",
       "         132: 1,\n",
       "         133: 1,\n",
       "         134: 1,\n",
       "         135: 1,\n",
       "         136: 1,\n",
       "         137: 1,\n",
       "         138: 1,\n",
       "         139: 1,\n",
       "         140: 1,\n",
       "         141: 1,\n",
       "         142: 1,\n",
       "         143: 1,\n",
       "         144: 1,\n",
       "         145: 1,\n",
       "         146: 1,\n",
       "         147: 1,\n",
       "         148: 1,\n",
       "         149: 1,\n",
       "         150: 1,\n",
       "         151: 1,\n",
       "         152: 1,\n",
       "         153: 1,\n",
       "         154: 1,\n",
       "         155: 1,\n",
       "         156: 1,\n",
       "         157: 1,\n",
       "         158: 1,\n",
       "         159: 1,\n",
       "         160: 1,\n",
       "         161: 1,\n",
       "         162: 1,\n",
       "         163: 1,\n",
       "         164: 1,\n",
       "         165: 1,\n",
       "         166: 1,\n",
       "         167: 1,\n",
       "         168: 1,\n",
       "         169: 1,\n",
       "         170: 1,\n",
       "         171: 1,\n",
       "         172: 1,\n",
       "         173: 1,\n",
       "         174: 1,\n",
       "         175: 1,\n",
       "         176: 1,\n",
       "         177: 1,\n",
       "         178: 1,\n",
       "         179: 1,\n",
       "         180: 1,\n",
       "         181: 1,\n",
       "         182: 1,\n",
       "         183: 1,\n",
       "         184: 1,\n",
       "         185: 1,\n",
       "         186: 1,\n",
       "         187: 1,\n",
       "         188: 1,\n",
       "         189: 1,\n",
       "         190: 1,\n",
       "         191: 1,\n",
       "         192: 1,\n",
       "         193: 1,\n",
       "         194: 1,\n",
       "         195: 1,\n",
       "         196: 1,\n",
       "         197: 1,\n",
       "         198: 1,\n",
       "         199: 1,\n",
       "         200: 1,\n",
       "         201: 1,\n",
       "         202: 1,\n",
       "         203: 1,\n",
       "         204: 1,\n",
       "         205: 1,\n",
       "         206: 1,\n",
       "         207: 1,\n",
       "         208: 1,\n",
       "         209: 1,\n",
       "         210: 1,\n",
       "         211: 1,\n",
       "         212: 1,\n",
       "         213: 1,\n",
       "         214: 1,\n",
       "         215: 1,\n",
       "         216: 1,\n",
       "         217: 1,\n",
       "         218: 1,\n",
       "         219: 1,\n",
       "         220: 1,\n",
       "         221: 1,\n",
       "         222: 1,\n",
       "         223: 1,\n",
       "         224: 1,\n",
       "         225: 1,\n",
       "         226: 1,\n",
       "         227: 1,\n",
       "         228: 1,\n",
       "         229: 1,\n",
       "         230: 1,\n",
       "         231: 1,\n",
       "         232: 1,\n",
       "         233: 1,\n",
       "         234: 1,\n",
       "         235: 1,\n",
       "         236: 1,\n",
       "         237: 1,\n",
       "         238: 1,\n",
       "         239: 1,\n",
       "         240: 1,\n",
       "         241: 1,\n",
       "         242: 1,\n",
       "         243: 1,\n",
       "         244: 1,\n",
       "         245: 1,\n",
       "         246: 1,\n",
       "         247: 1,\n",
       "         248: 1,\n",
       "         249: 1,\n",
       "         250: 1,\n",
       "         251: 1,\n",
       "         252: 1,\n",
       "         253: 1,\n",
       "         254: 1,\n",
       "         255: 1,\n",
       "         256: 1,\n",
       "         257: 1,\n",
       "         258: 1,\n",
       "         259: 1,\n",
       "         260: 1,\n",
       "         261: 1,\n",
       "         262: 1,\n",
       "         263: 1,\n",
       "         264: 1,\n",
       "         265: 1,\n",
       "         266: 1,\n",
       "         267: 1,\n",
       "         268: 1,\n",
       "         269: 1,\n",
       "         270: 1,\n",
       "         271: 1,\n",
       "         272: 1,\n",
       "         273: 1,\n",
       "         274: 1,\n",
       "         275: 1,\n",
       "         276: 1,\n",
       "         277: 1,\n",
       "         278: 1,\n",
       "         279: 1,\n",
       "         280: 1,\n",
       "         281: 1,\n",
       "         282: 1,\n",
       "         283: 1,\n",
       "         284: 1,\n",
       "         285: 1,\n",
       "         286: 1,\n",
       "         287: 1,\n",
       "         288: 1,\n",
       "         289: 1,\n",
       "         290: 1,\n",
       "         291: 1,\n",
       "         292: 1,\n",
       "         293: 1,\n",
       "         294: 1,\n",
       "         295: 1,\n",
       "         296: 1,\n",
       "         297: 1,\n",
       "         298: 1,\n",
       "         299: 1,\n",
       "         300: 1,\n",
       "         301: 1,\n",
       "         302: 1,\n",
       "         303: 1,\n",
       "         304: 1,\n",
       "         305: 1,\n",
       "         306: 1,\n",
       "         307: 1,\n",
       "         308: 1,\n",
       "         309: 1,\n",
       "         310: 1,\n",
       "         311: 1,\n",
       "         312: 1,\n",
       "         313: 1,\n",
       "         314: 1,\n",
       "         315: 1,\n",
       "         316: 1,\n",
       "         317: 1,\n",
       "         318: 1,\n",
       "         319: 1,\n",
       "         320: 1,\n",
       "         321: 1,\n",
       "         322: 2,\n",
       "         323: 1,\n",
       "         324: 1,\n",
       "         325: 1,\n",
       "         326: 1,\n",
       "         327: 1,\n",
       "         328: 1,\n",
       "         329: 1,\n",
       "         330: 1,\n",
       "         331: 1,\n",
       "         332: 1,\n",
       "         333: 1,\n",
       "         334: 1,\n",
       "         335: 1,\n",
       "         336: 1,\n",
       "         337: 1,\n",
       "         338: 1,\n",
       "         339: 1,\n",
       "         340: 1,\n",
       "         341: 1,\n",
       "         342: 1,\n",
       "         343: 1,\n",
       "         344: 1,\n",
       "         345: 1,\n",
       "         346: 1,\n",
       "         347: 1,\n",
       "         348: 1,\n",
       "         349: 1,\n",
       "         350: 1,\n",
       "         351: 1,\n",
       "         352: 1,\n",
       "         353: 1,\n",
       "         354: 1,\n",
       "         355: 1,\n",
       "         356: 1,\n",
       "         357: 1,\n",
       "         358: 1,\n",
       "         359: 1,\n",
       "         360: 1,\n",
       "         361: 1,\n",
       "         362: 1,\n",
       "         363: 1,\n",
       "         364: 1,\n",
       "         365: 1,\n",
       "         366: 1,\n",
       "         367: 1,\n",
       "         368: 1,\n",
       "         369: 1,\n",
       "         370: 1,\n",
       "         371: 1,\n",
       "         372: 1,\n",
       "         373: 1,\n",
       "         374: 1,\n",
       "         375: 1,\n",
       "         376: 1,\n",
       "         377: 1,\n",
       "         378: 1,\n",
       "         379: 1,\n",
       "         380: 1,\n",
       "         381: 1,\n",
       "         382: 1,\n",
       "         383: 1,\n",
       "         384: 1,\n",
       "         385: 1,\n",
       "         386: 1,\n",
       "         387: 1,\n",
       "         388: 1,\n",
       "         389: 1,\n",
       "         390: 1,\n",
       "         391: 1,\n",
       "         392: 1,\n",
       "         393: 1,\n",
       "         394: 1,\n",
       "         395: 1,\n",
       "         396: 1,\n",
       "         397: 1,\n",
       "         398: 1,\n",
       "         399: 1,\n",
       "         400: 1,\n",
       "         401: 1,\n",
       "         402: 1,\n",
       "         403: 1,\n",
       "         404: 1,\n",
       "         405: 1,\n",
       "         406: 1,\n",
       "         407: 1,\n",
       "         408: 1,\n",
       "         409: 1,\n",
       "         410: 1,\n",
       "         411: 1,\n",
       "         412: 1,\n",
       "         413: 1,\n",
       "         414: 1,\n",
       "         415: 1,\n",
       "         416: 1,\n",
       "         417: 1,\n",
       "         418: 1,\n",
       "         419: 1,\n",
       "         420: 1,\n",
       "         421: 1,\n",
       "         422: 1,\n",
       "         423: 1,\n",
       "         424: 1,\n",
       "         425: 1,\n",
       "         426: 1,\n",
       "         427: 1,\n",
       "         428: 1,\n",
       "         429: 1,\n",
       "         430: 1,\n",
       "         431: 1,\n",
       "         432: 1,\n",
       "         433: 1,\n",
       "         434: 1,\n",
       "         435: 1,\n",
       "         436: 1,\n",
       "         437: 1,\n",
       "         438: 1,\n",
       "         439: 1,\n",
       "         440: 1,\n",
       "         441: 1,\n",
       "         442: 1,\n",
       "         443: 1,\n",
       "         444: 1,\n",
       "         445: 1,\n",
       "         446: 1,\n",
       "         447: 1,\n",
       "         448: 1,\n",
       "         449: 1,\n",
       "         450: 1,\n",
       "         451: 1,\n",
       "         452: 1,\n",
       "         453: 1,\n",
       "         454: 1,\n",
       "         455: 1,\n",
       "         456: 1,\n",
       "         457: 1,\n",
       "         458: 1,\n",
       "         459: 1,\n",
       "         460: 1,\n",
       "         461: 1,\n",
       "         462: 1,\n",
       "         463: 1,\n",
       "         464: 1,\n",
       "         465: 1,\n",
       "         466: 1,\n",
       "         467: 1,\n",
       "         468: 1,\n",
       "         469: 1,\n",
       "         470: 1,\n",
       "         471: 1,\n",
       "         472: 1,\n",
       "         473: 1,\n",
       "         474: 1,\n",
       "         475: 1,\n",
       "         476: 1,\n",
       "         477: 1,\n",
       "         478: 1,\n",
       "         479: 1,\n",
       "         480: 1,\n",
       "         481: 1,\n",
       "         482: 1,\n",
       "         483: 1,\n",
       "         484: 1,\n",
       "         485: 1,\n",
       "         486: 1,\n",
       "         487: 1,\n",
       "         488: 1,\n",
       "         489: 1,\n",
       "         490: 1,\n",
       "         491: 1,\n",
       "         492: 1,\n",
       "         493: 1,\n",
       "         494: 1,\n",
       "         495: 1,\n",
       "         496: 1,\n",
       "         497: 1,\n",
       "         498: 1,\n",
       "         499: 1,\n",
       "         500: 1,\n",
       "         501: 1,\n",
       "         502: 1,\n",
       "         503: 1,\n",
       "         504: 1,\n",
       "         505: 1,\n",
       "         506: 1,\n",
       "         507: 1,\n",
       "         508: 1,\n",
       "         509: 1,\n",
       "         510: 1,\n",
       "         511: 1,\n",
       "         512: 1,\n",
       "         513: 1,\n",
       "         514: 1,\n",
       "         515: 1,\n",
       "         516: 1,\n",
       "         517: 1,\n",
       "         518: 1,\n",
       "         519: 1,\n",
       "         520: 1,\n",
       "         521: 1,\n",
       "         522: 1,\n",
       "         523: 1,\n",
       "         524: 1,\n",
       "         525: 1,\n",
       "         526: 1,\n",
       "         527: 1,\n",
       "         528: 1,\n",
       "         529: 1,\n",
       "         530: 1,\n",
       "         531: 1,\n",
       "         532: 1,\n",
       "         533: 1,\n",
       "         534: 1,\n",
       "         535: 1,\n",
       "         536: 1,\n",
       "         537: 1,\n",
       "         538: 1,\n",
       "         539: 1,\n",
       "         540: 1,\n",
       "         541: 1,\n",
       "         542: 1,\n",
       "         543: 1,\n",
       "         544: 1,\n",
       "         545: 1,\n",
       "         546: 1,\n",
       "         547: 1,\n",
       "         548: 1,\n",
       "         549: 1,\n",
       "         550: 1,\n",
       "         551: 1,\n",
       "         552: 1,\n",
       "         553: 1,\n",
       "         554: 1,\n",
       "         555: 1,\n",
       "         556: 1,\n",
       "         557: 1,\n",
       "         558: 1,\n",
       "         559: 1,\n",
       "         560: 1,\n",
       "         561: 1,\n",
       "         562: 1,\n",
       "         563: 1,\n",
       "         564: 1,\n",
       "         565: 1,\n",
       "         566: 1,\n",
       "         567: 1,\n",
       "         568: 1,\n",
       "         569: 1,\n",
       "         570: 1,\n",
       "         571: 1,\n",
       "         572: 1,\n",
       "         573: 1,\n",
       "         574: 1,\n",
       "         575: 1,\n",
       "         576: 1,\n",
       "         577: 1,\n",
       "         578: 1,\n",
       "         579: 1,\n",
       "         580: 1,\n",
       "         581: 1,\n",
       "         582: 1,\n",
       "         583: 1,\n",
       "         584: 1,\n",
       "         585: 1,\n",
       "         586: 1,\n",
       "         587: 1,\n",
       "         588: 1,\n",
       "         589: 1,\n",
       "         590: 1,\n",
       "         591: 1,\n",
       "         592: 1,\n",
       "         593: 1,\n",
       "         594: 1,\n",
       "         595: 1,\n",
       "         596: 1,\n",
       "         597: 1,\n",
       "         598: 1,\n",
       "         599: 1,\n",
       "         600: 1,\n",
       "         601: 1,\n",
       "         602: 1,\n",
       "         603: 1,\n",
       "         604: 1,\n",
       "         605: 1,\n",
       "         606: 1,\n",
       "         607: 1,\n",
       "         608: 1,\n",
       "         609: 1,\n",
       "         610: 1,\n",
       "         611: 1,\n",
       "         612: 1,\n",
       "         613: 1,\n",
       "         614: 1,\n",
       "         615: 1,\n",
       "         616: 1,\n",
       "         617: 1,\n",
       "         618: 1,\n",
       "         619: 1,\n",
       "         620: 1,\n",
       "         621: 1,\n",
       "         622: 1,\n",
       "         623: 1,\n",
       "         624: 1,\n",
       "         625: 1,\n",
       "         626: 1,\n",
       "         627: 1,\n",
       "         628: 1,\n",
       "         629: 1,\n",
       "         630: 1,\n",
       "         631: 1,\n",
       "         632: 1,\n",
       "         633: 1,\n",
       "         634: 1,\n",
       "         635: 1,\n",
       "         636: 1,\n",
       "         637: 1,\n",
       "         638: 1,\n",
       "         639: 1,\n",
       "         640: 1,\n",
       "         641: 2,\n",
       "         642: 1,\n",
       "         643: 1,\n",
       "         644: 1,\n",
       "         645: 1,\n",
       "         646: 1,\n",
       "         647: 1,\n",
       "         648: 1,\n",
       "         649: 1,\n",
       "         650: 1,\n",
       "         651: 1,\n",
       "         652: 1,\n",
       "         653: 1,\n",
       "         654: 1,\n",
       "         655: 1,\n",
       "         656: 1,\n",
       "         657: 1,\n",
       "         658: 1,\n",
       "         659: 1,\n",
       "         660: 1,\n",
       "         661: 1,\n",
       "         662: 1,\n",
       "         663: 1,\n",
       "         664: 1,\n",
       "         665: 1,\n",
       "         666: 1,\n",
       "         667: 1,\n",
       "         668: 1,\n",
       "         669: 1,\n",
       "         670: 1,\n",
       "         671: 1,\n",
       "         672: 1,\n",
       "         673: 1,\n",
       "         674: 1,\n",
       "         675: 1,\n",
       "         676: 1,\n",
       "         677: 1,\n",
       "         678: 1,\n",
       "         679: 1,\n",
       "         680: 1,\n",
       "         681: 1,\n",
       "         682: 1,\n",
       "         683: 1,\n",
       "         684: 1,\n",
       "         685: 1,\n",
       "         686: 1,\n",
       "         687: 1,\n",
       "         688: 1,\n",
       "         689: 1,\n",
       "         690: 1,\n",
       "         691: 1,\n",
       "         692: 1,\n",
       "         693: 1,\n",
       "         694: 1,\n",
       "         695: 1,\n",
       "         696: 1,\n",
       "         697: 1,\n",
       "         698: 1,\n",
       "         699: 1,\n",
       "         700: 1,\n",
       "         701: 1,\n",
       "         702: 1,\n",
       "         703: 1,\n",
       "         704: 1,\n",
       "         705: 1,\n",
       "         706: 1,\n",
       "         707: 1,\n",
       "         708: 1,\n",
       "         709: 1,\n",
       "         710: 1,\n",
       "         711: 1,\n",
       "         712: 1,\n",
       "         713: 1,\n",
       "         714: 1,\n",
       "         715: 1,\n",
       "         716: 1,\n",
       "         717: 1,\n",
       "         718: 1,\n",
       "         719: 1,\n",
       "         720: 1,\n",
       "         721: 1,\n",
       "         722: 1,\n",
       "         723: 1,\n",
       "         724: 1,\n",
       "         725: 1,\n",
       "         726: 1,\n",
       "         727: 1,\n",
       "         728: 1,\n",
       "         729: 1,\n",
       "         730: 1,\n",
       "         731: 1,\n",
       "         732: 1,\n",
       "         733: 1,\n",
       "         734: 1,\n",
       "         735: 1,\n",
       "         736: 1,\n",
       "         737: 1,\n",
       "         738: 1,\n",
       "         739: 1,\n",
       "         740: 1,\n",
       "         741: 1,\n",
       "         742: 1,\n",
       "         743: 1,\n",
       "         744: 1,\n",
       "         745: 1,\n",
       "         746: 1,\n",
       "         747: 1,\n",
       "         748: 1,\n",
       "         749: 1,\n",
       "         750: 1,\n",
       "         751: 1,\n",
       "         752: 1,\n",
       "         753: 1,\n",
       "         754: 1,\n",
       "         755: 1,\n",
       "         756: 1,\n",
       "         757: 1,\n",
       "         758: 1,\n",
       "         759: 1,\n",
       "         760: 1,\n",
       "         761: 1,\n",
       "         762: 1,\n",
       "         763: 1,\n",
       "         764: 1,\n",
       "         765: 1,\n",
       "         766: 1,\n",
       "         767: 1,\n",
       "         768: 1,\n",
       "         769: 1,\n",
       "         770: 1,\n",
       "         771: 1,\n",
       "         772: 1,\n",
       "         773: 1,\n",
       "         774: 1,\n",
       "         775: 1,\n",
       "         776: 1,\n",
       "         777: 1,\n",
       "         778: 1,\n",
       "         779: 1,\n",
       "         780: 1,\n",
       "         781: 1,\n",
       "         782: 1,\n",
       "         783: 1,\n",
       "         784: 1,\n",
       "         785: 1,\n",
       "         786: 1,\n",
       "         787: 1,\n",
       "         788: 1,\n",
       "         789: 1,\n",
       "         790: 1,\n",
       "         791: 1,\n",
       "         792: 1,\n",
       "         793: 1,\n",
       "         794: 1,\n",
       "         795: 1,\n",
       "         796: 1,\n",
       "         797: 1,\n",
       "         798: 1,\n",
       "         799: 1,\n",
       "         800: 1,\n",
       "         801: 1,\n",
       "         802: 1,\n",
       "         803: 1,\n",
       "         804: 1,\n",
       "         805: 1,\n",
       "         806: 1,\n",
       "         807: 1,\n",
       "         808: 1,\n",
       "         809: 1,\n",
       "         810: 1,\n",
       "         811: 1,\n",
       "         812: 1,\n",
       "         813: 1,\n",
       "         814: 1,\n",
       "         815: 1,\n",
       "         816: 1,\n",
       "         817: 1,\n",
       "         818: 1,\n",
       "         819: 1,\n",
       "         820: 1,\n",
       "         821: 1,\n",
       "         822: 1,\n",
       "         823: 1,\n",
       "         824: 1,\n",
       "         825: 1,\n",
       "         826: 1,\n",
       "         827: 1,\n",
       "         828: 1,\n",
       "         829: 1,\n",
       "         830: 1,\n",
       "         831: 1,\n",
       "         832: 1,\n",
       "         833: 1,\n",
       "         834: 1,\n",
       "         835: 1,\n",
       "         836: 1,\n",
       "         837: 1,\n",
       "         838: 1,\n",
       "         839: 1,\n",
       "         840: 1,\n",
       "         841: 1,\n",
       "         842: 1,\n",
       "         843: 1,\n",
       "         844: 1,\n",
       "         845: 1,\n",
       "         846: 1,\n",
       "         847: 1,\n",
       "         848: 1,\n",
       "         849: 1,\n",
       "         850: 1,\n",
       "         851: 1,\n",
       "         852: 1,\n",
       "         853: 1,\n",
       "         854: 1,\n",
       "         855: 1,\n",
       "         856: 1,\n",
       "         857: 1,\n",
       "         858: 1,\n",
       "         859: 1,\n",
       "         860: 1,\n",
       "         861: 1,\n",
       "         862: 1,\n",
       "         863: 1,\n",
       "         864: 1,\n",
       "         865: 1,\n",
       "         866: 1})"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(edge_index[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748e1f74",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a885b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../../../data/processed\"\n",
    "separate_date = \"2022-01\"\n",
    "\n",
    "# Load data\n",
    "reviews = pd.read_parquet(f\"{directory}/reviews_with_interactions.parquet\")\n",
    "listings = pd.read_parquet(f\"{directory}/listings_with_interactions.parquet\")\n",
    "reviewers = pd.read_parquet(f\"{directory}/reviewers_with_interactions.parquet\")\n",
    "\n",
    "print(\"Full: \", len(reviews), len(listings), len(reviewers))\n",
    "# Prepare data and graph\n",
    "(\n",
    "    train_reviews,\n",
    "    train_listings,\n",
    "    train_reviewers,\n",
    "    test_reviews,\n",
    "    test_listings,\n",
    "    test_reviewers,\n",
    ") = train_test_split(reviews, listings, reviewers, separate_date)\n",
    "test_listings2dict = get_entity2dict(test_listings, \"listing_id\")\n",
    "reverse_test_listings2dict = {k: v for v, k in test_listings2dict.items()}\n",
    "test_reviewers2dict = get_entity2dict(test_reviewers, \"reviewer_id\")\n",
    "reverse_test_reviewers2dict = {k: v for v, k in test_reviewers2dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5d93c5d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[182, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[850, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 853],\n",
      "    edge_label=[853],\n",
      "    edge_label_index=[2, 853]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 917] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[179, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[874, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 885],\n",
      "    edge_label=[885],\n",
      "    edge_label_index=[2, 885]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 956] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[178, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[948, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 949],\n",
      "    edge_label=[949],\n",
      "    edge_label_index=[2, 949]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1013] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[173, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[895, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 895],\n",
      "    edge_label=[895],\n",
      "    edge_label_index=[2, 895]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 945] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[165, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[896, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 900],\n",
      "    edge_label=[900],\n",
      "    edge_label_index=[2, 900]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 945] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[188, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[958, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 963],\n",
      "    edge_label=[963],\n",
      "    edge_label_index=[2, 963]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1034] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[163, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[866, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 872],\n",
      "    edge_label=[872],\n",
      "    edge_label_index=[2, 872]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 910] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[182, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[865, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 873],\n",
      "    edge_label=[873],\n",
      "    edge_label_index=[2, 873]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 952] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[195, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[904, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 914],\n",
      "    edge_label=[914],\n",
      "    edge_label_index=[2, 914]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1000] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[178, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[853, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 857],\n",
      "    edge_label=[857],\n",
      "    edge_label_index=[2, 857]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 917] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[192, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[971, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 975],\n",
      "    edge_label=[975],\n",
      "    edge_label_index=[2, 975]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1048] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[167, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[846, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 848],\n",
      "    edge_label=[848],\n",
      "    edge_label_index=[2, 848]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 894] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[180, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[906, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 910],\n",
      "    edge_label=[910],\n",
      "    edge_label_index=[2, 910]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 972] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[172, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[880, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 883],\n",
      "    edge_label=[883],\n",
      "    edge_label_index=[2, 883]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 932] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[176, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[929, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 932],\n",
      "    edge_label=[932],\n",
      "    edge_label_index=[2, 932]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 989] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[185, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[916, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 921],\n",
      "    edge_label=[921],\n",
      "    edge_label_index=[2, 921]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 992] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[176, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[879, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 882],\n",
      "    edge_label=[882],\n",
      "    edge_label_index=[2, 882]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 941] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[197, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[896, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 901],\n",
      "    edge_label=[901],\n",
      "    edge_label_index=[2, 901]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 975] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[170, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[845, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 846],\n",
      "    edge_label=[846],\n",
      "    edge_label_index=[2, 846]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 893] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[176, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[881, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 883],\n",
      "    edge_label=[883],\n",
      "    edge_label_index=[2, 883]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 937] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[177, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[879, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 882],\n",
      "    edge_label=[882],\n",
      "    edge_label_index=[2, 882]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 939] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[187, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[862, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 868],\n",
      "    edge_label=[868],\n",
      "    edge_label_index=[2, 868]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 944] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[199, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[905, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 911],\n",
      "    edge_label=[911],\n",
      "    edge_label_index=[2, 911]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1014] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[172, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[931, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 935],\n",
      "    edge_label=[935],\n",
      "    edge_label_index=[2, 935]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 988] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[192, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[936, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 940],\n",
      "    edge_label=[940],\n",
      "    edge_label_index=[2, 940]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1017] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[183, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[951, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 954],\n",
      "    edge_label=[954],\n",
      "    edge_label_index=[2, 954]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1014] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[179, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[894, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 897],\n",
      "    edge_label=[897],\n",
      "    edge_label_index=[2, 897]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 958] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[181, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[971, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 974],\n",
      "    edge_label=[974],\n",
      "    edge_label_index=[2, 974]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1038] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[184, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[909, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 912],\n",
      "    edge_label=[912],\n",
      "    edge_label_index=[2, 912]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 974] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[181, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[877, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 881],\n",
      "    edge_label=[881],\n",
      "    edge_label_index=[2, 881]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 935] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[178, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[904, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 906],\n",
      "    edge_label=[906],\n",
      "    edge_label_index=[2, 906]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 969] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[184, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[851, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 855],\n",
      "    edge_label=[855],\n",
      "    edge_label_index=[2, 855]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 918] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[183, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[865, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 866],\n",
      "    edge_label=[866],\n",
      "    edge_label_index=[2, 866]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 935] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[171, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[881, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 882],\n",
      "    edge_label=[882],\n",
      "    edge_label_index=[2, 882]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 936] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[176, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[870, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 880],\n",
      "    edge_label=[880],\n",
      "    edge_label_index=[2, 880]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 936] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[163, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[916, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 918],\n",
      "    edge_label=[918],\n",
      "    edge_label_index=[2, 918]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 958] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[186, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[865, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 867],\n",
      "    edge_label=[867],\n",
      "    edge_label_index=[2, 867]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 951] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[189, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[943, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 947],\n",
      "    edge_label=[947],\n",
      "    edge_label_index=[2, 947]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1017] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[175, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[868, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 870],\n",
      "    edge_label=[870],\n",
      "    edge_label_index=[2, 870]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 929] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[196, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[983, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 984],\n",
      "    edge_label=[984],\n",
      "    edge_label_index=[2, 984]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1065] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[182, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[879, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 880],\n",
      "    edge_label=[880],\n",
      "    edge_label_index=[2, 880]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 939] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[185, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[869, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 873],\n",
      "    edge_label=[873],\n",
      "    edge_label_index=[2, 873]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 943] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[185, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[898, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 900],\n",
      "    edge_label=[900],\n",
      "    edge_label_index=[2, 900]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 963] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[171, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[920, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 926],\n",
      "    edge_label=[926],\n",
      "    edge_label_index=[2, 926]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 976] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[177, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[899, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 902],\n",
      "    edge_label=[902],\n",
      "    edge_label_index=[2, 902]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 964] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[181, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[925, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 932],\n",
      "    edge_label=[932],\n",
      "    edge_label_index=[2, 932]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 995] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[190, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[925, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 930],\n",
      "    edge_label=[930],\n",
      "    edge_label_index=[2, 930]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1003] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[171, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[873, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 875],\n",
      "    edge_label=[875],\n",
      "    edge_label_index=[2, 875]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 929] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[188, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[905, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 912],\n",
      "    edge_label=[912],\n",
      "    edge_label_index=[2, 912]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 980] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[188, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[985, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 991],\n",
      "    edge_label=[991],\n",
      "    edge_label_index=[2, 991]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1063] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[173, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[871, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 873],\n",
      "    edge_label=[873],\n",
      "    edge_label_index=[2, 873]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 923] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[187, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[978, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 984],\n",
      "    edge_label=[984],\n",
      "    edge_label_index=[2, 984]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1053] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[178, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[900, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 903],\n",
      "    edge_label=[903],\n",
      "    edge_label_index=[2, 903]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 961] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[169, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[885, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 887],\n",
      "    edge_label=[887],\n",
      "    edge_label_index=[2, 887]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 932] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[190, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[975, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 978],\n",
      "    edge_label=[978],\n",
      "    edge_label_index=[2, 978]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1048] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[183, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[899, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 901],\n",
      "    edge_label=[901],\n",
      "    edge_label_index=[2, 901]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 963] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[184, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[904, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 912],\n",
      "    edge_label=[912],\n",
      "    edge_label_index=[2, 912]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 974] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[186, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[964, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 967],\n",
      "    edge_label=[967],\n",
      "    edge_label_index=[2, 967]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1033] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[174, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[908, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 911],\n",
      "    edge_label=[911],\n",
      "    edge_label_index=[2, 911]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 970] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[190, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[942, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 948],\n",
      "    edge_label=[948],\n",
      "    edge_label_index=[2, 948]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1013] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[170, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[878, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 883],\n",
      "    edge_label=[883],\n",
      "    edge_label_index=[2, 883]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 932] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[172, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[851, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 854],\n",
      "    edge_label=[854],\n",
      "    edge_label_index=[2, 854]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 907] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[186, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[887, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 891],\n",
      "    edge_label=[891],\n",
      "    edge_label_index=[2, 891]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 958] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[172, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[874, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 883],\n",
      "    edge_label=[883],\n",
      "    edge_label_index=[2, 883]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 946] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[182, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[973, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 977],\n",
      "    edge_label=[977],\n",
      "    edge_label_index=[2, 977]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1044] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[174, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[907, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 913],\n",
      "    edge_label=[913],\n",
      "    edge_label_index=[2, 913]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 970] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[181, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[852, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 858],\n",
      "    edge_label=[858],\n",
      "    edge_label_index=[2, 858]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 925] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[181, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[870, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 872],\n",
      "    edge_label=[872],\n",
      "    edge_label_index=[2, 872]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 927] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[177, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[923, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 924],\n",
      "    edge_label=[924],\n",
      "    edge_label_index=[2, 924]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 994] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[163, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[834, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 837],\n",
      "    edge_label=[837],\n",
      "    edge_label_index=[2, 837]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 882] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[194, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[957, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 959],\n",
      "    edge_label=[959],\n",
      "    edge_label_index=[2, 959]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1029] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[177, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[931, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 937],\n",
      "    edge_label=[937],\n",
      "    edge_label_index=[2, 937]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 992] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[175, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[941, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 951],\n",
      "    edge_label=[951],\n",
      "    edge_label_index=[2, 951]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1005] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[171, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[843, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 846],\n",
      "    edge_label=[846],\n",
      "    edge_label_index=[2, 846]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 898] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[169, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[919, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 921],\n",
      "    edge_label=[921],\n",
      "    edge_label_index=[2, 921]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 969] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[180, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[925, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 930],\n",
      "    edge_label=[930],\n",
      "    edge_label_index=[2, 930]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 990] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[178, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[935, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 937],\n",
      "    edge_label=[937],\n",
      "    edge_label_index=[2, 937]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 997] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[179, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[922, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 928],\n",
      "    edge_label=[928],\n",
      "    edge_label_index=[2, 928]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 989] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[181, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[929, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 930],\n",
      "    edge_label=[930],\n",
      "    edge_label_index=[2, 930]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 987] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[172, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[897, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 904],\n",
      "    edge_label=[904],\n",
      "    edge_label_index=[2, 904]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 954] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[191, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[901, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 911],\n",
      "    edge_label=[911],\n",
      "    edge_label_index=[2, 911]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 979] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[181, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[933, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 935],\n",
      "    edge_label=[935],\n",
      "    edge_label_index=[2, 935]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 994] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[164, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[877, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 880],\n",
      "    edge_label=[880],\n",
      "    edge_label_index=[2, 880]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 926] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[178, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[924, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 927],\n",
      "    edge_label=[927],\n",
      "    edge_label_index=[2, 927]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 985] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[183, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[839, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 843],\n",
      "    edge_label=[843],\n",
      "    edge_label_index=[2, 843]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 905] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[189, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[902, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 909],\n",
      "    edge_label=[909],\n",
      "    edge_label_index=[2, 909]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 981] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[183, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[865, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 870],\n",
      "    edge_label=[870],\n",
      "    edge_label_index=[2, 870]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 929] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[174, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[882, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 887],\n",
      "    edge_label=[887],\n",
      "    edge_label_index=[2, 887]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 946] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[182, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[877, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 878],\n",
      "    edge_label=[878],\n",
      "    edge_label_index=[2, 878]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 944] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[194, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[913, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 918],\n",
      "    edge_label=[918],\n",
      "    edge_label_index=[2, 918]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 994] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[176, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[880, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 887],\n",
      "    edge_label=[887],\n",
      "    edge_label_index=[2, 887]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 942] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[189, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[911, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 915],\n",
      "    edge_label=[915],\n",
      "    edge_label_index=[2, 915]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 987] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[194, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[886, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 890],\n",
      "    edge_label=[890],\n",
      "    edge_label_index=[2, 890]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 967] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[179, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[952, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 953],\n",
      "    edge_label=[953],\n",
      "    edge_label_index=[2, 953]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1011] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[177, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[874, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 880],\n",
      "    edge_label=[880],\n",
      "    edge_label_index=[2, 880]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 931] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[171, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[879, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 881],\n",
      "    edge_label=[881],\n",
      "    edge_label_index=[2, 881]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 937] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[192, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[885, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 887],\n",
      "    edge_label=[887],\n",
      "    edge_label_index=[2, 887]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 965] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[180, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[857, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 858],\n",
      "    edge_label=[858],\n",
      "    edge_label_index=[2, 858]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 916] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[166, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[943, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 946],\n",
      "    edge_label=[946],\n",
      "    edge_label_index=[2, 946]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 989] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[163, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[862, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 866],\n",
      "    edge_label=[866],\n",
      "    edge_label_index=[2, 866]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 915] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[183, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[904, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 905],\n",
      "    edge_label=[905],\n",
      "    edge_label_index=[2, 905]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 967] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[196, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[883, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 886],\n",
      "    edge_label=[886],\n",
      "    edge_label_index=[2, 886]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 987] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[177, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[830, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 838],\n",
      "    edge_label=[838],\n",
      "    edge_label_index=[2, 838]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 900] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[190, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[938, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 939],\n",
      "    edge_label=[939],\n",
      "    edge_label_index=[2, 939]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1014] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[177, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[959, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 966],\n",
      "    edge_label=[966],\n",
      "    edge_label_index=[2, 966]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1023] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[197, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[971, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 973],\n",
      "    edge_label=[973],\n",
      "    edge_label_index=[2, 973]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1056] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[180, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[1002, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 1006],\n",
      "    edge_label=[1006],\n",
      "    edge_label_index=[2, 1006]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1075] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[178, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[958, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 961],\n",
      "    edge_label=[961],\n",
      "    edge_label_index=[2, 961]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1024] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[181, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[931, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 932],\n",
      "    edge_label=[932],\n",
      "    edge_label_index=[2, 932]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 992] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[182, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[914, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 918],\n",
      "    edge_label=[918],\n",
      "    edge_label_index=[2, 918]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 984] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[169, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[867, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 871],\n",
      "    edge_label=[871],\n",
      "    edge_label_index=[2, 871]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 919] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[176, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[864, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 868],\n",
      "    edge_label=[868],\n",
      "    edge_label_index=[2, 868]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 923] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[174, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[891, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 897],\n",
      "    edge_label=[897],\n",
      "    edge_label_index=[2, 897]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 955] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[182, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[923, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 929],\n",
      "    edge_label=[929],\n",
      "    edge_label_index=[2, 929]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 990] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[181, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[981, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 985],\n",
      "    edge_label=[985],\n",
      "    edge_label_index=[2, 985]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1049] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[182, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[917, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 918],\n",
      "    edge_label=[918],\n",
      "    edge_label_index=[2, 918]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 985] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[166, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[901, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 908],\n",
      "    edge_label=[908],\n",
      "    edge_label_index=[2, 908]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 958] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[180, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[982, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 983],\n",
      "    edge_label=[983],\n",
      "    edge_label_index=[2, 983]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1044] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[187, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[931, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 937],\n",
      "    edge_label=[937],\n",
      "    edge_label_index=[2, 937]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 998] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[193, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[861, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 868],\n",
      "    edge_label=[868],\n",
      "    edge_label_index=[2, 868]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 944] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[189, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[925, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 929],\n",
      "    edge_label=[929],\n",
      "    edge_label_index=[2, 929]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 998] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[173, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[975, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 978],\n",
      "    edge_label=[978],\n",
      "    edge_label_index=[2, 978]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1031] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[166, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[837, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 840],\n",
      "    edge_label=[840],\n",
      "    edge_label_index=[2, 840]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 892] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[185, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[863, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 868],\n",
      "    edge_label=[868],\n",
      "    edge_label_index=[2, 868]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 951] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[180, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[930, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 935],\n",
      "    edge_label=[935],\n",
      "    edge_label_index=[2, 935]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1004] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[168, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[894, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 902],\n",
      "    edge_label=[902],\n",
      "    edge_label_index=[2, 902]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 949] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[171, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[975, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 977],\n",
      "    edge_label=[977],\n",
      "    edge_label_index=[2, 977]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1037] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[190, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[933, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 938],\n",
      "    edge_label=[938],\n",
      "    edge_label_index=[2, 938]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1009] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[186, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[851, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 855],\n",
      "    edge_label=[855],\n",
      "    edge_label_index=[2, 855]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 919] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[181, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[883, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 883],\n",
      "    edge_label=[883],\n",
      "    edge_label_index=[2, 883]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 951] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[187, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[927, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 929],\n",
      "    edge_label=[929],\n",
      "    edge_label_index=[2, 929]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 999] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[172, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[894, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 900],\n",
      "    edge_label=[900],\n",
      "    edge_label_index=[2, 900]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 953] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[167, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[904, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 905],\n",
      "    edge_label=[905],\n",
      "    edge_label_index=[2, 905]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 952] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[182, 159],\n",
      "    input_id=[128],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[956, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 961],\n",
      "    edge_label=[961],\n",
      "    edge_label_index=[2, 961]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 1028] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={\n",
      "    x=[108, 159],\n",
      "    input_id=[77],\n",
      "    batch_size=77\n",
      "  },\n",
      "  \u001b[1muser\u001b[0m={ x=[549, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={\n",
      "    edge_index=[2, 553],\n",
      "    edge_label=[553],\n",
      "    edge_label_index=[2, 553]\n",
      "  },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 586] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82514160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1442687 entries, 0 to 1459535\n",
      "Data columns (total 21 columns):\n",
      " #   Column                 Non-Null Count    Dtype              \n",
      "---  ------                 --------------    -----              \n",
      " 0   listing_id             1442687 non-null  object             \n",
      " 1   id                     1442687 non-null  object             \n",
      " 2   rating                 1442687 non-null  int64              \n",
      " 3   comments               1442687 non-null  object             \n",
      " 4   localized_comments     440951 non-null   object             \n",
      " 5   response               165434 non-null   object             \n",
      " 6   localized_response     40491 non-null    object             \n",
      " 7   language               1442627 non-null  object             \n",
      " 8   created_at             1442687 non-null  datetime64[ns, UTC]\n",
      " 9   localized_date         1442687 non-null  object             \n",
      " 10  reviewee_id            1442687 non-null  object             \n",
      " 11  reviewee_first_name    1442687 non-null  object             \n",
      " 12  reviewee_host_name     1442687 non-null  object             \n",
      " 13  reviewee_is_superhost  1442687 non-null  bool               \n",
      " 14  reviewee_picture_url   1442687 non-null  object             \n",
      " 15  reviewer_id            1442687 non-null  object             \n",
      " 16  reviewer_first_name    1442687 non-null  object             \n",
      " 17  reviewer_host_name     1442687 non-null  object             \n",
      " 18  reviewer_is_superhost  1442687 non-null  bool               \n",
      " 19  reviewer_picture_url   1442687 non-null  object             \n",
      " 20  timestamp              1442687 non-null  int64              \n",
      "dtypes: bool(2), datetime64[ns, UTC](1), int64(2), object(16)\n",
      "memory usage: 222.9+ MB\n"
     ]
    }
   ],
   "source": [
    "reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7b2ac83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20799 entries, 0 to 24286\n",
      "Columns: 162 entries, num_of_guest_capacity to listing_id\n",
      "dtypes: category(132), datetime64[ns](1), float64(27), object(2)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "listings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "683febfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1359391 entries, 0 to 1378156\n",
      "Data columns (total 2 columns):\n",
      " #   Column                Non-Null Count    Dtype \n",
      "---  ------                --------------    ----- \n",
      " 0   reviewer_id           1359391 non-null  object\n",
      " 1   reviewer_picture_url  1359391 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.1+ MB\n"
     ]
    }
   ],
   "source": [
    "reviewers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c9291be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2009-05-23 16:27:17+0000', tz='UTC')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['created_at'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a200580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2022-10-23 13:01:08+0000', tz='UTC')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['created_at'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abe46913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1380190"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70193b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92015b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "embeddings = model.inference(test_data.x_dict, test_data.edge_index_dict)\n",
    "user_embeddings = embeddings[\"user\"]\n",
    "listing_embeddings = embeddings[\"listing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5d21a494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class RECOMMENDENTATION_TYPE(Enum):\n",
    "    USER_TO_ITEM = \"USER_TO_ITEM\"\n",
    "    ITEM_TO_ITEM = \"ITEM_TO_ITEM\"\n",
    "\n",
    "\n",
    "def get_entity2dict(df, id_col):\n",
    "    entity2dict = {}\n",
    "\n",
    "    for idx, _id in enumerate(df[id_col].to_list()):\n",
    "        entity2dict[_id] = idx\n",
    "\n",
    "    return entity2dict\n",
    "\n",
    "\n",
    "def get_similar_listings_by_graph_embeddings(\n",
    "    query_listing_idx, listing_embeddings, reverse_test_listings2dict, K\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate the top-k closest listings with the first listing the reviewers has reviewed in terms of embeddings\n",
    "    \"\"\"\n",
    "    query_listing_embedding = listing_embeddings[query_listing_idx]\n",
    "    cos_t = torch.nn.CosineSimilarity(dim=1)(query_listing_embedding, listing_embeddings)\n",
    "    top_ids = torch.argsort(-cos_t).numpy()\n",
    "    query_listing_id = reverse_test_listings2dict[query_listing_idx]\n",
    "    recommendation_list = []\n",
    "    for index in top_ids:\n",
    "        if len(recommendation_list) == K:\n",
    "            break\n",
    "        candidate_listing_id = reverse_test_listings2dict[index]\n",
    "        if candidate_listing_id != query_listing_id:\n",
    "            recommendation_list.append(candidate_listing_id)\n",
    "    return recommendation_list\n",
    "\n",
    "\n",
    "def get_recommended_listings_by_graph_embeddings(\n",
    "    query_user_embedding, listing_embeddings, reverse_test_listings2dict, K\n",
    "):\n",
    "    \"\"\"\n",
    "    for each user, generate the top-k closest listing in terms of embeddings\n",
    "    \"\"\"\n",
    "    cos_t = torch.nn.CosineSimilarity(dim=1)(query_user_embedding, listing_embeddings)\n",
    "    top_ids = torch.argsort(-cos_t).numpy()[:K]\n",
    "    def get_id_by_index(index):\n",
    "        return reverse_test_listings2dict[index]\n",
    "    recommendation_list = np.vectorize(get_id_by_index)(top_ids)\n",
    "    return recommendation_list\n",
    "\n",
    "\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "def prepare_evaluation_pairs(\n",
    "    rec_type,\n",
    "    test_reviews,\n",
    "    test_listings,\n",
    "    user_embeddings,\n",
    "    listing_embeddings,\n",
    "    test_listings2dict,\n",
    "    reverse_test_listings2dict,\n",
    "    test_reviewers2dict,\n",
    "    reverse_test_reviewers2dict,\n",
    "    K,\n",
    "):\n",
    "    # Generate (num_user, K) recommendation matrix\n",
    "    # Generate (num_user, x) ground truth matrix where x is unsure\n",
    "    recommendations = []\n",
    "    ground_truths = []\n",
    "    if rec_type == RECOMMENDENTATION_TYPE.USER_TO_ITEM.value:\n",
    "        n_users = user_embeddings.shape[0]\n",
    "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        for number, prime in zip(PRIMES, executor.map(is_prime, PRIMES)):\n",
    "            print('%d is prime: %s' % (number, prime))\n",
    "        for user_idx in range(n_users):\n",
    "            print(user_idx)\n",
    "            query_user_embedding = user_embeddings[user_idx]\n",
    "            recommendation_list = get_recommended_listings_by_graph_embeddings(\n",
    "                query_user_embedding, listing_embeddings, reverse_test_listings2dict, K\n",
    "            )\n",
    "            query_user_id = reverse_test_reviewers2dict[user_idx]\n",
    "            ground_truth_list = list(\n",
    "                test_reviews[test_reviews[\"reviewer_id\"] == query_user_id][\"listing_id\"].values\n",
    "            )\n",
    "            recommendations.append(recommendation_list)\n",
    "            ground_truths.append(ground_truth_list)\n",
    "\n",
    "    elif rec_type == RECOMMENDENTATION_TYPE.ITEM_TO_ITEM.value:\n",
    "        v = test_reviews[\"reviewer_id\"].value_counts()\n",
    "        reviews_that_user_interaction_more_than_once = test_reviews[\n",
    "            test_reviews[\"reviewer_id\"].isin(v.index[v.gt(1)])\n",
    "        ]\n",
    "        for reviewer_id in reviews_that_user_interaction_more_than_once[\"reviewer_id\"].unique():\n",
    "            user_interactions = reviews_that_user_interaction_more_than_once[\n",
    "                reviews_that_user_interaction_more_than_once[\"reviewer_id\"] == reviewer_id\n",
    "            ]\n",
    "            assert len(user_interactions) > 1\n",
    "            user_first_interaction = user_interactions.sort_values(by=\"created_at\").iloc[0]\n",
    "            query_listing_id = user_first_interaction[\"listing_id\"]\n",
    "            query_listing_idx = test_listings2dict[query_listing_id]\n",
    "            recommendation_list = get_similar_listings_by_graph_embeddings(\n",
    "                query_listing_idx, listing_embeddings, reverse_test_listings2dict, K\n",
    "            )\n",
    "            ground_truth_list = user_interactions[\n",
    "                ~user_interactions[\"id\"].isin([user_first_interaction[\"id\"]])\n",
    "            ][\"listing_id\"].values\n",
    "\n",
    "            assert len(ground_truth_list) != 0\n",
    "            recommendations.append(recommendation_list)\n",
    "            ground_truths.append(ground_truth_list)\n",
    "\n",
    "    return np.array(recommendations), np.array(ground_truths)\n",
    "\n",
    "\n",
    "def hit_rate(recommendations, ground_truths):\n",
    "    n_users = recommendations.shape[0]\n",
    "    hits = []\n",
    "\n",
    "    for user_idx in range(n_users):\n",
    "        recommendation = recommendations[user_idx]\n",
    "        ground_truth = ground_truths[user_idx]\n",
    "        if len(set(recommendation).intersection(ground_truth)) > 0:\n",
    "            hit = 1\n",
    "        else:\n",
    "            hit = 0\n",
    "        hits.append(hit)\n",
    "    return np.array(hits).mean()\n",
    "\n",
    "\n",
    "def evaluate_nn(\n",
    "    user_embeddings,\n",
    "    listing_embeddings,\n",
    "    test_reviews,\n",
    "    test_listings,\n",
    "    test_listings2dict,\n",
    "    reverse_test_listings2dict,\n",
    "    test_reviewers2dict,\n",
    "    reverse_test_reviewers2dict,\n",
    "    K=10,\n",
    "):\n",
    "\n",
    "    u2i_recommendations, u2i_ground_truths = prepare_evaluation_pairs(\n",
    "        RECOMMENDENTATION_TYPE.USER_TO_ITEM.value,\n",
    "        test_reviews,\n",
    "        test_listings,\n",
    "        user_embeddings,\n",
    "        listing_embeddings,\n",
    "        test_listings2dict,\n",
    "        reverse_test_listings2dict,\n",
    "        test_reviewers2dict,\n",
    "        reverse_test_reviewers2dict,\n",
    "        K,\n",
    "    )\n",
    "    u2i_hit_rate = hit_rate(u2i_recommendations, u2i_ground_truths)\n",
    "    i2i_hit_rate = None\n",
    "#     i2i_recommendations, i2i_ground_truths = prepare_evaluation_pairs(\n",
    "#         RECOMMENDENTATION_TYPE.ITEM_TO_ITEM.value,\n",
    "#         test_reviews,\n",
    "#         test_listings,\n",
    "#         user_embeddings,\n",
    "#         listing_embeddings,\n",
    "#         test_listings2dict,\n",
    "#         reverse_test_listings2dict,\n",
    "#         test_reviewers2dict,\n",
    "#         reverse_test_reviewers2dict,\n",
    "#         K,\n",
    "#     )\n",
    "#     i2i_hit_rate = hit_rate(i2i_recommendations, i2i_ground_truths)\n",
    "\n",
    "    return u2i_hit_rate, i2i_hit_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "56e63391",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m u2i_hit_rate \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_nn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlisting_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_reviews\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_listings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_listings2dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreverse_test_listings2dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_reviewers2dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreverse_test_reviewers2dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m u2i_hit_rate\n",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36mevaluate_nn\u001b[0;34m(user_embeddings, listing_embeddings, test_reviews, test_listings, test_listings2dict, reverse_test_listings2dict, test_reviewers2dict, reverse_test_reviewers2dict, K)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_nn\u001b[39m(\n\u001b[1;32m    129\u001b[0m     user_embeddings,\n\u001b[1;32m    130\u001b[0m     listing_embeddings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m     K\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m    138\u001b[0m ):\n\u001b[0;32m--> 140\u001b[0m     u2i_recommendations, u2i_ground_truths \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_evaluation_pairs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mRECOMMENDENTATION_TYPE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUSER_TO_ITEM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_reviews\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_listings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlisting_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_listings2dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreverse_test_listings2dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_reviewers2dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreverse_test_reviewers2dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m     u2i_hit_rate \u001b[38;5;241m=\u001b[39m hit_rate(u2i_recommendations, u2i_ground_truths)\n\u001b[1;32m    153\u001b[0m     i2i_hit_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36mprepare_evaluation_pairs\u001b[0;34m(rec_type, test_reviews, test_listings, user_embeddings, listing_embeddings, test_listings2dict, reverse_test_listings2dict, test_reviewers2dict, reverse_test_reviewers2dict, K)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(user_idx)\n\u001b[1;32m     75\u001b[0m query_user_embedding \u001b[38;5;241m=\u001b[39m user_embeddings[user_idx]\n\u001b[0;32m---> 76\u001b[0m recommendation_list \u001b[38;5;241m=\u001b[39m \u001b[43mget_recommended_listings_by_graph_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_user_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlisting_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse_test_listings2dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m query_user_id \u001b[38;5;241m=\u001b[39m reverse_test_reviewers2dict[user_idx]\n\u001b[1;32m     80\u001b[0m ground_truth_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m     81\u001b[0m     test_reviews[test_reviews[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreviewer_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m query_user_id][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisting_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     82\u001b[0m )\n",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36mget_recommended_listings_by_graph_embeddings\u001b[0;34m(query_user_embedding, listing_embeddings, reverse_test_listings2dict, K)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03mfor each user, generate the top-k closest listing in terms of embeddings\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m cos_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCosineSimilarity(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)(query_user_embedding, listing_embeddings)\n\u001b[0;32m---> 48\u001b[0m top_ids \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margsort\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mcos_t\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()[:K]\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_id_by_index\u001b[39m(index):\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reverse_test_listings2dict[index]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "u2i_hit_rate = evaluate_nn(\n",
    "        user_embeddings,\n",
    "        listing_embeddings,\n",
    "        test_reviews,\n",
    "        test_listings,\n",
    "        test_listings2dict,\n",
    "        reverse_test_listings2dict,\n",
    "        test_reviewers2dict,\n",
    "        reverse_test_reviewers2dict,\n",
    ")\n",
    "u2i_hit_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f6981d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1113, 0.1113, 0.1113,  ..., 0.1113, 0.1113, 0.1113],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([-0.1113, -0.1113, -0.1113,  ..., -0.1113, -0.1113, -0.1113],\n",
      "       grad_fn=<NegBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([13881, 16971, 10351, ..., 16445, 17744,   746])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_t = torch.nn.CosineSimilarity(dim=1)(user_embeddings[0], listing_embeddings)\n",
    "top_ids = torch.argsort(-cos_t).numpy()\n",
    "print(cos_t)\n",
    "print(-cos_t)\n",
    "top_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15bc3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "i2i_hit_rate = evaluate_nn(\n",
    "        user_embeddings,\n",
    "        listing_embeddings,\n",
    "        test_reviews,\n",
    "        test_listings,\n",
    "        test_listings2dict,\n",
    "        reverse_test_listings2dict,\n",
    "        test_reviewers2dict,\n",
    "        reverse_test_reviewers2dict,\n",
    ")\n",
    "i2i_hit_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f37a364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8940811.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tt] *",
   "language": "python",
   "name": "conda-env-tt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
