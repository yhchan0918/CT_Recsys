{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76ab39d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import random\n",
    "from datetime import date, datetime as dt, timedelta\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "from warnings import simplefilter\n",
    "import click\n",
    "from dateutil.relativedelta import relativedelta  # type: ignore\n",
    "import datetime  # type: ignore\n",
    "import pandas as pd  # type: ignore\n",
    "from loguru import logger\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "\n",
    "from train_test_split import *\n",
    "from evaluate import *\n",
    "from constants import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa2c8f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myhchan0918\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0e636e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "directory = \"/Users/yhchan/Downloads/FYP/data/processed\"\n",
    "\n",
    "\n",
    "reviews = pd.read_parquet(f\"{directory}/reviews_with_interactions.parquet\")\n",
    "listings = pd.read_parquet(f\"{directory}/listings_with_interactions.parquet\")\n",
    "reviewers = pd.read_parquet(f\"{directory}/reviewers_with_interactions.parquet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "544f5ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 14:20:33.361 | INFO     | __main__:<module>:7 - Start of Retraining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2021-10-24 2022-10-23\n",
      "408596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 14:20:34.434 | INFO     | train_test_split:main_train_val_test:136 - Split df into train and test portion\n"
     ]
    }
   ],
   "source": [
    "iteration = 0\n",
    "start_date = dt.strptime(\"2021-10-24\", \"%Y-%m-%d\").date()\n",
    "if start_date == dt.strptime(MAX_START_DATE, \"%Y-%m-%d\").date():\n",
    "    raise Exception(\"Stop Simulation\")\n",
    "end_date, nxt_start_date = split_date_by_period_months(start_date, TOTAL_MONTHS_PER_ITERATION)\n",
    "\n",
    "logger.info(\"Start of Retraining\")\n",
    "print(iteration)\n",
    "print(start_date, end_date)\n",
    "\n",
    "\n",
    "\n",
    "# Prepare data and graph\n",
    "(\n",
    "    train_reviews,\n",
    "    train_listings,\n",
    "    train_reviewers,\n",
    "    test_reviews,\n",
    "    test_listings,\n",
    "    test_reviewers,\n",
    ") = main_train_val_test(\n",
    "    reviews,\n",
    "    listings,\n",
    "    reviewers,\n",
    "    start_date,\n",
    "    end_date,\n",
    "    10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c22af302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_test_data_by_scenario(train_reviews, test_reviews, user_col, scenario_type):\n",
    "    if scenario_type == \"cold_start\":\n",
    "        train_reviewers = list(train_reviews[user_col].unique())\n",
    "        return test_reviews[~test_reviews[user_col].isin(train_reviewers)]\n",
    "\n",
    "def get_nunique(df, col):\n",
    "    return (df[col].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c34ec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date = dt.strptime(SIMULATION_START_DATE, '%Y-%m-%d').date()\n",
    "# end_date, nxt_start_date = split_date_by_period_months(start_date, TOTAL_MONTHS_PER_ITERATION)\n",
    "\n",
    "\n",
    "# (\n",
    "# train_reviews,\n",
    "# train_listings,\n",
    "# train_reviewers,\n",
    "# test_reviews,\n",
    "# test_listings,\n",
    "# test_reviewers,\n",
    "# ) = main_train_val_test(reviews, listings, reviewers, start_date, end_date, 10)\n",
    "\n",
    "# cold_start_test_reviews = filter_test_data_by_scenario(train_reviews, test_reviews, \"reviewer_id\", \"cold_start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "943b8a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 16:34:21.809 | INFO     | train_test_split:main_train_val_test:136 - Split df into train and test portion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2015-10-24 2016-10-23\n",
      "53610\n",
      "{'num_reviews': 53610, 'num_train_reviews': 40500, 'num_test_reviews': 13110, 'num_cold_start_test_reviews': 12980, 'num_unique_cold_start_test_listings': 2320, 'num_unique_cold_start_test_reviewers': 12830, 'num_unique_train_listings': 2706, 'num_unique_test_listings': 2331, 'num_unique_train_reviewers': 39828, 'num_unique_test_reviewers': 12952}\n",
      "1\n",
      "2016-10-24 2017-10-23\n",
      "103877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 16:34:22.318 | INFO     | train_test_split:main_train_val_test:136 - Split df into train and test portion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_reviews': 103877, 'num_train_reviews': 81540, 'num_test_reviews': 22337, 'num_cold_start_test_reviews': 22053, 'num_unique_cold_start_test_listings': 3748, 'num_unique_cold_start_test_reviewers': 21775, 'num_unique_train_listings': 4509, 'num_unique_test_listings': 3763, 'num_unique_train_reviewers': 79927, 'num_unique_test_reviewers': 22046}\n",
      "2\n",
      "2017-10-24 2018-10-23\n",
      "160543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 16:34:22.874 | INFO     | train_test_split:main_train_val_test:136 - Split df into train and test portion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_reviews': 160543, 'num_train_reviews': 125395, 'num_test_reviews': 35148, 'num_cold_start_test_reviews': 34634, 'num_unique_cold_start_test_listings': 5617, 'num_unique_cold_start_test_reviewers': 34126, 'num_unique_train_listings': 6756, 'num_unique_test_listings': 5636, 'num_unique_train_reviewers': 122793, 'num_unique_test_reviewers': 34614}\n",
      "3\n",
      "2018-10-24 2019-10-23\n",
      "248046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 16:34:23.631 | INFO     | train_test_split:main_train_val_test:136 - Split df into train and test portion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_reviews': 248046, 'num_train_reviews': 197693, 'num_test_reviews': 50353, 'num_cold_start_test_reviews': 49437, 'num_unique_cold_start_test_listings': 7875, 'num_unique_cold_start_test_reviewers': 48645, 'num_unique_train_listings': 9493, 'num_unique_test_listings': 7903, 'num_unique_train_reviewers': 192742, 'num_unique_test_reviewers': 49510}\n",
      "4\n",
      "2019-10-24 2020-10-23\n",
      "192921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 16:34:24.301 | INFO     | train_test_split:main_train_val_test:136 - Split df into train and test portion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_reviews': 192921, 'num_train_reviews': 156414, 'num_test_reviews': 36507, 'num_cold_start_test_reviews': 35680, 'num_unique_cold_start_test_listings': 6437, 'num_unique_cold_start_test_reviewers': 35279, 'num_unique_train_listings': 10864, 'num_unique_test_listings': 6486, 'num_unique_train_reviewers': 152348, 'num_unique_test_reviewers': 36042}\n",
      "5\n",
      "2020-10-24 2021-10-23\n",
      "239538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 16:34:25.015 | INFO     | train_test_split:main_train_val_test:136 - Split df into train and test portion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_reviews': 239538, 'num_train_reviews': 184653, 'num_test_reviews': 54885, 'num_cold_start_test_reviews': 53548, 'num_unique_cold_start_test_listings': 9005, 'num_unique_cold_start_test_reviewers': 52840, 'num_unique_train_listings': 11274, 'num_unique_test_listings': 9079, 'num_unique_train_reviewers': 179415, 'num_unique_test_reviewers': 54102}\n",
      "6\n",
      "2021-10-24 2022-10-23\n",
      "408596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 16:34:25.992 | INFO     | train_test_split:main_train_val_test:136 - Split df into train and test portion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_reviews': 408596, 'num_train_reviews': 334678, 'num_test_reviews': 73918, 'num_cold_start_test_reviews': 71775, 'num_unique_cold_start_test_listings': 14254, 'num_unique_cold_start_test_reviewers': 70416, 'num_unique_train_listings': 17229, 'num_unique_test_listings': 14380, 'num_unique_train_reviewers': 324135, 'num_unique_test_reviewers': 72447}\n",
      "7\n",
      "2022-10-24 2023-10-23\n",
      "0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'datetime.date' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 16\u001b[0m\n\u001b[1;32m      5\u001b[0m end_date, nxt_start_date \u001b[38;5;241m=\u001b[39m split_date_by_period_months(start_date, TOTAL_MONTHS_PER_ITERATION)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(start_date, end_date)\n\u001b[1;32m      9\u001b[0m (\n\u001b[1;32m     10\u001b[0m train_reviews,\n\u001b[1;32m     11\u001b[0m train_listings,\n\u001b[1;32m     12\u001b[0m train_reviewers,\n\u001b[1;32m     13\u001b[0m test_reviews,\n\u001b[1;32m     14\u001b[0m test_listings,\n\u001b[1;32m     15\u001b[0m test_reviewers,\n\u001b[0;32m---> 16\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mmain_train_val_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreviews\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlistings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreviewers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m cold_start_test_reviews \u001b[38;5;241m=\u001b[39m filter_test_data_by_scenario(train_reviews, test_reviews, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreviewer_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcold_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m data_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_reviews\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mlen\u001b[39m(train_reviews) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_reviews),\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_train_reviews\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;28mlen\u001b[39m(train_reviews),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_unique_test_reviewers\u001b[39m\u001b[38;5;124m\"\u001b[39m: get_nunique(test_reviewers, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviewer_id\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     31\u001b[0m }\n",
      "File \u001b[0;32m~/Downloads/FYP/CT_of_recommendation_system/ct_pipeline/train_test_split.py:124\u001b[0m, in \u001b[0;36mmain_train_val_test\u001b[0;34m(reviews, listings, reviewers, start_date, end_date, train_split_period_months)\u001b[0m\n\u001b[1;32m    117\u001b[0m df \u001b[38;5;241m=\u001b[39m split_df_date(reviews, start_date, end_date)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df))\n\u001b[1;32m    119\u001b[0m (\n\u001b[1;32m    120\u001b[0m     start_date,\n\u001b[1;32m    121\u001b[0m     end_date_train,\n\u001b[1;32m    122\u001b[0m     start_date_test,\n\u001b[1;32m    123\u001b[0m     end_date,\n\u001b[0;32m--> 124\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mget_split_dates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_split_period_months\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m train_reviews, test_reviews \u001b[38;5;241m=\u001b[39m set_train_test(\n\u001b[1;32m    126\u001b[0m     df,\n\u001b[1;32m    127\u001b[0m     start_date,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m     end_date,\n\u001b[1;32m    131\u001b[0m )\n\u001b[1;32m    133\u001b[0m train_listings, train_reviewers \u001b[38;5;241m=\u001b[39m build_partitioned_data(train_reviews, listings, reviewers)\n",
      "File \u001b[0;32m~/Downloads/FYP/CT_of_recommendation_system/ct_pipeline/train_test_split.py:76\u001b[0m, in \u001b[0;36mget_split_dates\u001b[0;34m(df, start_date, train_split_period_months)\u001b[0m\n\u001b[1;32m     72\u001b[0m end_date \u001b[38;5;241m=\u001b[39m df[REVIEWS_DATE_COL]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate\u001b[38;5;241m.\u001b[39mmax()\n\u001b[1;32m     73\u001b[0m end_date_train, start_date_test \u001b[38;5;241m=\u001b[39m split_date_by_period_months(\n\u001b[1;32m     74\u001b[0m     start_date_, train_split_period_months\n\u001b[1;32m     75\u001b[0m )\n\u001b[0;32m---> 76\u001b[0m \u001b[43mcheck_split_period_months\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     79\u001b[0m     start_date_,\n\u001b[1;32m     80\u001b[0m     end_date_train,\n\u001b[1;32m     81\u001b[0m     start_date_test,\n\u001b[1;32m     82\u001b[0m     end_date,\n\u001b[1;32m     83\u001b[0m )\n",
      "File \u001b[0;32m~/Downloads/FYP/CT_of_recommendation_system/ct_pipeline/train_test_split.py:36\u001b[0m, in \u001b[0;36mcheck_split_period_months\u001b[0;34m(end_date, end_date_train)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_split_period_months\u001b[39m(\n\u001b[1;32m     30\u001b[0m     end_date: datetime\u001b[38;5;241m.\u001b[39mdate,\n\u001b[1;32m     31\u001b[0m     end_date_train: datetime\u001b[38;5;241m.\u001b[39mdate,\n\u001b[1;32m     32\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m    Validate the amount of split_period_months is not greater than the period of the rest of the data\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mend_date_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m:\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_split_period_months is greater than the period of the entire dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: '>=' not supported between instances of 'datetime.date' and 'float'"
     ]
    }
   ],
   "source": [
    "iteration = 0\n",
    "start_date = dt.strptime(SIMULATION_START_DATE, '%Y-%m-%d').date()\n",
    "while True:\n",
    "    print(iteration)\n",
    "    end_date, nxt_start_date = split_date_by_period_months(start_date, TOTAL_MONTHS_PER_ITERATION)\n",
    "    print(start_date, end_date)\n",
    "    \n",
    "    \n",
    "    (\n",
    "    train_reviews,\n",
    "    train_listings,\n",
    "    train_reviewers,\n",
    "    test_reviews,\n",
    "    test_listings,\n",
    "    test_reviewers,\n",
    "    ) = main_train_val_test(reviews, listings, reviewers, start_date, end_date, 10)\n",
    "    \n",
    "    cold_start_test_reviews = filter_test_data_by_scenario(train_reviews, test_reviews, \"reviewer_id\", \"cold_start\")\n",
    "    \n",
    "    data_dict = {\n",
    "        \"num_reviews\": len(train_reviews) + len(test_reviews),\n",
    "        \"num_train_reviews\":len(train_reviews),\n",
    "        \"num_test_reviews\":len(test_reviews),\n",
    "        \"num_cold_start_test_reviews\": len(cold_start_test_reviews),\n",
    "        \"num_unique_cold_start_test_listings\":  get_nunique(cold_start_test_reviews, 'listing_id'),\n",
    "        \"num_unique_cold_start_test_reviewers\":  get_nunique(cold_start_test_reviews, 'reviewer_id'),\n",
    "        \"num_unique_train_listings\": get_nunique(train_listings, 'listing_id'),\n",
    "        \"num_unique_test_listings\": get_nunique(test_listings, 'listing_id'),\n",
    "        \"num_unique_train_reviewers\": get_nunique(train_reviewers, 'reviewer_id'),\n",
    "        \"num_unique_test_reviewers\": get_nunique(test_reviewers, 'reviewer_id'),\n",
    "    }\n",
    "    \n",
    "    print(data_dict)\n",
    "    \n",
    "    if start_date == dt.strptime(MAX_START_DATE, '%Y-%m-%d').date():\n",
    "        break\n",
    "    else:   \n",
    "        start_date = nxt_start_date\n",
    "        iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d3e28b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2015-10-24 2016-10-23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/yhchan/Downloads/FYP/CT_of_recommendation_system/ml_pipeline/ct_run/wandb/run-20230304_145657-fd5y66dg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yhchan0918/CT_OF_AIRBNB_RECSYS/runs/fd5y66dg' target=\"_blank\">experiment_1</a></strong> to <a href='https://wandb.ai/yhchan0918/CT_OF_AIRBNB_RECSYS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yhchan0918/CT_OF_AIRBNB_RECSYS' target=\"_blank\">https://wandb.ai/yhchan0918/CT_OF_AIRBNB_RECSYS</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yhchan0918/CT_OF_AIRBNB_RECSYS/runs/fd5y66dg' target=\"_blank\">https://wandb.ai/yhchan0918/CT_OF_AIRBNB_RECSYS/runs/fd5y66dg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 14:57:01.723 | INFO     | train_test_split:main_train_val_test:136 - Split df into train and test portion\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./train)... Done. 0.1s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./test)... Done. 0.0s\n",
      "/Users/yhchan/Downloads/FYP/CT_of_recommendation_system/ml_pipeline/ct_run/train_test_split.py:173: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1670525682339/work/torch/csrc/utils/tensor_numpy.cpp:205.)\n",
      "  temp = torch.from_numpy(val).view(-1, 1).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Heterogenous Graph HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={ x=[2706, 159] },\n",
      "  \u001b[1muser\u001b[0m={ x=[39828, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={ edge_index=[2, 40500] },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 40500] }\n",
      ")\n",
      "Test Heterogenous Graph HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={ x=[2331, 159] },\n",
      "  \u001b[1muser\u001b[0m={ x=[12952, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={ edge_index=[2, 13110] },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 13110] }\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 14:57:04.630 | INFO     | __main__:<module>:149 - Epoch: 001, Train Loss: 51390321.6874, Test Loss: 4107816.4783 \n",
      "2023-03-04 14:57:05.871 | INFO     | __main__:<module>:149 - Epoch: 002, Train Loss: 2049263.2889, Test Loss: 4306045.5998 \n",
      "2023-03-04 14:57:07.508 | INFO     | __main__:<module>:168 - No production model found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project yhchan0918/CT_OF_AIRBNB_RECSYS does not contain artifact: \"Unsupervised_GraphSAGE:production\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>contender_model_hit_rate</td><td>▁</td></tr><tr><td>epoch</td><td>▁█</td></tr><tr><td>num_listings</td><td>▁</td></tr><tr><td>num_reviewers</td><td>▁</td></tr><tr><td>num_reviews</td><td>▁</td></tr><tr><td>num_test_listings</td><td>▁</td></tr><tr><td>num_test_reviewers</td><td>▁</td></tr><tr><td>num_test_reviews</td><td>▁</td></tr><tr><td>num_train_listings</td><td>▁</td></tr><tr><td>num_train_reviewers</td><td>▁</td></tr><tr><td>num_train_reviews</td><td>▁</td></tr><tr><td>test_loss</td><td>▁█</td></tr><tr><td>train_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_test_loss</td><td>4107816.47834</td></tr><tr><td>best_train_loss</td><td>2049263.28887</td></tr><tr><td>contender_model_hit_rate</td><td>0.04537</td></tr><tr><td>epoch</td><td>2</td></tr><tr><td>num_listings</td><td>5037</td></tr><tr><td>num_reviewers</td><td>52780</td></tr><tr><td>num_reviews</td><td>53610</td></tr><tr><td>num_test_listings</td><td>2331</td></tr><tr><td>num_test_reviewers</td><td>12952</td></tr><tr><td>num_test_reviews</td><td>13110</td></tr><tr><td>num_train_listings</td><td>2706</td></tr><tr><td>num_train_reviewers</td><td>39828</td></tr><tr><td>num_train_reviews</td><td>40500</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">experiment_1</strong> at: <a href='https://wandb.ai/yhchan0918/CT_OF_AIRBNB_RECSYS/runs/fd5y66dg' target=\"_blank\">https://wandb.ai/yhchan0918/CT_OF_AIRBNB_RECSYS/runs/fd5y66dg</a><br/>Synced 6 W&B file(s), 0 media file(s), 15 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230304_145657-fd5y66dg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2016-10-24 2017-10-23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1897a5f1be4d9ca17f044e3a95b670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016751768750000076, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/yhchan/Downloads/FYP/CT_of_recommendation_system/ml_pipeline/ct_run/wandb/run-20230304_145743-etcfoomv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yhchan0918/CT_OF_AIRBNB_RECSYS/runs/etcfoomv' target=\"_blank\">experiment_2</a></strong> to <a href='https://wandb.ai/yhchan0918/CT_OF_AIRBNB_RECSYS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yhchan0918/CT_OF_AIRBNB_RECSYS' target=\"_blank\">https://wandb.ai/yhchan0918/CT_OF_AIRBNB_RECSYS</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yhchan0918/CT_OF_AIRBNB_RECSYS/runs/etcfoomv' target=\"_blank\">https://wandb.ai/yhchan0918/CT_OF_AIRBNB_RECSYS/runs/etcfoomv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 14:57:48.645 | INFO     | train_test_split:main_train_val_test:136 - Split df into train and test portion\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./train)... Done. 0.1s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./test)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Heterogenous Graph HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={ x=[4509, 159] },\n",
      "  \u001b[1muser\u001b[0m={ x=[79927, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={ edge_index=[2, 81540] },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 81540] }\n",
      ")\n",
      "Test Heterogenous Graph HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={ x=[3763, 159] },\n",
      "  \u001b[1muser\u001b[0m={ x=[22046, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={ edge_index=[2, 22337] },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 22337] }\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 14:57:53.102 | INFO     | __main__:<module>:149 - Epoch: 001, Train Loss: 327708163.7414, Test Loss: 2103130.2605 \n",
      "2023-03-04 14:57:56.134 | INFO     | __main__:<module>:149 - Epoch: 002, Train Loss: 5665729.5317, Test Loss: 736178.3164 \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./artifacts/Unsupervised_GraphSAGE:v0/2_model_state_dict.pt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>contender_model_hit_rate</td><td>▁</td></tr><tr><td>epoch</td><td>▁█</td></tr><tr><td>num_listings</td><td>▁</td></tr><tr><td>num_reviewers</td><td>▁</td></tr><tr><td>num_reviews</td><td>▁</td></tr><tr><td>num_test_listings</td><td>▁</td></tr><tr><td>num_test_reviewers</td><td>▁</td></tr><tr><td>num_test_reviews</td><td>▁</td></tr><tr><td>num_train_listings</td><td>▁</td></tr><tr><td>num_train_reviewers</td><td>▁</td></tr><tr><td>num_train_reviews</td><td>▁</td></tr><tr><td>production_model_hit_rate</td><td>▁</td></tr><tr><td>production_model_test_loss</td><td>▁</td></tr><tr><td>test_loss</td><td>█▁</td></tr><tr><td>train_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_test_loss</td><td>736178.31639</td></tr><tr><td>best_train_loss</td><td>5665729.53171</td></tr><tr><td>contender_model_hit_rate</td><td>0.83612</td></tr><tr><td>epoch</td><td>2</td></tr><tr><td>num_listings</td><td>8272</td></tr><tr><td>num_reviewers</td><td>101973</td></tr><tr><td>num_reviews</td><td>103877</td></tr><tr><td>num_test_listings</td><td>3763</td></tr><tr><td>num_test_reviewers</td><td>22046</td></tr><tr><td>num_test_reviews</td><td>22337</td></tr><tr><td>num_train_listings</td><td>4509</td></tr><tr><td>num_train_reviewers</td><td>79927</td></tr><tr><td>num_train_reviews</td><td>81540</td></tr><tr><td>production_model_hit_rate</td><td>0.83612</td></tr><tr><td>production_model_test_loss</td><td>2870760.95907</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">experiment_2</strong> at: <a href='https://wandb.ai/yhchan0918/CT_OF_AIRBNB_RECSYS/runs/etcfoomv' target=\"_blank\">https://wandb.ai/yhchan0918/CT_OF_AIRBNB_RECSYS/runs/etcfoomv</a><br/>Synced 6 W&B file(s), 0 media file(s), 15 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230304_145743-etcfoomv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2017-10-24 2018-10-23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bdf9233581e4bfd9f1a48cf80c07f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016751880549999973, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/yhchan/Downloads/FYP/CT_of_recommendation_system/ml_pipeline/ct_run/wandb/run-20230304_145840-thym9e7h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yhchan0918/CT_OF_AIRBNB_RECSYS/runs/thym9e7h' target=\"_blank\">experiment_3</a></strong> to <a href='https://wandb.ai/yhchan0918/CT_OF_AIRBNB_RECSYS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yhchan0918/CT_OF_AIRBNB_RECSYS' target=\"_blank\">https://wandb.ai/yhchan0918/CT_OF_AIRBNB_RECSYS</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yhchan0918/CT_OF_AIRBNB_RECSYS/runs/thym9e7h' target=\"_blank\">https://wandb.ai/yhchan0918/CT_OF_AIRBNB_RECSYS/runs/thym9e7h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 14:58:46.482 | INFO     | train_test_split:main_train_val_test:136 - Split df into train and test portion\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./train)... Done. 0.2s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./test)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Heterogenous Graph HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={ x=[6756, 159] },\n",
      "  \u001b[1muser\u001b[0m={ x=[122793, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={ edge_index=[2, 125395] },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 125395] }\n",
      ")\n",
      "Test Heterogenous Graph HeteroData(\n",
      "  \u001b[1mlisting\u001b[0m={ x=[5636, 159] },\n",
      "  \u001b[1muser\u001b[0m={ x=[34614, 1] },\n",
      "  \u001b[1m(user, rates, listing)\u001b[0m={ edge_index=[2, 35148] },\n",
      "  \u001b[1m(listing, rev_rates, user)\u001b[0m={ edge_index=[2, 35148] }\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 14:58:53.339 | INFO     | __main__:<module>:149 - Epoch: 001, Train Loss: 393890358.0131, Test Loss: 14518573.8910 \n",
      "2023-03-04 14:58:58.969 | INFO     | __main__:<module>:149 - Epoch: 002, Train Loss: 142787.1928, Test Loss: 5278424.0801 \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./artifacts/Unsupervised_GraphSAGE:v0/2_model_state_dict.pt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>contender_model_hit_rate</td><td>▁</td></tr><tr><td>epoch</td><td>▁█</td></tr><tr><td>num_listings</td><td>▁</td></tr><tr><td>num_reviewers</td><td>▁</td></tr><tr><td>num_reviews</td><td>▁</td></tr><tr><td>num_test_listings</td><td>▁</td></tr><tr><td>num_test_reviewers</td><td>▁</td></tr><tr><td>num_test_reviews</td><td>▁</td></tr><tr><td>num_train_listings</td><td>▁</td></tr><tr><td>num_train_reviewers</td><td>▁</td></tr><tr><td>num_train_reviews</td><td>▁</td></tr><tr><td>production_model_hit_rate</td><td>▁</td></tr><tr><td>production_model_test_loss</td><td>▁</td></tr><tr><td>test_loss</td><td>█▁</td></tr><tr><td>train_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_test_loss</td><td>5278424.08015</td></tr><tr><td>best_train_loss</td><td>142787.19281</td></tr><tr><td>contender_model_hit_rate</td><td>0.01877</td></tr><tr><td>epoch</td><td>2</td></tr><tr><td>num_listings</td><td>12392</td></tr><tr><td>num_reviewers</td><td>157407</td></tr><tr><td>num_reviews</td><td>160543</td></tr><tr><td>num_test_listings</td><td>5636</td></tr><tr><td>num_test_reviewers</td><td>34614</td></tr><tr><td>num_test_reviews</td><td>35148</td></tr><tr><td>num_train_listings</td><td>6756</td></tr><tr><td>num_train_reviewers</td><td>122793</td></tr><tr><td>num_train_reviews</td><td>125395</td></tr><tr><td>production_model_hit_rate</td><td>0.01877</td></tr><tr><td>production_model_test_loss</td><td>6737162.93163</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">experiment_3</strong> at: <a href='https://wandb.ai/yhchan0918/CT_OF_AIRBNB_RECSYS/runs/thym9e7h' target=\"_blank\">https://wandb.ai/yhchan0918/CT_OF_AIRBNB_RECSYS/runs/thym9e7h</a><br/>Synced 6 W&B file(s), 0 media file(s), 9 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230304_145840-thym9e7h/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Driver code\n",
    "iteration = 0\n",
    "start_date = dt.strptime(SIMULATION_START_DATE, '%Y-%m-%d').date()\n",
    "while True:\n",
    "    print(iteration)\n",
    "    end_date, nxt_start_date = split_date_by_period_months(start_date, TOTAL_MONTHS_PER_ITERATION)\n",
    "    print(start_date, end_date)\n",
    "    wandb.init(\n",
    "          project=PROJECT_NAME, \n",
    "          name=f\"iteration_{iteration}\", \n",
    "          config={\n",
    "            \"architecture\": \"Unsupervised GraphSAGE\",\n",
    "            \"iteration\": iteration,\n",
    "            \"start_date\":start_date,\n",
    "            \"end_date\":end_date,\n",
    "            \"learning_rate\": 0.01,\n",
    "            \"hidden_channels\": 32,\n",
    "            \"train_batch_size\": 1024,\n",
    "            \"test_batch_size\": 256,\n",
    "            \"epochs\": 2,\n",
    "            \"train_num_neighbours\":[10, 10],\n",
    "            \"test_num_neighbours\":[-1],\n",
    "            \"train_split_period_months\":10,\n",
    "            \"total_months_of_data\": TOTAL_MONTHS_PER_ITERATION,\n",
    "          })\n",
    "    wandb.define_metric(\"train_loss\", step_metric=\"epoch\", summary=\"min\")\n",
    "    wandb.define_metric(\"test_loss\", step_metric=\"epoch\", summary=\"min\")\n",
    "\n",
    "    # Prepare data and graph\n",
    "    (\n",
    "        train_reviews,\n",
    "        train_listings,\n",
    "        train_reviewers,\n",
    "        test_reviews,\n",
    "        test_listings,\n",
    "        test_reviewers,\n",
    "    ) = main_train_val_test(reviews, listings, reviewers, start_date, end_date, wandb.config['train_split_period_months'])\n",
    "    wandb.log({\n",
    "        \"num_reviews\": len(train_reviews) + len(test_reviews),\n",
    "        \"num_train_reviews\":len(train_reviews),\n",
    "        \"num_test_reviews\":len(test_reviews),\n",
    "        \"num_listings\":len(train_listings) + len(test_listings),\n",
    "        \"num_train_listings\":len(train_listings),\n",
    "        \"num_test_listings\":len(test_listings),\n",
    "        \"num_reviewers\":len(train_reviewers) + len(test_reviewers),\n",
    "        \"num_train_reviewers\":len(train_reviewers),\n",
    "        \"num_test_reviewers\":len(test_reviewers),\n",
    "    })\n",
    "    train_reviews.to_csv('train/train_reviews.parquet', index=False)\n",
    "    train_listings.to_csv('train/train_listings.parquet', index=False)\n",
    "    train_reviewers.to_csv('train/train_reviewers.parquet', index=False)\n",
    "    test_reviews.to_csv('test/test_reviews.parquet', index=False)\n",
    "    test_listings.to_csv('test/test_listings.parquet', index=False)\n",
    "    test_reviewers.to_csv('test/test_reviewers.parquet', index=False)\n",
    "\n",
    "    dataset_art = wandb.Artifact(f\"{start_date}_{end_date}_data_{iteration}\", type='dataset')\n",
    "    for dir in [\"train\", \"test\"]:\n",
    "        dataset_art.add_dir(dir)\n",
    "    wandb.log_artifact(dataset_art)\n",
    "    test_listings2dict = get_entity2dict(test_listings, \"listing_id\")\n",
    "    reverse_test_listings2dict = {k: v for v, k in test_listings2dict.items()}\n",
    "    test_reviewers2dict = get_entity2dict(test_reviewers, \"reviewer_id\")\n",
    "    reverse_test_reviewers2dict = {k: v for v, k in test_reviewers2dict.items()}\n",
    "    data = build_heterograph(reviews, listings)\n",
    "    train_data = build_heterograph(train_reviews, train_listings)\n",
    "    test_data = build_heterograph(test_reviews, test_listings)\n",
    "    print(\"Training Heterogenous Graph\", train_data)\n",
    "    print(\"Test Heterogenous Graph\", test_data)\n",
    "\n",
    "    # Modelling\n",
    "    train_loader = prepare_data_loader(\n",
    "        data=train_data, batch_size=wandb.config['train_batch_size'], num_neighbours=wandb.config['train_num_neighbours']\n",
    "    )\n",
    "    test_loader = prepare_data_loader(data=test_data, batch_size=wandb.config['test_batch_size'], num_neighbours=wandb.config[\"test_num_neighbours\"])\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_data = train_data.to(device)\n",
    "    model = Model(hidden_channels=wandb.config['hidden_channels'], data).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=wandb.config['learning_rate'])\n",
    "\n",
    "    def train():\n",
    "        model.train(True)\n",
    "        total_loss = 0\n",
    "        # Why using mini-batch gradient descent\n",
    "        # Update NN multiple times every epoch, Make more precise update to the parameters by calculating the average loss in each step\n",
    "        # Reduce overall training time and num of required epochs for reaching convergence, computational efficiency\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            # Zero gradients for every batch\n",
    "            optimizer.zero_grad()\n",
    "            # Make predictions for this batch\n",
    "            h = model(batch.x_dict, batch.edge_index_dict)\n",
    "            h_src = h[\"user\"][batch[\"user\", \"listing\"].edge_label_index[0]]\n",
    "            h_dst = h[\"listing\"][batch[\"user\", \"listing\"].edge_label_index[1]]\n",
    "            pred = (h_src * h_dst).sum(dim=-1)\n",
    "            # Compute the loss and its gradients\n",
    "            loss = F.binary_cross_entropy_with_logits(pred, batch[\"user\", \"listing\"].edge_label)\n",
    "            loss.backward()\n",
    "            # Adjust learning weights\n",
    "            optimizer.step()\n",
    "            total_loss += float(loss) * pred.size(0)\n",
    "\n",
    "        train_loss = total_loss / train_data.num_nodes\n",
    "        return train_loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test(model, test_data_loader):\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        for batch in test_data_loader:\n",
    "            batch = batch.to(device)\n",
    "            # Make predictions for this batch\n",
    "            h = model(batch.x_dict, batch.edge_index_dict)\n",
    "            h_src = h[\"user\"][batch[\"user\", \"listing\"].edge_label_index[0]]\n",
    "            h_dst = h[\"listing\"][batch[\"user\", \"listing\"].edge_label_index[1]]\n",
    "            pred = (h_src * h_dst).sum(dim=-1)\n",
    "            # Compute the loss and its gradients\n",
    "            loss = F.binary_cross_entropy_with_logits(pred, batch[\"user\", \"listing\"].edge_label)\n",
    "            total_loss += float(loss) * pred.size(0)\n",
    "\n",
    "        test_loss = total_loss / test_data.num_nodes\n",
    "        return test_loss\n",
    "\n",
    "    best_train_loss = float('inf')\n",
    "    best_test_loss = float('inf')\n",
    "    best_model_path = None\n",
    "    best_model_art = None\n",
    "    # Train and Evaluate Loss\n",
    "    for epoch in range(1, wandb.config['epochs'] + 1):\n",
    "        model_is_best = False\n",
    "        train_loss = train()\n",
    "        test_loss = test(model, test_loader)\n",
    "\n",
    "        if (train_loss < best_train_loss):\n",
    "            wandb.run.summary[\"best_train_loss\"] = train_loss\n",
    "            best_train_loss = train_loss\n",
    "\n",
    "        if (test_loss < best_test_loss):\n",
    "            wandb.run.summary[\"best_test_loss\"] = test_loss\n",
    "            best_test_loss = test_loss\n",
    "            model_is_best = True\n",
    "\n",
    "        metrics_dict = {\n",
    "            \"train_loss\":train_loss,\n",
    "            \"test_loss\":test_loss,\n",
    "            \"epoch\":epoch,\n",
    "        }\n",
    "        wandb.log(metrics_dict)\n",
    "        logger.info(f\"Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f} \")\n",
    "\n",
    "        model_path = f\"./models/{epoch}_model_state_dict.pt\"\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        model_art = wandb.Artifact(f\"{MODEL_NAME}_iteration_{iteration}\", type='model')\n",
    "        model_art.add_file(model_path)\n",
    "        wandb.log_artifact(model_art, aliases=[LATEST_TAG, ] if model_is_best else None)\n",
    "        if model_is_best:\n",
    "            best_model_art = model_art\n",
    "            best_model_path = model_path\n",
    "\n",
    "    production_model = None\n",
    "    try:\n",
    "        production_model_dir = wandb.use_artifact(f'{ENTITY_NAME}/{PROJECT_NAME}/{MODEL_REGISTRY_NAME}:{PRODUCTION_TAG}').download()\n",
    "        production_model_path = f\"{production_model_dir}/{os.listdir(production_model_dir)[0]}\"\n",
    "        production_model = load_model(production_model_path, wandb.config['hidden_channels'], data)\n",
    "        logger.info('Production model found')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        logger.info('No production model found')\n",
    "\n",
    "\n",
    "    contender_model = load_model(best_model_path, wandb.config['hidden_channels'], data)\n",
    "    hit_rate_by_contender_model = evaluate_model(contender_model, test_data)\n",
    "    wandb.log({\"contender_model_hit_rate\": hit_rate_by_contender_model}) \n",
    "\n",
    "    if production_model == None:\n",
    "        is_contender_model_better = True\n",
    "    else:\n",
    "        test_loss_by_production_model = test(production_model, test_loader)    \n",
    "        hit_rate_by_production_model = evaluate_model(production_model, test_data)\n",
    "        wandb.log({\"production_model_test_loss\":test_loss_by_production_model, \"production_model_hit_rate\": hit_rate_by_contender_model}) \n",
    "        is_contender_model_better = test_loss_by_production_model < best_test_loss and hit_rate_by_contender_model > hit_rate_by_production_model\n",
    "\n",
    "    model_registry_art = wandb.Artifact(MODEL_REGISTRY_NAME, type='model_registry')\n",
    "    model_registry_art.add_file(best_model_path)\n",
    "    # should go through shadow deployment or A/B Testing first before promoting it to production\n",
    "    wandb.log_artifact(model_registry_art, aliases=[PRODUCTION_TAG, LATEST_TAG] if is_contender_model_better else [LATEST_TAG])\n",
    "    # Save code\n",
    "    wandb.run.log_code(\n",
    "     \"./\", include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\")\n",
    "    )\n",
    "    wandb.finish()\n",
    "    \n",
    "    if start_date == dt.strptime(MAX_START_DATE, '%Y-%m-%d').date():\n",
    "        break\n",
    "    else:   \n",
    "        start_date = nxt_start_date\n",
    "        iteration += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f776fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bff6f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0 > float('-inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e868804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Runs yhchan0918/CT_OF_AIRBNB_RECSYS>\n",
      "No runs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, datetime.date(2015, 10, 24))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Fetch the iteration, end date of last run to determine iteration, start_date of current run\n",
    "# if cant find then the iteration is 0 and the start date just use the SIMULATION_START_DATE variable\n",
    "\n",
    "try:\n",
    "    api = wandb.Api()\n",
    "    runs = api.runs(f\"{ENTITY_NAME}/{PROJECT_NAME}\")\n",
    "    if len(runs) == 0:\n",
    "        raise Exception(\"No runs\")\n",
    "    last_iteration = float('-inf')\n",
    "    end_date_of_last_iteration = None\n",
    "\n",
    "    for run in runs: \n",
    "        config = {k: v for k,v in run.config.items()\n",
    "             if not k.startswith('_')}\n",
    "        run_name = run.name\n",
    "        iteration_no = int(run_name.split('_')[1])\n",
    "        if  iteration_no > last_iteration:\n",
    "            last_iteration = iteration_no\n",
    "            end_date_of_last_iteration = config['end_date']\n",
    "                  \n",
    "    current_iteration = last_iteration + 1\n",
    "    current_start_date = dt.strptime(end_date_of_last_iteration, \"%Y-%m-%d\").date() + relativedelta(days=1)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    current_iteration = 0\n",
    "    current_start_date = dt.strptime(SIMULATION_START_DATE, \"%Y-%m-%d\").date()              \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "              \n",
    "current_iteration, current_start_date              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "424fb4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, datetime.date(2015, 10, 24))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75adcd82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7303f620",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/yhchan/Downloads/FYP/CT_of_recommendation_system/ml_pipeline/wandb/run-20230225_232808-2s1uyljt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yhchan0918/my-awesome-project/runs/2s1uyljt' target=\"_blank\">experiment_1</a></strong> to <a href='https://wandb.ai/yhchan0918/my-awesome-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yhchan0918/my-awesome-project' target=\"_blank\">https://wandb.ai/yhchan0918/my-awesome-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yhchan0918/my-awesome-project/runs/2s1uyljt' target=\"_blank\">https://wandb.ai/yhchan0918/my-awesome-project/runs/2s1uyljt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1924b16685241d6861b3edd5275b466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▆▄█▇▇█▇</td></tr><tr><td>hit_rate</td><td>▁</td></tr><tr><td>loss</td><td>█▄▂▁▂▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.75372</td></tr><tr><td>date</td><td>2023-02-26</td></tr><tr><td>hit_rate</td><td>0.86809</td></tr><tr><td>loss</td><td>0.18551</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">experiment_1</strong> at: <a href='https://wandb.ai/yhchan0918/my-awesome-project/runs/2s1uyljt' target=\"_blank\">https://wandb.ai/yhchan0918/my-awesome-project/runs/2s1uyljt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230225_232808-2s1uyljt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb29fb85191f4ab5b7c7d299d231047a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01675109305000054, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/yhchan/Downloads/FYP/CT_of_recommendation_system/ml_pipeline/wandb/run-20230225_232818-1gkr4dpo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yhchan0918/my-awesome-project/runs/1gkr4dpo' target=\"_blank\">experiment_2</a></strong> to <a href='https://wandb.ai/yhchan0918/my-awesome-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yhchan0918/my-awesome-project' target=\"_blank\">https://wandb.ai/yhchan0918/my-awesome-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yhchan0918/my-awesome-project/runs/1gkr4dpo' target=\"_blank\">https://wandb.ai/yhchan0918/my-awesome-project/runs/1gkr4dpo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca6067e85c6495cb054fd3cef77b238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.027 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.034441…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▅▆█▇██▇</td></tr><tr><td>hit_rate</td><td>▁</td></tr><tr><td>loss</td><td>█▄▇▃▄▃▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.7306</td></tr><tr><td>date</td><td>2023-02-27</td></tr><tr><td>hit_rate</td><td>0.94817</td></tr><tr><td>loss</td><td>0.22256</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">experiment_2</strong> at: <a href='https://wandb.ai/yhchan0918/my-awesome-project/runs/1gkr4dpo' target=\"_blank\">https://wandb.ai/yhchan0918/my-awesome-project/runs/1gkr4dpo</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230225_232818-1gkr4dpo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ad07a00f1240c38b88a7fe6cf6040c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01672731943333474, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/yhchan/Downloads/FYP/CT_of_recommendation_system/ml_pipeline/wandb/run-20230225_232829-ehb43ltp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yhchan0918/my-awesome-project/runs/ehb43ltp' target=\"_blank\">experiment_3</a></strong> to <a href='https://wandb.ai/yhchan0918/my-awesome-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yhchan0918/my-awesome-project' target=\"_blank\">https://wandb.ai/yhchan0918/my-awesome-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yhchan0918/my-awesome-project/runs/ehb43ltp' target=\"_blank\">https://wandb.ai/yhchan0918/my-awesome-project/runs/ehb43ltp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940c98f60cda4a4eb1ae239a8c248c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.027 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.034441…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▅▃▄▇█▇█</td></tr><tr><td>hit_rate</td><td>▁</td></tr><tr><td>loss</td><td>█▃▂▃▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.84853</td></tr><tr><td>date</td><td>2023-02-28</td></tr><tr><td>hit_rate</td><td>0.80284</td></tr><tr><td>loss</td><td>0.16238</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">experiment_3</strong> at: <a href='https://wandb.ai/yhchan0918/my-awesome-project/runs/ehb43ltp' target=\"_blank\">https://wandb.ai/yhchan0918/my-awesome-project/runs/ehb43ltp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230225_232829-ehb43ltp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f6e736571a459fa215cac7815a01c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016743477766666123, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/yhchan/Downloads/FYP/CT_of_recommendation_system/ml_pipeline/wandb/run-20230225_232838-dvee1la1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yhchan0918/my-awesome-project/runs/dvee1la1' target=\"_blank\">experiment_4</a></strong> to <a href='https://wandb.ai/yhchan0918/my-awesome-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yhchan0918/my-awesome-project' target=\"_blank\">https://wandb.ai/yhchan0918/my-awesome-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yhchan0918/my-awesome-project/runs/dvee1la1' target=\"_blank\">https://wandb.ai/yhchan0918/my-awesome-project/runs/dvee1la1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3efb6860997045488c994a6875759086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.027 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▂▂▅▅▇█▆</td></tr><tr><td>hit_rate</td><td>▁</td></tr><tr><td>loss</td><td>█▅▅▅▃▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.70462</td></tr><tr><td>date</td><td>2023-03-01</td></tr><tr><td>hit_rate</td><td>0.8891</td></tr><tr><td>loss</td><td>0.25627</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">experiment_4</strong> at: <a href='https://wandb.ai/yhchan0918/my-awesome-project/runs/dvee1la1' target=\"_blank\">https://wandb.ai/yhchan0918/my-awesome-project/runs/dvee1la1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230225_232838-dvee1la1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb7597fc16c94dc2b31c4d38bd7ad550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016752406950001842, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/yhchan/Downloads/FYP/CT_of_recommendation_system/ml_pipeline/wandb/run-20230225_232850-ihc41jav</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yhchan0918/my-awesome-project/runs/ihc41jav' target=\"_blank\">experiment_5</a></strong> to <a href='https://wandb.ai/yhchan0918/my-awesome-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yhchan0918/my-awesome-project' target=\"_blank\">https://wandb.ai/yhchan0918/my-awesome-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yhchan0918/my-awesome-project/runs/ihc41jav' target=\"_blank\">https://wandb.ai/yhchan0918/my-awesome-project/runs/ihc41jav</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▄▄▅▆███</td></tr><tr><td>hit_rate</td><td>▁</td></tr><tr><td>loss</td><td>█▄▃▃▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.95688</td></tr><tr><td>date</td><td>2023-03-02</td></tr><tr><td>hit_rate</td><td>0.15433</td></tr><tr><td>loss</td><td>0.03116</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">experiment_5</strong> at: <a href='https://wandb.ai/yhchan0918/my-awesome-project/runs/ihc41jav' target=\"_blank\">https://wandb.ai/yhchan0918/my-awesome-project/runs/ihc41jav</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230225_232850-ihc41jav/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Launch 5 simulated experiments\n",
    "total_runs = 5\n",
    "\n",
    "for run in range(1, total_runs + 1):\n",
    "  # 🐝 1️⃣ Start a new run to track this script\n",
    "    wandb.init(\n",
    "      # Set the project where this run will be logged\n",
    "      project=\"my-awesome-project\", \n",
    "      # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "      name=f\"experiment_{run}\", \n",
    "      # Track hyperparameters and run metadata\n",
    "      config={\n",
    "      \"learning_rate\": 0.02,\n",
    "      \"architecture\": \"CNN\",\n",
    "      \"dataset\": \"CIFAR-100\",\n",
    "      \"epochs\": 10,\n",
    "      \"iteration\": run\n",
    "      })\n",
    "\n",
    "    # This simple block simulates a training loop logging metrics\n",
    "    epochs = 10\n",
    "    offset = random.random() / 5\n",
    "    for epoch in range(2, epochs):\n",
    "        acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
    "        loss = 2 ** -epoch + random.random() / epoch + offset\n",
    "        wandb.log({\"acc\": acc, \"loss\": loss})\n",
    "    \n",
    "    today = (date.today() + timedelta(days=run))\n",
    "    hit_rate = random.random()\n",
    "    wandb.log({\"hit_rate\": hit_rate, \"date\":today }) \n",
    "\n",
    "    # Mark the run as finished\n",
    "    wandb.finish()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tt] *",
   "language": "python",
   "name": "conda-env-tt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
